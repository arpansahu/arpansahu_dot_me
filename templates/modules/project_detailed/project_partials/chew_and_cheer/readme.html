<h1>
 chew_and_cheer | Django Project CRUD using AJAX, DJANGO FORMS, GRAPHQL and DJANGO REST/GRAPHQL APIs
</h1>
<p>
 This is a simple django CRUD project
</p>
<h2>
 Project Features
</h2>
<ol>
 <li>
  <strong>
   Account Functionality:
  </strong>
  Complete account management.
 </li>
 <li>
  <strong>
   PostgreSql Integration:
  </strong>
  Utilized as a database.
 </li>
 <li>
  <strong>
   AWS S3/MinIO Integration:
  </strong>
  For file storage.
 </li>
 <li>
  <strong>
   Redis Integration:
  </strong>
  Utilized for caching and message pub/sub.
 </li>
 <li>
  <strong>
   MailJet Integration:
  </strong>
  Used for email services.
 </li>
 <li>
  <strong>
   Dockerized Project:
  </strong>
  Fully containerized for easy deployment.
 </li>
 <li>
  <strong>
   Kubernetes-native
  </strong>
  Kubernetes support also available.
 </li>
 <li>
  <strong>
   CI/CD Pipeline:
  </strong>
  Continuous integration and deployment included using Jenkins.
 </li>
 <li>
  <strong>
   Sentry Integrated:
  </strong>
  Logging and Debugging Made Easy.
 </li>
</ol>
<h2>
 CURD Functionalities
</h2>
<p>
 CRUD Operations
</p>
<h3>
 Django Forms
</h3>
<pre><code>-   Create Operation: Users can create new entries using Django forms. The form data is validated on the server side, and upon successful validation, the data is saved to the PostgreSQL database.
-   Read Operation: The project displays existing entries using Django views and templates. Users can view a list of entries or details of a specific entry.
-   Update Operation: Users can update existing entries through forms. The current data is pre-populated in the form, allowing users to make changes and save them.
-   Delete Operation: Users can delete entries. Upon confirmation, the entry is removed from the database.
</code></pre>
<h3>
 AJAX Integration
</h3>
<pre><code>-   Asynchronous Form Submission: Forms are submitted using AJAX to provide a seamless user experience. The page does not need to reload, and users receive immediate feedback.
-   Dynamic Content Loading: Data is fetched asynchronously to update parts of the web page without a full reload, enhancing responsiveness.
</code></pre>
<h3>
 GraphQL Integration
</h3>
<pre><code>-   Querying Data: Users can query entries using GraphQL queries. This allows fetching specific data fields, reducing the amount of data transferred.
-   Mutations: Users can create, update, and delete entries using GraphQL mutations, providing a flexible and efficient way to manage data.
</code></pre>
<h2>
 Django REST Framework (DRF) API
</h2>
<p>
 The project includes an API app that demonstrates different views available in Django REST Framework:
</p>
<pre><code>-  Function-Based Views (FBVs)
-   FBV with @api_view Decorator
-   Basic Class-Based Views (CBVs)
-   Class-Based Views using APIView
-   Generic API Views with Mixins
-   ViewSets
-   ViewSets with Authentication and Permissions
-   ListAPIView with Filters and Pagination
-   Nested Serializers and Hyperlinked Serializers
</code></pre>
<ul>
 <li>
  Have Open Schema View
 </li>
 <li>
  Have Docs View
 </li>
</ul>
<p>
 -Deployed on AWS / Now in My Own Home Ubuntu Server LTS 22.0 / Hostinger VPS Server
</p>
<ol>
 <li>
  <strong>
   Ubuntu 22.0 LTS
  </strong>
  - Base operating system
 </li>
 <li>
  <strong>
   Nginx
  </strong>
  - Web proxy server with HTTPS
 </li>
 <li>
  <strong>
   Wildcard SSL
  </strong>
  - Let's Encrypt certificate via acme.sh
 </li>
 <li>
  <strong>
   Acme-dns
  </strong>
  - Automated wildcard certificate renewal
 </li>
 <li>
  <strong>
   Docker/Kubernetes
  </strong>
  - Container orchestration with k3s, managed via Portainer at https://portainer.arpansahu.space
 </li>
 <li>
  <strong>
   Jenkins
  </strong>
  - CI/CD pipeline at https://jenkins.arpansahu.space
 </li>
 <li>
  <strong>
   PostgreSQL
  </strong>
  - Schema-based database with TLS stream proxy at https://postgres.arpansahu.space:9552
 </li>
 <li>
  <strong>
   PgAdmin
  </strong>
  - PostgreSQL management UI at https://pgadmin.arpansahu.space
 </li>
 <li>
  <strong>
   Redis
  </strong>
  - Caching and message broker with TLS stream proxy at https://redis.arpansahu.space:9551
 </li>
 <li>
  <strong>
   Redis Commander
  </strong>
  - Redis management UI at https://redis.arpansahu.space
 </li>
 <li>
  <strong>
   MinIO
  </strong>
  - Self-hosted S3 storage server at https://minio.arpansahu.space (Console) and https://minioapi.arpansahu.space (API)
 </li>
 <li>
  <strong>
   Harbor
  </strong>
  - Self-hosted Docker registry at https://harbor.arpansahu.space
 </li>
 <li>
  <strong>
   RabbitMQ
  </strong>
  - Message queue broker at https://rabbitmq.arpansahu.space
 </li>
 <li>
  <strong>
   Kafka/AKHQ
  </strong>
  - Event streaming platform with UI at https://kafka.arpansahu.space
 </li>
 <li>
  <strong>
   SSH Web Terminal
  </strong>
  - Browser-based SSH access at https://ssh.arpansahu.space
 </li>
 <li>
  <strong>
   Sentry
  </strong>
  - Error tracking and monitoring at https://arpansahu.sentry.io
 </li>
 <li>
  <strong>
   Monitoring Stack
  </strong>
  - Prometheus, Grafana, and node-exporter for system monitoring
 </li>
</ol>
<h2>
 What is Python ?
</h2>
<p>
 Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the
 <br/>
 use of significant indentation. Python is dynamically typed and garbage-collected. It supports multiple programming
 <br/>
 paradigms, including structured, object-oriented and functional programming.
</p>
<h2>
 What is Django ?
</h2>
<p>
 Django is a Python-based free and open-source web framework that follows the model-template-view architectural pattern.
</p>
<h2>
 What is Redis ?
</h2>
<p>
 Redis is an in-memory data structure project implementing a distributed, in-memory key-value database with optional durability.
 <br/>
 The most common Redis use cases are session cache, full-page cache, queues, leader boards and counting, publish-subscribe, and much more. in this case, we will use Redis as a message broker.
</p>
<h2>
 What is GraphQL?
</h2>
<p>
 GraphQL is a query language for APIs developed by Facebook, enabling clients to request exactly the data they need. Using a single endpoint, GraphQL allows clients to specify queries and mutations, which can reduce network overhead and improve efficiency. It is strongly typed, providing a clear and precise schema that defines the structure of the data and the possible queries. GraphQL also supports real-time updates with subscriptions, allowing clients to receive live data changes. This flexibility and efficiency make it a powerful tool for modern API development.
</p>
<h2>
 Django Rest Framework
</h2>
<p>
 Django Rest Framework (DRF) is a powerful and flexible toolkit for building Web APIs in Django. It supports RESTful API development, enabling the creation of endpoints for various HTTP methods like GET, POST, PUT, and DELETE. DRF simplifies serialization, authentication, and authorization, making it easy to convert complex data types such as querysets and model instances to native Python datatypes that can be easily rendered into JSON, XML, or other content types. Its extensive documentation, built-in features, and customizable components make it a popular choice for building robust and scalable APIs in Django.
</p>
<h2>
 What is AJAX?
</h2>
<p>
 A web development technique that enables asynchronous data exchange between a web browser and a server without requiring a full page refresh. By using JavaScript to send HTTP requests and receive responses, AJAX can update parts of a web page dynamically, enhancing user experience with faster and more interactive interfaces. It supports various data formats, including JSON, XML, HTML, and plain text. AJAX is widely used in web applications for tasks such as form submissions, content updates, and data retrieval, providing a seamless and responsive user experience.
</p>
<h2>
 Tech Stack
</h2>
<p>
 <a href="https://www.python.org/">
  <img alt="Python" src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.djangoproject.com/">
  <img alt="Django" src="https://img.shields.io/badge/Django-092E20?style=for-the-badge&logo=django&logoColor=white"/>
 </a>
 <br/>
 <a href="https://developer.mozilla.org/en-US/docs/Glossary/HTML5">
  <img alt="HTML5" src="https://img.shields.io/badge/html5-%23E34F26.svg?style=for-the-badge&logo=html5&logoColor=white"/>
 </a>
 <br/>
 <a href="https://developer.mozilla.org/en-US/docs/Web/CSS">
  <img alt="CSS3" src="https://img.shields.io/badge/css3-%231572B6.svg?style=for-the-badge&logo=css3&logoColor=white"/>
 </a>
 <br/>
 <a href="https://getbootstrap.com/">
  <img alt="Bootstrap" src="https://img.shields.io/badge/Bootstrap-563D7C?style=for-the-badge&logo=bootstrap&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.javascript.com/">
  <img alt="Javascript" src="https://img.shields.io/badge/JavaScript-323330?style=for-the-badge&logo=javascript&logoColor=F7DF1E"/>
 </a>
 <br/>
 <a href="https://redis.io/docs/">
  <img alt="Redis" src="https://img.shields.io/badge/redis-%23DD0031.svg?style=for-the-badge&logo=redis&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.postgresql.org/docs/">
  <img alt="Postgres" src="https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.github.com/">
  <img alt="Github" src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.docker.com/">
  <img alt="Docker" src="https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white"/>
 </a>
 <br/>
 <a href="https://goharbor.io/">
  <img alt="Harbor" src="https://img.shields.io/badge/HARBOR-TEXT?style=for-the-badge&logo=harbor&logoColor=white&color=blue"/>
 </a>
 <br/>
 <a href="https://kubernetes.io/">
  <img alt="Kubernetes" src="https://img.shields.io/badge/kubernetes-326ce5.svg?&style=for-the-badge&logo=kubernetes&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.jenkins.io/">
  <img alt="Jenkins" src="https://img.shields.io/badge/Jenkins-D24939?style=for-the-badge&logo=Jenkins&logoColor=white"/>
 </a>
 <br/>
 <a href="https://nginx.org/en/">
  <img alt="Nginx" src="https://img.shields.io/badge/Nginx-009639?style=for-the-badge&logo=nginx&logoColor=white"/>
 </a>
 <br/>
 <a href="https://min.io/">
  <img alt="MINIIO" src="https://img.shields.io/badge/MINIO-TEXT?style=for-the-badge&logo=minio&logoColor=white&color=%23C72E49"/>
 </a>
 <br/>
 <a href="https://ubuntu.com/">
  <img alt="Ubuntu" src="https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white"/>
 </a>
 <br/>
 <a href="https://mailjet.com/">
  <img alt="Mail Jet" src="https://img.shields.io/badge/MAILJET-9933CC?style=for-the-badge&logo=minutemailer&logoColor=white"/>
 </a>
 <br/>
 <a href="https://graphql.org/">
  <img alt="GraphQL" src="https://img.shields.io/badge/-GraphQL-E10098?style=for-the-badge&logo=graphql&logoColor=white"/>
 </a>
 <br/>
 <a href="https://rancher.com/">
  <img alt="Rancher" src="https://img.shields.io/badge/Rancher-0075A8?style=for-the-badge&logo=rancher&logoColor=white"/>
 </a>
</p>
<h2>
 Demo
</h2>
<p>
 Available at: https://chew-and-cheer.arpansahu.me
</p>
<p>
 admin login details:--
 <br/>
 email: admin@arpansahu.space
 <br/>
 password: showmecode
</p>
<h2>
 License
</h2>
<p>
 <a href="https://choosealicense.com/licenses/mit/">
  MIT
 </a>
</p>
<h2>
 Installation
</h2>
<p>
 Installing Pre requisites
</p>
<pre><code class="language-bash">  pip install -r requirements.txt
</code></pre>
<p>
 Create .env File and don't forget to add .env to gitignore
</p>
<pre><code class="language-bash">  add variables mentioned in .env.example
</code></pre>
<p>
 Making Migrations and Migrating them.
</p>
<pre><code class="language-bash">  python manage.py makemigrations
  python manage.py migrate
</code></pre>
<p>
 Run update_data Command
</p>
<pre><code>  python manage.py update_data
</code></pre>
<p>
 Creating Super User
</p>
<pre><code class="language-bash">  python manage.py createsuperuser
</code></pre>
<p>
 Installing Redis On Local (For ubuntu) for other Os Please refer to their website https://redis.io/
</p>
<pre><code class="language-bash">  curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg
  echo &quot;deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main&quot; | sudo tee /etc/apt/sources.list.d/redis.list
  sudo apt-get update
  sudo apt-get install redis
  sudo systemctl restart redis.service
</code></pre>
<p>
 to check if its running or not
</p>
<pre><code class="language-bash">  sudo systemctl status redis
</code></pre>
<p>
 Run Server
</p>
<pre><code class="language-bash">  python manage.py runserver

  or 

  gunicorn --bind 0.0.0.0:8001 chew_and_cheer.wsgi
</code></pre>
<p>
 Use these CACHE settings
</p>
<pre><code class="language-python">
if not DEBUG:
    CHANNEL_LAYERS = {
        &#x27;default&#x27;: {
            &quot;BACKEND&quot;: &quot;channels.layers.InMemoryChannelLayer&quot;,
        }
    }
else:
    CHANNEL_LAYERS = {
        &quot;default&quot;: {
            &quot;BACKEND&quot;: &quot;channels_redis.core.RedisChannelLayer&quot;,
            &quot;CONFIG&quot;: {
                &quot;hosts&quot;: [(REDIS_CLOUD_URL)],
            },
        },
    }
</code></pre>
<p>
 Change settings.py static files and media files settings | Now I have added support for BlackBlaze Static Storage also which also based on AWS S3 protocols
</p>
<pre><code class="language-python">if not DEBUG:
    BUCKET_TYPE = BUCKET_TYPE

    if BUCKET_TYPE == &#x27;AWS&#x27;:
        AWS_S3_CUSTOM_DOMAIN = f&#x27;{AWS_STORAGE_BUCKET_NAME}.s3.amazonaws.com&#x27;
        AWS_DEFAULT_ACL = &#x27;public-read&#x27;
        AWS_S3_OBJECT_PARAMETERS = {
            &#x27;CacheControl&#x27;: &#x27;max-age=86400&#x27;
        }
        AWS_LOCATION = &#x27;static&#x27;
        AWS_QUERYSTRING_AUTH = False
        AWS_HEADERS = {
            &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27;,
        }
        # s3 static settings
        AWS_STATIC_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/static&#x27;
        STATIC_URL = f&#x27;https://{AWS_S3_CUSTOM_DOMAIN}/{AWS_STATIC_LOCATION}/&#x27;
        STATICFILES_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.StaticStorage&#x27;
        # s3 public media settings
        AWS_PUBLIC_MEDIA_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/media&#x27;
        MEDIA_URL = f&#x27;https://{AWS_S3_CUSTOM_DOMAIN}/{AWS_PUBLIC_MEDIA_LOCATION}/&#x27;
        DEFAULT_FILE_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.PublicMediaStorage&#x27;
        # s3 private media settings
        PRIVATE_MEDIA_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/private&#x27;
        PRIVATE_FILE_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.PrivateMediaStorage&#x27;

    elif BUCKET_TYPE == &#x27;BLACKBLAZE&#x27;:
        AWS_S3_REGION_NAME = &#x27;us-east-005&#x27;

        AWS_S3_ENDPOINT = f&#x27;s3.{AWS_S3_REGION_NAME}.backblazeb2.com&#x27;
        AWS_S3_ENDPOINT_URL = f&#x27;https://{AWS_S3_ENDPOINT}&#x27;

        AWS_DEFAULT_ACL = &#x27;public-read&#x27;
        AWS_S3_OBJECT_PARAMETERS = {
            &#x27;CacheControl&#x27;: &#x27;max-age=86400&#x27;,
        }

        AWS_LOCATION = &#x27;static&#x27;
        AWS_QUERYSTRING_AUTH = False
        AWS_HEADERS = {
            &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27;,
        }
        # s3 static settings
        AWS_STATIC_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/static&#x27;
        STATIC_URL = f&#x27;https://{AWS_STORAGE_BUCKET_NAME}.{AWS_STATIC_LOCATION}/&#x27;
        STATICFILES_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.StaticStorage&#x27;
        # s3 public media settings
        AWS_PUBLIC_MEDIA_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/media&#x27;
        MEDIA_URL = f&#x27;https://{AWS_STORAGE_BUCKET_NAME}.{AWS_PUBLIC_MEDIA_LOCATION}/&#x27;
        DEFAULT_FILE_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.PublicMediaStorage&#x27;
        # s3 private media settings
        PRIVATE_MEDIA_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/private&#x27;
        PRIVATE_FILE_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.PrivateMediaStorage&#x27;

    elif BUCKET_TYPE == &#x27;MINIO&#x27;:
        AWS_S3_REGION_NAME = &#x27;us-east-1&#x27;  # MinIO doesn&#x27;t require this, but boto3 does
        AWS_S3_ENDPOINT_URL = &#x27;https://minio.arpansahu.me&#x27;
        AWS_DEFAULT_ACL = &#x27;public-read&#x27;
        AWS_S3_OBJECT_PARAMETERS = {
            &#x27;CacheControl&#x27;: &#x27;max-age=86400&#x27;,
        }
        AWS_LOCATION = &#x27;static&#x27;
        AWS_QUERYSTRING_AUTH = False
        AWS_HEADERS = {
            &#x27;Access-Control-Allow-Origin&#x27;: &#x27;*&#x27;,
        }

        # s3 static settings
        AWS_STATIC_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/static&#x27;
        STATIC_URL = f&#x27;https://{AWS_STORAGE_BUCKET_NAME}/{AWS_STATIC_LOCATION}/&#x27;
        STATICFILES_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.StaticStorage&#x27;

        # s3 public media settings
        AWS_PUBLIC_MEDIA_LOCATION = f&#x27;portfolio/{PROJECT_NAME}/media&#x27;
        MEDIA_URL = f&#x27;https://{AWS_STORAGE_BUCKET_NAME}/{AWS_PUBLIC_MEDIA_LOCATION}/&#x27;
        DEFAULT_FILE_STORAGE = f&#x27;{PROJECT_NAME}.storage_backends.PublicMediaStorage&#x27;

        # s3 private media settings
        PRIVATE_MEDIA_LOCATION = &#x27;portfolio/borcelle_crm/private&#x27;
        PRIVATE_FILE_STORAGE = &#x27;borcelle_crm.storage_backends.PrivateMediaStorage&#x27;
else:
    # Static files (CSS, JavaScript, Images)
    # https://docs.djangoproject.com/en/3.2/howto/static-files/

    STATIC_URL = &#x27;/static/&#x27;

    STATIC_ROOT = os.path.join(BASE_DIR, &#x27;staticfiles&#x27;)
    MEDIA_URL = &#x27;/media/&#x27;

MEDIA_ROOT = os.path.join(BASE_DIR, &#x27;media&#x27;)
STATICFILES_DIRS = [os.path.join(BASE_DIR, &quot;static&quot;), ]
</code></pre>
<p>
 run below command
</p>
<pre><code class="language-bash">python manage.py collectstatic
</code></pre>
<p>
 and you are good to go
</p>
<h2>
 Custom Django Management Commands
</h2>
<ol>
 <li>
  Test DB
  <br/>
  Django management command designed to test the basic functionality of the database. It performs a series of CRUD (Create, Read, Update, Delete) operations to ensure the database is working correctly.
 </li>
</ol>
<pre><code class="language-bash">python manage.py test_db
</code></pre>
<ol>
 <li>
  Test Cache
  <br/>
  Django management command designed to test the basic functionality of the caching system. It performs a set and get operation to ensure the cache is working correctly and validates the expiration of cache entries.
 </li>
</ol>
<pre><code class="language-bash">python manage.py test_cache
</code></pre>
<h2>
 Readme Manager
</h2>
<p>
 Each repository contains an
 <code>
  update_readme.sh
 </code>
 script located in the
 <code>
  readme_manager
 </code>
 directory. This script is responsible for updating the README file in the repository by pulling in content from various sources.
</p>
<h3>
 What it Does
</h3>
<p>
 The
 <code>
  update_readme.sh
 </code>
 script performs the following actions:
</p>
<ol>
 <li>
  <strong>
   Clone Required Files
  </strong>
  : Clones the
  <code>
   requirements.txt
  </code>
  ,
  <code>
   readme_updater.py
  </code>
  , and
  <code>
   baseREADME.md
  </code>
  files from the
  <code>
   common_readme
  </code>
  repository.
 </li>
 <li>
  <strong>
   Set Up Python Environment
  </strong>
  : Creates and activates a Python virtual environment.
 </li>
 <li>
  <strong>
   Install Dependencies
  </strong>
  : Installs the necessary dependencies listed in
  <code>
   requirements.txt
  </code>
  .
 </li>
 <li>
  <strong>
   Run Update Script
  </strong>
  : Executes the
  <code>
   readme_updater.py
  </code>
  script to update the README file using
  <code>
   baseREADME.md
  </code>
  and other specified sources.
 </li>
 <li>
  <strong>
   Clean Up
  </strong>
  : Deactivates the Python virtual environment and removes it.
 </li>
</ol>
<h3>
 How to Use
</h3>
<p>
 To run the
 <code>
  update_readme.sh
 </code>
 script, navigate to the
 <code>
  readme_manager
 </code>
 directory and execute the script:
</p>
<pre><code class="language-bash">cd readme_manager &amp;&amp; ./update_readme.sh
</code></pre>
<p>
 This will update the
 <code>
  README.md
 </code>
 file in the root of the repository with the latest content from the specified sources.
</p>
<h3>
 Updating Content
</h3>
<p>
 If you need to make changes that are specific to the project or project-specific files, you might need to update the content of the partial README files. Here are the files that are included:
</p>
<ul>
 <li>
  <strong>
   Project-Specific Files
  </strong>
  :
 </li>
 <li>
  <code>
   env.example
  </code>
 </li>
 <li>
  <code>
   docker-compose.yml
  </code>
 </li>
 <li>
  <code>
   Dockerfile
  </code>
 </li>
 <li>
  <p>
   <code>
    Jenkinsfile
   </code>
  </p>
 </li>
 <li>
  <p>
   <strong>
    Project-Specific Partial Files
   </strong>
   :
  </p>
 </li>
 <li>
  <code>
   INTRODUCTION
  </code>
  :
  <code>
   ../readme_manager/partials/introduction.md
  </code>
 </li>
 <li>
  <code>
   DOC_AND_STACK
  </code>
  :
  <code>
   ../readme_manager/partials/documentation_and_stack.md
  </code>
 </li>
 <li>
  <code>
   TECHNOLOGY QNA
  </code>
  :
  <code>
   ../readme_manager/partials/technology_qna.md
  </code>
 </li>
 <li>
  <code>
   DEMO
  </code>
  :
  <code>
   ../readme_manager/partials/demo.md
  </code>
 </li>
 <li>
  <code>
   INSTALLATION
  </code>
  :
  <code>
   ../readme_manager/partials/installation.md
  </code>
 </li>
 <li>
  <code>
   DJANGO_COMMANDS
  </code>
  :
  <code>
   ../readme_manager/partials/django_commands.md
  </code>
 </li>
 <li>
  <code>
   NGINX_SERVER
  </code>
  :
  <code>
   ../readme_manager/partials/nginx_server.md
  </code>
 </li>
</ul>
<p>
 These files are specific to the project and should be updated within the project repository.
</p>
<ul>
 <li>
  <strong>
   Common Files
  </strong>
  :
 </li>
 <li>
  All other files are common across projects and should be updated in the
  <code>
   common_readme
  </code>
  repository.
 </li>
</ul>
<p>
 There are a few files which are common for all projects. For convenience, these are inside the
 <code>
  common_readme
 </code>
 repository so that if changes are made, they will be updated in all the projects' README files.
</p>
<pre><code class="language-python"># Define a dictionary with the placeholders and their corresponding GitHub raw URLs or local paths

include_files = {
    # common files

    &quot;README of Docker Installation&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/01-docker/docker_installation.md&quot;,
    &quot;DOCKER_END&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/01-docker/docker_end.md&quot;,
    &quot;README of Nginx Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/02-nginx/README.md&quot;,
    &quot;README of Jenkins Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/12-jenkins/Jenkins.md&quot;,
    &quot;README of PostgreSql Server With Nginx Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/03-postgres/README.md&quot;,
    &quot;README of PGAdmin4 Server With Nginx Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/06-pgadmin/README.md&quot;,
    &quot;README of Portainer Server With Nginx Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/05-portainer/README.md&quot;,
    &quot;README of Redis Server Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/04-redis/README.md&quot;,
    &quot;README of Redis Commander Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/07-redis_commander/README.md&quot;,
    &quot;README of Minio Server Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/08-minio/README.md&quot;,
    &quot;README of RabbitMQ Server Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/09-rabbitmq/README.md&quot;,
    &quot;README of Kafka Server Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/10-kafka/Kafka.md&quot;,
    &quot;README of AKHQ UI Setup&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/10-kafka/AKHQ.md&quot;,
    &quot;README of Intro&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/Intro.md&quot;,
    &quot;INSTALLATION ORDER&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/INSTALLATION_ORDER.md&quot;,
    &quot;HOME SERVER SETUP&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/README.md&quot;,
    &quot;SSH KEY SETUP&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/00-ssh-key-setup.md&quot;,
    &quot;HARDWARE PREPARATION&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/01-hardware-preparation.md&quot;,
    &quot;UBUNTU INSTALLATION&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/02-ubuntu-installation.md&quot;,
    &quot;INITIAL CONFIGURATION&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/03-initial-configuration.md&quot;,
    &quot;NETWORK CONFIGURATION&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/04-network-configuration.md&quot;,
    &quot;UPS CONFIGURATION&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/05-ups-configuration.md&quot;,
    &quot;BACKUP INTERNET&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/06-backup-internet.md&quot;,
    &quot;MONITORING SETUP&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/07-monitoring-setup.md&quot;,
    &quot;AUTOMATED BACKUPS&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/08-automated-backups.md&quot;,
    &quot;REMOTE ACCESS SETUP&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/09-remote-access.md&quot;,
    &quot;CORE SERVICES INSTALLATION&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/home_server/steps/10-core-services.md&quot;,
    &quot;SSH WEB TERMINAL SETUP&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/ssh-web-terminal/README.md&quot;,
    &quot;ROUTER ADMIN AIRTEL SETUP&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/airtel/README.md&quot;,
    &quot;README of Readme Manager&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/Readme%20manager/readme_manager.md&quot;,
    &quot;AWS DEPLOYMENT INTRODUCTION&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/Introduction/aws_desployment_introduction.md&quot;,
    &quot;STATIC_FILES&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/Introduction/static_files_settings.md&quot;,
    &quot;SENTRY&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/Introduction/sentry.md&quot;,
    &quot;CHANNELS&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/Introduction/channels.md&quot;,
    &quot;CACHE&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/Introduction/cache.md&quot;,
    &quot;README of Harbor&quot; : &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/11-harbor/harbor.md&quot;,
    &quot;INCLUDE FILES&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/include_files.py&quot;,
    &quot;MONITORING&quot;: &quot;https://raw.githubusercontent.com/arpansahu/arpansahu-one-scripts/main/README.md&quot;,

    # kubernetes k3s (current production setup: k3s + Portainer, Nginx-managed HTTPS)
    &quot;KUBE DEPLOYMENT&quot;: &quot;https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/kubernetes_k3s/README.md&quot;,

    # project files
    &quot;env.example&quot;: &quot;../env.example&quot;,
    &quot;docker-compose.yml&quot;: &quot;../docker-compose.yml&quot;,
    &quot;Dockerfile&quot;: &quot;../Dockerfile&quot;,
    &quot;Jenkinsfile-deploy&quot;: &quot;../Jenkinsfile-deploy&quot;,
    &quot;Jenkinsfile-build&quot;: &quot;../Jenkinsfile-build&quot;,
    &quot;DEPLOYMENT YAML&quot;: &quot;../deployment.yaml&quot;,
    &quot;SERVICE YAML&quot;: &quot;../service.yaml&quot;,


    # project partials files
    &quot;INTRODUCTION&quot;: &quot;../readme_manager/partials/introduction.md&quot;,
    &quot;INTRODUCTION MAIN&quot;: &quot;../readme_manager/partials/introduction_main.md&quot;,
    &quot;DOC_AND_STACK&quot;: &quot;../readme_manager/partials/documentation_and_stack.md&quot;,
    &quot;TECHNOLOGY QNA&quot;: &quot;../readme_manager/partials/technology_qna.md&quot;,
    &quot;DEMO&quot;: &quot;../readme_manager/partials/demo.md&quot;,
    &quot;INSTALLATION&quot;: &quot;../readme_manager/partials/installation.md&quot;,
    &quot;DJANGO_COMMANDS&quot;: &quot;../readme_manager/partials/django_commands.md&quot;,
    &quot;NGINX_SERVER&quot;: &quot;../readme_manager/partials/nginx_server.md&quot;,
    &quot;SERVICES&quot;: &quot;../readme_manager/partials/services.md&quot;,
    &quot;JENKINS PROJECT NAME&quot;: &quot;../readme_manager/partials/jenkins_project_name.md&quot;,
    &quot;JENKINS BUILD PROJECT NAME&quot;: &quot;../readme_manager/partials/jenkins_build_project_name.md&quot;,
    &quot;STATIC PROJECT NAME&quot;: &quot;../readme_manager/partials/static_project_name.md&quot;,
    &quot;PROJECT_NAME_DASH&quot; : &quot;../readme_manager/partials/project_name_with_dash.md&quot;,
    &quot;PROJECT_DOCKER_PORT&quot;: &quot;../readme_manager/partials/project_docker_port.md&quot;,
    &quot;PROJECT_NODE_PORT&quot;: &quot;../readme_manager/partials/project_node_port.md&quot;,
    &quot;DOMAIN_NAME&quot;: &quot;../readme_manager/partials/project_domain_name.md&quot;
}
</code></pre>
<p>
 Also, remember if you want to include new files, you need to change the
 <code>
  baseREADME
 </code>
 file and the
 <code>
  include_files
 </code>
 array in the
 <code>
  common_readme
 </code>
 repository itself.
</p>
<h2>
 Deployment on AWS EC2/ Home Server Ubuntu 22.0 LTS/ Hostinger VPS Server
</h2>
<h2>
 Deployment Architecture Evolution
</h2>
<p>
 This project and all related services have evolved through multiple deployment strategies, each with unique advantages. This documentation covers all three approaches to provide flexibility based on your needs.
</p>
<h3>
 Deployment Timeline
</h3>
<p>
 <strong>
  Phase 1: Heroku (Legacy)
 </strong>
 <br/>
 - Initial hosting on Heroku
 <br/>
 - Simple deployment but expensive at scale
 <br/>
 - Limited control over infrastructure
</p>
<p>
 <strong>
  Phase 2: EC2 + Home Server Hybrid (2022-2023)
 </strong>
 <br/>
 - EC2 for portfolio (arpansahu.me) with Nginx
 <br/>
 - Home Server for all other projects
 <br/>
 - Nginx on EC2 forwarded traffic to Home Server
 <br/>
 - Cost-effective but faced reliability challenges
</p>
<p>
 <strong>
  Phase 3: Single EC2 Server (Aug 2023)
 </strong>
 <br/>
 - Consolidated all projects to single EC2 instance
 <br/>
 - Started with t2.medium (~$40/month)
 <br/>
 - Optimized to t2.small (~$15/month)
 <br/>
 - Better reliability, higher costs
</p>
<p>
 <strong>
  Phase 4: Hostinger VPS (Jan 2024)
 </strong>
 <br/>
 - Migrated to Hostinger VPS for cost optimization
 <br/>
 - Better pricing than EC2
 <br/>
 - Good balance of cost and reliability
</p>
<p>
 <strong>
  Phase 5: Home Server (Current - 2026)
 </strong>
 <br/>
 - Back to Home Server with improved setup
 <br/>
 - Leveraging lessons learned from previous attempts
 <br/>
 - Modern infrastructure with Kubernetes, proper monitoring
 <br/>
 - Significant cost savings with better reliability measures
</p>
<h3>
 Three Deployment Options
</h3>
<p>
 This documentation supports all three deployment strategies:
</p>
<h4>
 1. AWS EC2
</h4>
<p>
 <strong>
  Advantages:
 </strong>
 <br/>
 - High reliability (99.99% uptime SLA)
 <br/>
 - Global infrastructure and CDN integration
 <br/>
 - Scalable on demand
 <br/>
 - Professional-grade monitoring and support
 <br/>
 - No dependency on home internet/power
</p>
<p>
 <strong>
  Disadvantages:
 </strong>
 <br/>
 - Higher cost (~$15-40/month depending on instance)
 <br/>
 - Ongoing monthly expenses
 <br/>
 - Limited by instance size without additional cost
</p>
<p>
 <strong>
  Best For:
 </strong>
 <br/>
 - Production applications requiring maximum uptime
 <br/>
 - Applications needing global reach
 <br/>
 - When budget allows for convenience
 <br/>
 - Business-critical services
</p>
<h4>
 2. Hostinger VPS
</h4>
<p>
 <strong>
  Advantages:
 </strong>
 <br/>
 - Cost-effective (~$8-12/month)
 <br/>
 - Good performance for price
 <br/>
 - Managed infrastructure options
 <br/>
 - Reliable uptime
 <br/>
 - Easy scaling
</p>
<p>
 <strong>
  Disadvantages:
 </strong>
 <br/>
 - Still recurring monthly cost
 <br/>
 - Less control than EC2
 <br/>
 - Limited to Hostinger's infrastructure
</p>
<p>
 <strong>
  Best For:
 </strong>
 <br/>
 - Budget-conscious deployments
 <br/>
 - Personal projects requiring good uptime
 <br/>
 - When you want managed services at lower cost
 <br/>
 - Small to medium applications
</p>
<h4>
 3. Home Server
</h4>
<p>
 <strong>
  Advantages:
 </strong>
 <br/>
 -
 <strong>
  Zero recurring costs
 </strong>
 (only electricity)
 <br/>
 - Full hardware control and unlimited resources
 <br/>
 - Privacy and data sovereignty
 <br/>
 - Learning opportunity for infrastructure management
 <br/>
 - Can repurpose old laptops/desktops
 <br/>
 - Ideal for development and testing
</p>
<p>
 <strong>
  Disadvantages (and Mitigations):
 </strong>
 <br/>
 -
 <strong>
  ISP downtime
 </strong>
 ‚Üí Use UPS + mobile hotspot backup
 <br/>
 -
 <strong>
  Power cuts
 </strong>
 ‚Üí UPS with sufficient backup time
 <br/>
 -
 <strong>
  Weather issues
 </strong>
 ‚Üí Redundant internet connection
 <br/>
 -
 <strong>
  Hardware failure
 </strong>
 ‚Üí Regular backups, spare parts
 <br/>
 -
 <strong>
  Remote troubleshooting
 </strong>
 ‚Üí Proper monitoring, remote access tools
 <br/>
 -
 <strong>
  Dynamic IP
 </strong>
 ‚Üí Dynamic DNS services (afraid.org, No-IP)
</p>
<p>
 <strong>
  Best For:
 </strong>
 <br/>
 - Personal projects and portfolios
 <br/>
 - Development and testing environments
 <br/>
 - Learning DevOps and system administration
 <br/>
 - When you have reliable power and internet
 <br/>
 - Cost-sensitive deployments
</p>
<h3>
 Current Architecture (Home Server)
</h3>
<pre><code>Internet
   ‚îÇ
   ‚îú‚îÄ arpansahu.space (Home Server with Dynamic DNS)
   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îî‚îÄ Nginx (Port 443) - TLS Termination
   ‚îÇ        ‚îÇ
   ‚îÇ        ‚îú‚îÄ Jenkins (CI/CD)
   ‚îÇ        ‚îú‚îÄ Portainer (Docker Management)
   ‚îÇ        ‚îú‚îÄ PgAdmin (Database Admin)
   ‚îÇ        ‚îú‚îÄ RabbitMQ (Message Queue)
   ‚îÇ        ‚îú‚îÄ Redis Commander (Cache Admin)
   ‚îÇ        ‚îú‚îÄ MinIO (Object Storage)
   ‚îÇ        ‚îÇ
   ‚îÇ        ‚îî‚îÄ Kubernetes (k3s)
   ‚îÇ             ‚îú‚îÄ Django Applications
   ‚îÇ             ‚îú‚îÄ PostgreSQL Databases
   ‚îÇ             ‚îî‚îÄ Redis Instances
</code></pre>
<h3>
 Home Server Improvements (2026)
</h3>
<p>
 Lessons learned from 2022-2023 experience have been addressed:
</p>
<p>
 <strong>
  Reliability Enhancements:
 </strong>
 <br/>
 1. UPS with 2-4 hour backup capacity
 <br/>
 2. Redundant internet (primary broadband + 4G backup)
 <br/>
 3. Hardware RAID for data redundancy
 <br/>
 4. Automated monitoring and alerting
 <br/>
 5. Remote management tools (SSH, VPN)
 <br/>
 6. Automated backup to cloud storage
</p>
<p>
 <strong>
  Monitoring Stack:
 </strong>
 <br/>
 - Uptime monitoring (UptimeRobot, Healthchecks.io)
 <br/>
 - System monitoring (Prometheus + Grafana)
 <br/>
 - Log aggregation (Loki)
 <br/>
 - Alert notifications (Email, Telegram)
</p>
<p>
 <strong>
  Infrastructure:
 </strong>
 <br/>
 - Kubernetes (k3s) for orchestration
 <br/>
 - Docker for containerization
 <br/>
 - PM2 for process management
 <br/>
 - Nginx for reverse proxy and HTTPS
 <br/>
 - Automated deployments via Jenkins
</p>
<h3>
 Comparison Matrix
</h3>
<table>
 <thead>
  <tr>
   <th>
    Feature
   </th>
   <th>
    EC2
   </th>
   <th>
    Hostinger VPS
   </th>
   <th>
    Home Server
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    Monthly Cost
   </td>
   <td>
    $15-40
   </td>
   <td>
    $8-12
   </td>
   <td>
    ~$5 (electricity)
   </td>
  </tr>
  <tr>
   <td>
    Uptime SLA
   </td>
   <td>
    99.99%
   </td>
   <td>
    99.9%
   </td>
   <td>
    95-98% (with improvements)
   </td>
  </tr>
  <tr>
   <td>
    Setup Time
   </td>
   <td>
    Medium
   </td>
   <td>
    Easy
   </td>
   <td>
    Complex
   </td>
  </tr>
  <tr>
   <td>
    Scalability
   </td>
   <td>
    Excellent
   </td>
   <td>
    Good
   </td>
   <td>
    Limited by hardware
   </td>
  </tr>
  <tr>
   <td>
    Control
   </td>
   <td>
    High
   </td>
   <td>
    Medium
   </td>
   <td>
    Full
   </td>
  </tr>
  <tr>
   <td>
    Learning Value
   </td>
   <td>
    Medium
   </td>
   <td>
    Low
   </td>
   <td>
    Very High
   </td>
  </tr>
  <tr>
   <td>
    Remote Access
   </td>
   <td>
    Built-in
   </td>
   <td>
    Built-in
   </td>
   <td>
    Requires setup
   </td>
  </tr>
  <tr>
   <td>
    Backup
   </td>
   <td>
    Easy
   </td>
   <td>
    Easy
   </td>
   <td>
    Manual setup needed
   </td>
  </tr>
  <tr>
   <td>
    Privacy
   </td>
   <td>
    Low
   </td>
   <td>
    Medium
   </td>
   <td>
    Complete
   </td>
  </tr>
 </tbody>
</table>
<h3>
 Recommended Setup by Use Case
</h3>
<p>
 <strong>
  For Production/Business:
 </strong>
 <br/>
 - Use EC2 or Hostinger VPS
 <br/>
 - Follow all documentation except home server specific sections
 <br/>
 - Implement proper backup and disaster recovery
</p>
<p>
 <strong>
  For Personal Projects:
 </strong>
 <br/>
 - Home Server is ideal
 <br/>
 - Follow complete documentation including home server setup
 <br/>
 - Implement monitoring and backup strategies
</p>
<p>
 <strong>
  For Learning:
 </strong>
 <br/>
 - Home Server provides maximum learning opportunity
 <br/>
 - Experiment with all services and configurations
 <br/>
 - Break things and fix them safely
</p>
<h3>
 Infrastructure Components
</h3>
<p>
 All deployment options use the same software stack:
</p>
<p>
 <strong>
  Core Services:
 </strong>
 <br/>
 - Docker Engine with docker-compose-plugin
 <br/>
 - Nginx with wildcard SSL (acme.sh)
 <br/>
 - Kubernetes (k3s) without Traefik
 <br/>
 - Portainer for container management
</p>
<p>
 <strong>
  Application Services:
 </strong>
 <br/>
 - PostgreSQL 16 with SCRAM-SHA-256
 <br/>
 - Redis for caching
 <br/>
 - RabbitMQ for message queuing
 <br/>
 - Kafka with KRaft mode for event streaming
 <br/>
 - MinIO for object storage
 <br/>
 - PgAdmin for database administration
 <br/>
 - AKHQ for Kafka management
</p>
<p>
 <strong>
  DevOps Tools:
 </strong>
 <br/>
 - Jenkins for CI/CD
 <br/>
 - Git for version control
 <br/>
 - PM2 for process management
</p>
<p>
 <strong>
  Monitoring (Home Server):
 </strong>
 <br/>
 - System metrics and health checks
 <br/>
 - Automated alerting
 <br/>
 - Log aggregation
</p>
<h3>
 Documentation Structure
</h3>
<p>
 This repository provides step-by-step guides for:
</p>
<ol>
 <li>
  <a href="home_server/steps/00-ssh-key-setup.md">
   SSH Key Setup (Do This First!)
  </a>
  ‚Üê
  <strong>
   IMPORTANT
  </strong>
 </li>
 <li>
  <a href="INSTALLATION_ORDER.md">
   Installation Order & Dependencies
  </a>
  ‚Üê
  <strong>
   Start Here
  </strong>
 </li>
 <li>
  <a href="01-docker/docker_installation.md">
   Docker Installation
  </a>
 </li>
 <li>
  <a href="02-nginx/README.md">
   Nginx Setup (HTTP + HTTPS)
  </a>
 </li>
 <li>
  <a href="kubernetes_k3s/deployment.md">
   Kubernetes with Portainer
  </a>
 </li>
 <li>
  <a href="03-postgres/README.md">
   PostgreSQL Setup
  </a>
 </li>
 <li>
  <a href="04-redis/README.md">
   Redis Setup
  </a>
 </li>
 <li>
  <a href="07-redis_commander/README.md">
   Redis Commander
  </a>
 </li>
 <li>
  <a href="09-rabbitmq/README.md">
   RabbitMQ
  </a>
 </li>
 <li>
  <a href="10-kafka/Kafka.md">
   Kafka with KRaft
  </a>
 </li>
 <li>
  <a href="10-kafka/AKHQ.md">
   AKHQ (Kafka UI)
  </a>
 </li>
 <li>
  <a href="05-portainer/README.md">
   Portainer
  </a>
 </li>
 <li>
  <a href="06-pgadmin/README.md">
   PgAdmin
  </a>
 </li>
 <li>
  <a href="08-minio/README.md">
   MinIO Object Storage
  </a>
 </li>
 <li>
  <a href="12-jenkins/Jenkins.md">
   Jenkins CI/CD
  </a>
 </li>
 <li>
  <a href="11-harbor/harbor.md">
   Harbor Private Registry
  </a>
 </li>
 <li>
  <a href="home_server/README.md">
   Home Server Setup
  </a>
  ‚Üê Complete laptop-to-server guide
 </li>
 <li>
  <a href="ssh-web-terminal/README.md">
   SSH Web Terminal
  </a>
  ‚Üê Browser-based SSH access
 </li>
 <li>
  <a href="airtel/README.md">
   Airtel Router Admin
  </a>
  ‚Üê Secure router management
 </li>
</ol>
<h3>
 Getting Started
</h3>
<p>
 <strong>
  For EC2/VPS Deployment:
 </strong>
 <br/>
 1. Provision Ubuntu 22.04 server
 <br/>
 2. Follow
 <a href="INSTALLATION_ORDER.md">
  Installation Order Guide
 </a>
 <br/>
 3. Install Docker and Docker Compose
 <br/>
 4. Set up Nginx with HTTPS
 <br/>
 5. Install required services in sequence
</p>
<p>
 <strong>
  For Home Server Deployment:
 </strong>
 <br/>
 1. Follow
 <a href="home_server/README.md">
  Home Server Setup Guide
 </a>
 <br/>
 2. Install Ubuntu Server 22.04
 <br/>
 3. Configure UPS and backup internet
 <br/>
 4. Follow
 <a href="INSTALLATION_ORDER.md">
  Installation Order Guide
 </a>
 <br/>
 5. Set up monitoring and alerting
</p>
<p>
 All projects are dockerized and run on predefined ports specified in Dockerfile and docker-compose.yml.
</p>
<h3>
 Architecture Diagrams
</h3>
<p>
 <strong>
  Historical Setup (2022-2023):
 </strong>
 <br/>
 <img alt="EC2 and Home Server Hybrid" class="d-block w-100" src="https://raw.githubusercontent.com/arpansahu/common_readme/main/Images/ec2_and_home_server.png"/>
</p>
<p>
 <strong>
  Single Server Setup (2023-2024):
 </strong>
 <br/>
 <img alt="Single Server Configuration" class="d-block w-100" src="https://raw.githubusercontent.com/arpansahu/common_readme/main/Images/One%20Server%20Configuration%20for%20arpanahuone.png"/>
</p>
<p>
 <strong>
  Current Home Server Setup (2026):
 </strong>
 <br/>
 - Updated architecture with Kubernetes
 <br/>
 - Improved reliability and monitoring
 <br/>
 - All services behind Nginx with HTTPS
 <br/>
 - Dynamic DNS for domain management
</p>
<h3>
 My Current Setup
</h3>
<p>
 As of January 2026, I'm running a home server setup with:
 <br/>
 - Repurposed laptop as primary server
 <br/>
 - Ubuntu 22.04 LTS Server
 <br/>
 - 16GB RAM, 500GB SSD
 <br/>
 - UPS backup power
 <br/>
 - Dual internet connections (broadband + 4G)
 <br/>
 - All services accessible via arpansahu.space
 <br/>
 - Automated backups to cloud storage
</p>
<p>
 Live projects: https://arpansahu.me/projects
</p>
<h3>
 Next Steps
</h3>
<p>
 Choose your deployment strategy and follow the relevant guides:
 <br/>
 -
 <strong>
  EC2/VPS
 </strong>
 : Skip home server setup, start with Docker installation
 <br/>
 -
 <strong>
  Home Server
 </strong>
 : Start with
 <a href="home_server_setup.md">
  Home Server Setup Guide
 </a>
</p>
<p>
 All guides are production-tested and follow the same format for consistency.
</p>
<p>
 <strong>
  Note:
 </strong>
 For complete setup guides:
 <br/>
 -
 <strong>
  Home Server
 </strong>
 :
 <a href="https://github.com/arpansahu/common_readme/blob/main/AWS%20Deployment/home_server/README.md">
  Home Server Setup Guide
 </a>
 <br/>
 -
 <strong>
  Installation Order
 </strong>
 :
 <a href="https://github.com/arpansahu/common_readme/blob/main/AWS%20Deployment/INSTALLATION_ORDER.md">
  Installation Order Guide
 </a>
 <br/>
 -
 <strong>
  SSH Web Terminal
 </strong>
 :
 <a href="https://github.com/arpansahu/common_readme/blob/main/AWS%20Deployment/ssh-web-terminal/README.md">
  SSH Web Terminal Setup
 </a>
 <br/>
 -
 <strong>
  Airtel Router Access
 </strong>
 :
 <a href="https://github.com/arpansahu/common_readme/blob/main/AWS%20Deployment/airtel/README.md">
  Airtel Router Admin Setup
 </a>
</p>
<h3>
 Step 1: Dockerize
</h3>
<h2>
 üê≥ Docker Engine Installation (Updated for 2026)
</h2>
<p>
 <strong>
  Reference:
 </strong>
 <a href="https://docs.docker.com/engine/install/ubuntu/">
  https://docs.docker.com/engine/install/ubuntu/
 </a>
</p>
<p>
 <strong>
  Current Server Versions:
 </strong>
 <br/>
 - Docker: 29.2.0 (February 2026)
 <br/>
 - Docker Compose: v5.0.2 (plugin, not standalone)
</p>
<hr/>
<h3>
 1Ô∏è‚É£ Prerequisites & Repository Setup
</h3>
<h4>
 1.1 Update apt and install required packages
</h4>
<pre><code class="language-bash">sudo apt-get update
sudo apt-get install -y \
  ca-certificates \
  curl \
  gnupg \
  lsb-release
</code></pre>
<hr/>
<h4>
 1.2 Add Docker's official GPG key (modern keyring approach)
</h4>
<pre><code class="language-bash">sudo mkdir -p /etc/apt/keyrings

curl -fsSL https://download.docker.com/linux/ubuntu/gpg \
  | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# Important: avoid GPG permission issues
sudo chmod a+r /etc/apt/keyrings/docker.gpg
</code></pre>
<blockquote>
 <p>
  üîπ
  <strong>
   Why this matters:
  </strong>
  <br/>
  Earlier READMEs often skipped
  <code>
   chmod a+r
  </code>
  , which now causes GPG errors on newer Ubuntu versions.
 </p>
</blockquote>
<hr/>
<h4>
 1.3 Add Docker repository
</h4>
<pre><code class="language-bash">echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) stable&quot; \
| sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null
</code></pre>
<hr/>
<h3>
 2Ô∏è‚É£ Install Docker Engine
</h3>
<h4>
 2.1 Update package index
</h4>
<pre><code class="language-bash">sudo apt-get update
</code></pre>
<blockquote>
 <p>
  If you still see GPG errors:
 </p>
</blockquote>
<pre><code class="language-bash">sudo chmod a+r /etc/apt/keyrings/docker.gpg
sudo apt-get update
</code></pre>
<hr/>
<h4>
 2.2 Install Docker Engine + Compose plugin
</h4>
<pre><code class="language-bash">sudo apt-get install -y \
  docker-ce \
  docker-ce-cli \
  containerd.io \
  docker-compose-plugin
</code></pre>
<p>
 ‚úÖ
 <strong>
  Change vs old README:
 </strong>
</p>
<ul>
 <li>
  <code>
   docker-compose-plugin
  </code>
  replaces old
  <code>
   docker-compose
  </code>
  binary
 </li>
 <li>
  Use
  <code>
   docker compose
  </code>
  (space) instead of
  <code>
   docker-compose
  </code>
  (hyphen)
 </li>
</ul>
<hr/>
<h3>
 3Ô∏è‚É£ Start & Enable Docker
</h3>
<pre><code class="language-bash">sudo systemctl start docker
sudo systemctl enable docker
</code></pre>
<hr/>
<h3>
 4Ô∏è‚É£ Verify Installation
</h3>
<pre><code class="language-bash">sudo docker run hello-world
</code></pre>
<p>
 ‚úÖ If you see
 <strong>
  "Hello from Docker!"
 </strong>
 , Docker is installed correctly.
</p>
<p>
 <strong>
  Verify versions:
 </strong>
</p>
<pre><code class="language-bash">docker --version
# Expected: Docker version 29.x or later

docker compose version
# Expected: Docker Compose version v5.x or later
</code></pre>
<p>
 <strong>
  Important:
 </strong>
 Notice
 <code>
  docker compose
 </code>
 (with space), NOT
 <code>
  docker-compose
 </code>
 (with hyphen). The old
 <code>
  docker-compose
 </code>
 standalone binary is deprecated and not installed.
</p>
<hr/>
<h3>
 5Ô∏è‚É£ (Recommended) Run Docker Without sudo
</h3>
<pre><code class="language-bash">sudo usermod -aG docker $USER
newgrp docker
</code></pre>
<p>
 Verify:
</p>
<pre><code class="language-bash">docker ps
</code></pre>
<hr/>
<h2>
 ‚úÖ Final Notes (Important Changes from Old Setup)
</h2>
<table>
 <thead>
  <tr>
   <th>
    Old Setup (Pre-2024)
   </th>
   <th>
    Current Setup (2026)
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <code>
     docker-compose
    </code>
    (hyphen)
   </td>
   <td>
    <code>
     docker compose
    </code>
    (space) -
    <strong>
     plugin
    </strong>
   </td>
  </tr>
  <tr>
   <td>
    Docker v24.x
   </td>
   <td>
    Docker v29.2.0
   </td>
  </tr>
  <tr>
   <td>
    Compose v2.23.x
   </td>
   <td>
    Compose v5.0.2
   </td>
  </tr>
  <tr>
   <td>
    No key permission fix
   </td>
   <td>
    Explicit
    <code>
     chmod a+r docker.gpg
    </code>
   </td>
  </tr>
  <tr>
   <td>
    Older install style
   </td>
   <td>
    Keyring-based (required now)
   </td>
  </tr>
  <tr>
   <td>
    Manual Compose install
   </td>
   <td>
    Bundled via plugin
   </td>
  </tr>
 </tbody>
</table>
<p>
 <strong>
  Critical:
 </strong>
 All docker-compose.yml files work with
 <code>
  docker compose
 </code>
 (space). Simply replace:
</p>
<pre><code class="language-bash"># Old way (deprecated):
docker-compose up -d

# New way (current):
docker compose up -d
</code></pre>
<hr/>
<h2>
 üìù Common Docker Compose Commands
</h2>
<pre><code class="language-bash"># Start services
docker compose up -d

# Stop services
docker compose down

# View logs
docker compose logs -f

# Restart services
docker compose restart

# Pull latest images
docker compose pull

# Check status
docker compose ps
</code></pre>
<hr/>
<h2>
 üîß Troubleshooting
</h2>
<h3>
 "docker compose: command not found"
</h3>
<p>
 This means
 <code>
  docker-compose-plugin
 </code>
 is not installed. Install it:
</p>
<pre><code class="language-bash">sudo apt-get install docker-compose-plugin
</code></pre>
<h3>
 Old docker-compose.yml files not working
</h3>
<p>
 All old
 <code>
  docker-compose
 </code>
 files are compatible with
 <code>
  docker compose
 </code>
 (plugin). No changes needed to YAML files, just change the command.
</p>
<hr/>
<h2>
 ‚úÖ Next Steps
</h2>
<p>
 After Docker installation, you can install:
 <br/>
 -
 <a href="../portainer/README.md">
  Portainer
 </a>
 - Docker management UI
 <br/>
 -
 <a href="../postgres/README.md">
  PostgreSQL
 </a>
 - Database server
 <br/>
 -
 <a href="../redis/README.md">
  Redis
 </a>
 - Cache server
 <br/>
 -
 <a href="../minio/README.md">
  MinIO
 </a>
 - Object storage
 <br/>
 -
 <a href="../harbor/README.md">
  Harbor
 </a>
 - Container registry
</p>
<p>
 See
 <a href="../INSTALLATION_ORDER.md">
  INSTALLATION_ORDER.md
 </a>
 for recommended sequence.
</p>
<p>
 Now in your Git Repository
</p>
<p>
 Create a file named Dockerfile with no extension and add following lines in it
</p>
<h3>
 Step 2: Private Docker Registry
</h3>
<h2>
 Harbor (Self-Hosted Private Docker Registry)
</h2>
<p>
 Harbor is an open-source container image registry that secures images with role-based access control, scans images for vulnerabilities, and signs images as trusted. It extends Docker Distribution by adding enterprise features like security, identity management, and image replication. This guide provides a complete, production-ready setup with Nginx reverse proxy.
</p>
<h3>
 Prerequisites
</h3>
<p>
 Before installing Harbor, ensure you have:
</p>
<ol>
 <li>
  Ubuntu Server 22.04 LTS
 </li>
 <li>
  Docker Engine installed (see docker_installation.md)
 </li>
 <li>
  Nginx with SSL certificates configured
 </li>
 <li>
  Domain name (example: harbor.arpansahu.space)
 </li>
 <li>
  Wildcard SSL certificate already issued (via acme.sh)
 </li>
 <li>
  Minimum 4GB RAM, 40GB disk space
 </li>
 <li>
  Root or sudo access
 </li>
</ol>
<h3>
 Architecture Overview
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (Port 443) - TLS Termination
        ‚îÇ
        ‚îî‚îÄ harbor.arpansahu.space
             ‚îÇ
             ‚îî‚îÄ Harbor Internal Nginx (localhost:8080)
                  ‚îÇ
                  ‚îú‚îÄ Harbor Core
                  ‚îú‚îÄ Harbor Registry
                  ‚îú‚îÄ Harbor Portal (Web UI)
                  ‚îú‚îÄ Trivy (Vulnerability Scanner)
                  ‚îú‚îÄ Notary (Image Signing)
                  ‚îî‚îÄ ChartMuseum (Helm Charts)
</code></pre>
<p>
 Key Principles:
 <br/>
 - Harbor runs on localhost only
 <br/>
 - System Nginx handles all external TLS
 <br/>
 - Harbor has its own internal Nginx
 <br/>
 - All data persisted in Docker volumes
 <br/>
 - Automatic restart via systemd
</p>
<h3>
 Why Harbor
</h3>
<p>
 <strong>
  Advantages:
 </strong>
 <br/>
 - Role-based access control (RBAC)
 <br/>
 - Vulnerability scanning with Trivy
 <br/>
 - Image signing and trust (Notary)
 <br/>
 - Helm chart repository
 <br/>
 - Image replication
 <br/>
 - Garbage collection
 <br/>
 - Web UI for management
 <br/>
 - Docker Hub proxy cache
</p>
<p>
 <strong>
  Use Cases:
 </strong>
 <br/>
 - Private Docker registry for organization
 <br/>
 - Secure image storage
 <br/>
 - Vulnerability assessment
 <br/>
 - Compliance and auditing
 <br/>
 - Multi-project isolation
 <br/>
 - Image lifecycle management
</p>
<h3>
 Part 1: Download and Extract Harbor
</h3>
<ol>
 <li>
  Download latest Harbor release
 </li>
</ol>
<pre><code class="language-bash">    cd /opt
    sudo wget https://github.com/goharbor/harbor/releases/download/v2.11.0/harbor-offline-installer-v2.11.0.tgz
</code></pre>
<pre><code>Check for latest version at: https://github.com/goharbor/harbor/releases
</code></pre>
<ol>
 <li>
  Extract Harbor installer
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -xzvf harbor-offline-installer-v2.11.0.tgz
    cd harbor
</code></pre>
<ol>
 <li>
  Verify extracted files
 </li>
</ol>
<pre><code class="language-bash">    ls -la
</code></pre>
<pre><code>Expected files:
- harbor.yml.tmpl
- install.sh
- prepare
- common.sh
- harbor.*.tar.gz (images)
</code></pre>
<h3>
 Part 2: Configure Harbor
</h3>
<ol>
 <li>
  Copy template configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo cp harbor.yml.tmpl harbor.yml
</code></pre>
<ol>
 <li>
  Edit Harbor configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano harbor.yml
</code></pre>
<ol>
 <li>
  <p>
   Configure essential settings
  </p>
  <p>
   Find and modify these lines:
  </p>
 </li>
</ol>
<pre><code class="language-yaml">    # Hostname for Harbor
    hostname: harbor.arpansahu.space

    # HTTP settings (used for internal communication)
    http:
      port: 8080

    # HTTPS settings (disabled - Nginx handles this)
    # Comment out or remove the https section completely
    # https:
    #   port: 443
    #   certificate: /path/to/cert
    #   private_key: /path/to/key

    # Harbor admin password
    harbor_admin_password: YourStrongPasswordHere

    # Database settings (PostgreSQL)
    database:
      password: ChangeDatabasePassword
      max_idle_conns: 100
      max_open_conns: 900

    # Data volume location
    data_volume: /data

    # Trivy (vulnerability scanner)
    trivy:
      ignore_unfixed: false
      skip_update: false
      offline_scan: false
      insecure: false

    # Job service
    jobservice:
      max_job_workers: 10

    # Notification webhook job
    notification:
      webhook_job_max_retry: 3

    # Log settings
    log:
      level: info
      local:
        rotate_count: 50
        rotate_size: 200M
        location: /var/log/harbor
</code></pre>
<pre><code>Important changes:
- Set `hostname` to your domain
- Set `http.port` to 8080 (internal)
- Comment out entire `https` section
- Change `harbor_admin_password`
- Change `database.password`
- Keep `data_volume: /data` for persistence
</code></pre>
<ol>
 <li>
  <p>
   Save and exit
  </p>
  <p>
   In nano:
   <code>
    Ctrl + O
   </code>
   ,
   <code>
    Enter
   </code>
   ,
   <code>
    Ctrl + X
   </code>
  </p>
 </li>
</ol>
<h3>
 Part 3: Install Harbor
</h3>
<ol>
 <li>
  Run Harbor installer with all components
 </li>
</ol>
<pre><code class="language-bash">    sudo ./install.sh --with-notary --with-trivy --with-chartmuseum
</code></pre>
<pre><code>This will:
- Load Harbor Docker images
- Generate docker-compose.yml
- Create necessary directories
- Start all Harbor services

Installation takes 5-10 minutes depending on system.
</code></pre>
<ol>
 <li>
  Verify installation
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose ps
</code></pre>
<pre><code>Expected services (all should be &quot;Up&quot;):
- harbor-core
- harbor-db (PostgreSQL)
- harbor-jobservice
- harbor-log
- harbor-portal (Web UI)
- nginx (Harbor&#x27;s internal)
- redis
- registry
- registryctl
- trivy-adapter
- notary-server
- notary-signer
- chartmuseum
</code></pre>
<ol>
 <li>
  Check Harbor logs
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose logs -f
</code></pre>
<pre><code>Press `Ctrl + C` to exit logs.
</code></pre>
<h3>
 Part 4: Configure System Nginx
</h3>
<ol>
 <li>
  Edit Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/nginx/sites-available/services
</code></pre>
<ol>
 <li>
  Add Harbor server block
 </li>
</ol>
<pre><code class="language-nginx">    # Harbor Registry - HTTP ‚Üí HTTPS
    server {
        listen 80;
        listen [::]:80;
        server_name harbor.arpansahu.space;
        return 301 https://$host$request_uri;
    }

    # Harbor Registry - HTTPS
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name harbor.arpansahu.space;

        ssl_certificate     /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;

        location / {
            # Allow large image uploads (2GB recommended, 0 for unlimited)
            # Note: Set to at least 2G for typical Docker images
            client_max_body_size 2G;

            proxy_pass http://127.0.0.1:8080;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;

            # WebSocket support
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection &quot;upgrade&quot;;

            # Timeouts for large image pushes
            proxy_connect_timeout 300;
            proxy_send_timeout 300;
            proxy_read_timeout 300;
        }
    }
</code></pre>
<ol>
 <li>
  Test Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nginx -t
</code></pre>
<ol>
 <li>
  Reload Nginx
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl reload nginx
</code></pre>
<h3>
 Part 5: Configure Auto-Start with Systemd
</h3>
<p>
 Harbor needs to start automatically after reboot. Docker Compose alone doesn't provide this.
</p>
<ol>
 <li>
  Create systemd service file
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/systemd/system/harbor.service
</code></pre>
<ol>
 <li>
  Add service configuration
 </li>
</ol>
<pre><code class="language-bash">    [Unit]
    Description=Harbor Container Registry
    After=docker.service
    Requires=docker.service

    [Service]
    Type=oneshot
    RemainAfterExit=yes
    WorkingDirectory=/opt/harbor
    ExecStart=/usr/bin/docker compose up -d
    ExecStop=/usr/bin/docker compose down
    Restart=on-failure
    RestartSec=10

    [Install]
    WantedBy=multi-user.target
</code></pre>
<ol>
 <li>
  Reload systemd daemon
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl daemon-reload
</code></pre>
<ol>
 <li>
  Enable Harbor service
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl enable harbor
</code></pre>
<ol>
 <li>
  Verify service status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status harbor
</code></pre>
<pre><code>Expected: Loaded and active
</code></pre>
<h3>
 Part 6: Configure Firewall and Port Forwarding
</h3>
<ol>
 <li>
  Configure UFW firewall
 </li>
</ol>
<pre><code class="language-bash">    # Allow HTTP/HTTPS (if not already allowed)
    sudo ufw allow 80/tcp
    sudo ufw allow 443/tcp

    # Block direct access to Harbor port
    sudo ufw deny 8080/tcp

    # Reload firewall
    sudo ufw reload
</code></pre>
<ol>
 <li>
  <p>
   Configure router port forwarding
  </p>
  <p>
   Access router admin: https://airtel.arpansahu.space (or http://192.168.1.1:81)
  </p>
  <p>
   Add port forwarding rules:
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Service
     </th>
     <th>
      External Port
     </th>
     <th>
      Internal IP
     </th>
     <th>
      Internal Port
     </th>
     <th>
      Protocol
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      Harbor HTTP
     </td>
     <td>
      80
     </td>
     <td>
      192.168.1.200
     </td>
     <td>
      80
     </td>
     <td>
      TCP
     </td>
    </tr>
    <tr>
     <td>
      Harbor HTTPS
     </td>
     <td>
      443
     </td>
     <td>
      192.168.1.200
     </td>
     <td>
      443
     </td>
     <td>
      TCP
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   Note: Do NOT forward port 8080 (Harbor internal port).
  </p>
 </li>
</ol>
<h3>
 Part 7: Test Harbor Installation
</h3>
<ol>
 <li>
  Check all containers are running
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose ps
</code></pre>
<pre><code>All should show &quot;Up&quot; status.
</code></pre>
<ol>
 <li>
  Test local access
 </li>
</ol>
<pre><code class="language-bash">    curl -I http://127.0.0.1:8080
</code></pre>
<pre><code>Expected: HTTP 200 or 301
</code></pre>
<ol>
 <li>
  Test external HTTPS access
 </li>
</ol>
<pre><code class="language-bash">    curl -I https://harbor.arpansahu.space
</code></pre>
<pre><code>Expected: HTTP 200
</code></pre>
<ol>
 <li>
  <p>
   Access Harbor Web UI
  </p>
  <p>
   Go to: https://harbor.arpansahu.space
  </p>
 </li>
 <li>
  <p>
   Login with admin credentials
  </p>
  <ul>
   <li>
    Username:
    <code>
     admin
    </code>
   </li>
   <li>
    Password: (from harbor.yml harbor_admin_password)
   </li>
  </ul>
 </li>
</ol>
<h3>
 Part 8: Initial Harbor Configuration
</h3>
<ol>
 <li>
  <p>
   Change admin password
  </p>
  <ul>
   <li>
    Click admin (top right) ‚Üí Change Password
   </li>
   <li>
    Set strong password
   </li>
   <li>
    Save
   </li>
  </ul>
 </li>
 <li>
  <p>
   Create project
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí New Project
   </li>
   <li>
    Project Name:
    <code>
     library
    </code>
    (default) or custom name
   </li>
   <li>
    Access Level: Private (recommended)
   </li>
   <li>
    Click: OK
   </li>
  </ul>
 </li>
 <li>
  <p>
   Create robot account for CI/CD
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Robot Accounts
   </li>
   <li>
    Click: New Robot Account
   </li>
   <li>
    Name:
    <code>
     ci-bot
    </code>
   </li>
   <li>
    Expiration: Never (or set expiry)
   </li>
   <li>
    Permissions: Push Artifact, Pull Artifact
   </li>
   <li>
    Click: Add
   </li>
   <li>
    Save token securely (shown only once)
   </li>
  </ul>
 </li>
</ol>
<h3>
 Part 9: Using Harbor as Docker Registry
</h3>
<h4>
 Login to Harbor
</h4>
<ol>
 <li>
  Login from Docker client
 </li>
</ol>
<pre><code class="language-bash">    docker login harbor.arpansahu.space
</code></pre>
<pre><code>Enter:
- Username: `admin` (or your username)
- Password: (your Harbor password)

Expected: Login Succeeded
</code></pre>
<ol>
 <li>
  Login with robot account (for CI/CD)
 </li>
</ol>
<pre><code class="language-bash">    docker login harbor.arpansahu.space -u robot$ci-bot -p YOUR_ROBOT_TOKEN
</code></pre>
<h4>
 Push Images to Harbor
</h4>
<ol>
 <li>
  Tag existing image
 </li>
</ol>
<pre><code class="language-bash">    docker tag nginx:latest harbor.arpansahu.space/library/nginx:latest
</code></pre>
<pre><code>Format: `harbor.domain.com/project/image:tag`
</code></pre>
<ol>
 <li>
  Push image to Harbor
 </li>
</ol>
<pre><code class="language-bash">    docker push harbor.arpansahu.space/library/nginx:latest
</code></pre>
<ol>
 <li>
  <p>
   Verify in Harbor UI
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Repositories
   </li>
   <li>
    You should see: nginx repository
   </li>
  </ul>
 </li>
</ol>
<h4>
 Pull Images from Harbor
</h4>
<ol>
 <li>
  Pull image from Harbor
 </li>
</ol>
<pre><code class="language-bash">    docker pull harbor.arpansahu.space/library/nginx:latest
</code></pre>
<ol>
 <li>
  Use in docker-compose.yml
 </li>
</ol>
<pre><code class="language-yaml">    services:
      web:
        image: harbor.arpansahu.space/library/nginx:latest
</code></pre>
<h3>
 Part 10: Configure Image Retention Policy
</h3>
<p>
 Retention policies automatically delete old images to save space.
</p>
<ol>
 <li>
  <p>
   Navigate to project
  </p>
  <ul>
   <li>
    Projects ‚Üí library ‚Üí Policy
   </li>
  </ul>
 </li>
 <li>
  <p>
   Add retention rule
  </p>
  <p>
   Click: Add Rule
  </p>
  <p>
   Configure:
   <br/>
   -
   <strong>
    Repositories
   </strong>
   : matching
   <code>
    **
   </code>
   (all repositories)
   <br/>
   -
   <strong>
    By artifact count
   </strong>
   : Retain the most recently pulled
   <code>
    3
   </code>
   artifacts
   <br/>
   -
   <strong>
    Tags
   </strong>
   : matching
   <code>
    **
   </code>
   (all tags)
   <br/>
   -
   <strong>
    Untagged artifacts
   </strong>
   : ‚úì Checked (delete untagged)
  </p>
  <p>
   This keeps last 3 pulled images and deletes others.
  </p>
  <p>
   <img alt="Add Retention Rule" class="d-block w-100" src="https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/harbor/retention_rule_add.png"/>
  </p>
 </li>
 <li>
  <p>
   Schedule retention policy
  </p>
  <p>
   Click: Add Retention Rule ‚Üí Schedule
  </p>
  <p>
   Configure schedule:
   <br/>
   -
   <strong>
    Type
   </strong>
   : Daily / Weekly / Monthly
   <br/>
   -
   <strong>
    Time
   </strong>
   : 02:00 AM (off-peak)
   <br/>
   -
   <strong>
    Cron
   </strong>
   :
   <code>
    0 2 * * *
   </code>
   (2 AM daily)
  </p>
  <p>
   Click: Save
  </p>
  <p>
   <img alt="Retention Rule Schedule" class="d-block w-100" src="https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/harbor/retention_rule_schedule.png"/>
  </p>
 </li>
 <li>
  <p>
   Test retention policy
  </p>
  <p>
   Click: Dry Run
  </p>
  <p>
   This shows what would be deleted without actually deleting.
  </p>
 </li>
</ol>
<h3>
 Part 11: Enable Vulnerability Scanning
</h3>
<p>
 Harbor uses Trivy to scan images for vulnerabilities.
</p>
<ol>
 <li>
  <p>
   Configure automatic scanning
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Configuration
   </li>
   <li>
    Enable: Automatically scan images on push
   </li>
   <li>
    Click: Save
   </li>
  </ul>
 </li>
 <li>
  <p>
   Manual scan existing image
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Repositories ‚Üí nginx
   </li>
   <li>
    Select tag: latest
   </li>
   <li>
    Click: Scan
   </li>
  </ul>
 </li>
 <li>
  <p>
   View scan results
  </p>
  <ul>
   <li>
    Click on tag
   </li>
   <li>
    View: Vulnerabilities tab
   </li>
   <li>
    See: Critical, High, Medium, Low vulnerabilities
   </li>
  </ul>
 </li>
 <li>
  <p>
   Set CVE allowlist (optional)
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Configuration
   </li>
   <li>
    Add CVE IDs to allow despite vulnerabilities
   </li>
   <li>
    Use for false positives or accepted risks
   </li>
  </ul>
 </li>
</ol>
<h3>
 Managing Harbor Service
</h3>
<ol>
 <li>
  Check Harbor status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status harbor
</code></pre>
<ol>
 <li>
  Stop Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop harbor
</code></pre>
<pre><code>or
</code></pre>
<pre><code class="language-bash">    cd /opt/harbor
    sudo docker compose down
</code></pre>
<ol>
 <li>
  Start Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start harbor
</code></pre>
<pre><code>or
</code></pre>
<pre><code class="language-bash">    cd /opt/harbor
    sudo docker compose up -d
</code></pre>
<ol>
 <li>
  Restart Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl restart harbor
</code></pre>
<ol>
 <li>
  View Harbor logs
 </li>
</ol>
<pre><code class="language-bash">    cd /opt/harbor
    sudo docker compose logs -f
</code></pre>
<ol>
 <li>
  View specific service logs
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose logs -f harbor-core
</code></pre>
<h3>
 Backup and Restore
</h3>
<ol>
 <li>
  Backup Harbor data
 </li>
</ol>
<pre><code class="language-bash">    # Stop Harbor
    sudo systemctl stop harbor

    # Backup data directory
    sudo tar -czf harbor-data-backup-$(date +%Y%m%d).tar.gz /data

    # Backup configuration
    sudo cp /opt/harbor/harbor.yml /backup/harbor-config-$(date +%Y%m%d).yml

    # Backup database
    sudo docker exec harbor-db pg_dumpall -U postgres &gt; harbor-db-backup-$(date +%Y%m%d).sql

    # Start Harbor
    sudo systemctl start harbor
</code></pre>
<ol>
 <li>
  Restore Harbor data
 </li>
</ol>
<pre><code class="language-bash">    # Stop Harbor
    sudo systemctl stop harbor

    # Restore data directory
    sudo tar -xzf harbor-data-backup-YYYYMMDD.tar.gz -C /

    # Restore configuration
    sudo cp /backup/harbor-config-YYYYMMDD.yml /opt/harbor/harbor.yml

    # Restore database
    sudo docker exec -i harbor-db psql -U postgres &lt; harbor-db-backup-YYYYMMDD.sql

    # Start Harbor
    sudo systemctl start harbor
</code></pre>
<h3>
 Common Issues and Fixes
</h3>
<ol>
 <li>
  <p>
   Harbor containers not starting
  </p>
  <p>
   Cause: Port conflict or insufficient resources
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check if port 8080 is in use
    sudo ss -tulnp | grep 8080

    # Check Docker logs
    cd /opt/harbor
    sudo docker compose logs

    # Check system resources
    free -h
    df -h
</code></pre>
<ol>
 <li>
  <p>
   Cannot login to Harbor
  </p>
  <p>
   Cause: Wrong credentials or database issue
  </p>
  <p>
   Fix:
  </p>
  <ul>
   <li>
    Verify admin password in harbor.yml
   </li>
   <li>
    Reset admin password:
   </li>
  </ul>
 </li>
</ol>
<pre><code class="language-bash">      cd /opt/harbor
      sudo docker compose exec harbor-core harbor-core password-reset
</code></pre>
<ol>
 <li>
  <p>
   Image push fails
  </p>
  <p>
   Cause: Storage full or permission issues
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check disk space
    df -h /data

    # Check Harbor logs
    sudo docker compose logs -f registry

    # Check data directory permissions
    sudo ls -la /data
</code></pre>
<ol>
 <li>
  <p>
   SSL certificate errors
  </p>
  <p>
   Cause: Nginx certificate misconfigured
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Verify certificate
    openssl x509 -in /etc/nginx/ssl/arpansahu.space/fullchain.pem -noout -dates

    # Check Nginx configuration
    sudo nginx -t

    # Reload Nginx
    sudo systemctl reload nginx
</code></pre>
<ol>
 <li>
  <p>
   Vulnerability scanning not working
  </p>
  <p>
   Cause: Trivy adapter not running or internet connectivity
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check Trivy adapter
    sudo docker compose ps trivy-adapter

    # Check Trivy logs
    sudo docker compose logs trivy-adapter

    # Update Trivy database manually
    sudo docker compose exec trivy-adapter /home/scanner/trivy --download-db-only
</code></pre>
<h3>
 Security Best Practices
</h3>
<ol>
 <li>
  <p>
   Use strong passwords
  </p>
  <ul>
   <li>
    Admin password: minimum 16 characters
   </li>
   <li>
    Database password: minimum 16 characters
   </li>
   <li>
    Robot account tokens: treat as secrets
   </li>
  </ul>
 </li>
 <li>
  <p>
   Enable HTTPS only
  </p>
  <ul>
   <li>
    Never use HTTP for Harbor
   </li>
   <li>
    Always proxy through Nginx with TLS
   </li>
  </ul>
 </li>
 <li>
  <p>
   Implement RBAC
  </p>
  <ul>
   <li>
    Create projects with limited access
   </li>
   <li>
    Use robot accounts for automation
   </li>
   <li>
    Assign minimal required permissions
   </li>
  </ul>
 </li>
 <li>
  <p>
   Enable vulnerability scanning
  </p>
  <ul>
   <li>
    Automatically scan on push
   </li>
   <li>
    Set CVE severity thresholds
   </li>
   <li>
    Block deployment of vulnerable images
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure image retention
  </p>
  <ul>
   <li>
    Automatically delete old images
   </li>
   <li>
    Keep only necessary image versions
   </li>
   <li>
    Schedule during off-peak hours
   </li>
  </ul>
 </li>
 <li>
  <p>
   Regular backups
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Automate with cron
    sudo crontab -e
</code></pre>
<pre><code>Add:
</code></pre>
<pre><code class="language-bash">    0 2 * * * /usr/local/bin/backup-harbor.sh
</code></pre>
<ol>
 <li>
  Monitor logs
 </li>
</ol>
<pre><code class="language-bash">    # Regular log review
    sudo docker compose logs --since 24h | grep ERROR
</code></pre>
<h3>
 Performance Optimization
</h3>
<ol>
 <li>
  <p>
   Configure garbage collection
  </p>
  <ul>
   <li>
    Go to: Administration ‚Üí Garbage Collection
   </li>
   <li>
    Schedule: Weekly at 2 AM
   </li>
   <li>
    This removes unreferenced image layers
   </li>
  </ul>
 </li>
 <li>
  <p>
   Optimize database
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Run vacuum on PostgreSQL
    sudo docker compose exec harbor-db vacuumdb -U postgres -d registry
</code></pre>
<ol>
 <li>
  <p>
   Configure resource limits
  </p>
  <p>
   Edit docker-compose.yml (auto-generated):
  </p>
 </li>
</ol>
<pre><code class="language-yaml">    services:
      registry:
        deploy:
          resources:
            limits:
              memory: 2G
            reservations:
              memory: 512M
</code></pre>
<ol>
 <li>
  <p>
   Enable Redis cache
  </p>
  <p>
   Harbor uses Redis by default for caching.
   <br/>
   Increase Redis memory if needed.
  </p>
 </li>
</ol>
<h3>
 Monitoring Harbor
</h3>
<ol>
 <li>
  Check Harbor health
 </li>
</ol>
<pre><code class="language-bash">    curl -k https://harbor.arpansahu.space/api/v2.0/health
</code></pre>
<ol>
 <li>
  Monitor Docker resources
 </li>
</ol>
<pre><code class="language-bash">    sudo docker stats
</code></pre>
<ol>
 <li>
  Check disk usage
 </li>
</ol>
<pre><code class="language-bash">    du -sh /data/*
</code></pre>
<ol>
 <li>
  View system logs
 </li>
</ol>
<pre><code class="language-bash">    sudo journalctl -u harbor -f
</code></pre>
<h3>
 Updating Harbor
</h3>
<ol>
 <li>
  <p>
   Backup current installation
  </p>
  <p>
   Follow backup procedure above.
  </p>
 </li>
 <li>
  <p>
   Download new Harbor version
  </p>
 </li>
</ol>
<pre><code class="language-bash">    cd /opt
    sudo wget https://github.com/goharbor/harbor/releases/download/vX.Y.Z/harbor-offline-installer-vX.Y.Z.tgz
</code></pre>
<ol>
 <li>
  Stop current Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop harbor
</code></pre>
<ol>
 <li>
  Extract new version
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -xzvf harbor-offline-installer-vX.Y.Z.tgz
    sudo mv harbor harbor-old
    sudo mv harbor-new harbor
</code></pre>
<ol>
 <li>
  Copy configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo cp harbor-old/harbor.yml harbor/harbor.yml
</code></pre>
<ol>
 <li>
  Run migration
 </li>
</ol>
<pre><code class="language-bash">    cd /opt/harbor
    sudo ./install.sh --with-notary --with-trivy --with-chartmuseum
</code></pre>
<ol>
 <li>
  Start Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start harbor
</code></pre>
<h3>
 Final Verification Checklist
</h3>
<p>
 Run these commands to verify Harbor is working:
</p>
<pre><code class="language-bash"># Check all containers
sudo docker compose ps

# Check systemd service
sudo systemctl status harbor

# Check local access
curl -I http://127.0.0.1:8080

# Check HTTPS access
curl -I https://harbor.arpansahu.space

# Check Nginx config
sudo nginx -t

# Check firewall
sudo ufw status | grep -E &#x27;(80|443)&#x27;

# Test Docker login
docker login harbor.arpansahu.space
</code></pre>
<p>
 Then test in browser:
 <br/>
 - Access: https://harbor.arpansahu.space
 <br/>
 - Login with admin credentials
 <br/>
 - Create test project
 <br/>
 - Push test image
 <br/>
 - Scan image for vulnerabilities
 <br/>
 - Verify retention policy configured
</p>
<h3>
 What This Setup Provides
</h3>
<p>
 After following this guide, you will have:
</p>
<ol>
 <li>
  Self-hosted private Docker registry
 </li>
 <li>
  HTTPS access via Nginx reverse proxy
 </li>
 <li>
  Automatic startup with systemd
 </li>
 <li>
  Vulnerability scanning with Trivy
 </li>
 <li>
  Image signing with Notary
 </li>
 <li>
  Helm chart repository
 </li>
 <li>
  Automatic image retention
 </li>
 <li>
  Web UI for management
 </li>
 <li>
  Robot accounts for CI/CD
 </li>
 <li>
  Production-ready configuration
 </li>
</ol>
<h3>
 Example Configuration Summary
</h3>
<table>
 <thead>
  <tr>
   <th>
    Component
   </th>
   <th>
    Value
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    Harbor URL
   </td>
   <td>
    https://harbor.arpansahu.space
   </td>
  </tr>
  <tr>
   <td>
    Internal Port
   </td>
   <td>
    8080 (localhost only)
   </td>
  </tr>
  <tr>
   <td>
    Admin User
   </td>
   <td>
    admin
   </td>
  </tr>
  <tr>
   <td>
    Default Project
   </td>
   <td>
    library
   </td>
  </tr>
  <tr>
   <td>
    Data Directory
   </td>
   <td>
    /data
   </td>
  </tr>
  <tr>
   <td>
    Config File
   </td>
   <td>
    /opt/harbor/harbor.yml
   </td>
  </tr>
  <tr>
   <td>
    Service File
   </td>
   <td>
    /etc/systemd/system/harbor.service
   </td>
  </tr>
 </tbody>
</table>
<h3>
 Architecture Summary
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (TLS Termination)
        ‚îÇ [Wildcard Certificate: *.arpansahu.space]
        ‚îÇ
        ‚îî‚îÄ harbor.arpansahu.space (Port 443 ‚Üí 8080)
             ‚îÇ
             ‚îî‚îÄ Harbor Stack (Docker Compose)
                  ‚îú‚îÄ Harbor Core (API + Logic)
                  ‚îú‚îÄ Harbor Portal (Web UI)
                  ‚îú‚îÄ Registry (Image Storage)
                  ‚îú‚îÄ PostgreSQL (Metadata)
                  ‚îú‚îÄ Redis (Cache)
                  ‚îú‚îÄ Trivy (Vulnerability Scanner)
                  ‚îú‚îÄ Notary (Image Signing)
                  ‚îî‚îÄ ChartMuseum (Helm Charts)
</code></pre>
<h3>
 Key Rules to Remember
</h3>
<ol>
 <li>
  Harbor internal port (8080) never exposed externally
 </li>
 <li>
  System Nginx handles all TLS termination
 </li>
 <li>
  Use systemd for automatic startup
 </li>
 <li>
  Robot accounts for CI/CD pipelines
 </li>
 <li>
  Configure retention to manage storage
 </li>
 <li>
  Enable vulnerability scanning on push
 </li>
 <li>
  Regular backups of /data directory
 </li>
 <li>
  Monitor disk usage in /data
 </li>
 <li>
  Use RBAC for multi-tenant access
 </li>
 <li>
  Keep Harbor updated
 </li>
</ol>
<h3>
 Troubleshooting
</h3>
<h4>
 1. 413 Request Entity Too Large Error
</h4>
<p>
 <strong>
  Symptom:
 </strong>
 Docker push fails with
 <code>
  413 Request Entity Too Large
 </code>
 when pushing large images.
</p>
<p>
 <strong>
  Cause:
 </strong>
 Nginx
 <code>
  client_max_body_size
 </code>
 limit is too small (default is 1MB).
</p>
<p>
 <strong>
  Solution:
 </strong>
</p>
<ol>
 <li>
  Edit system nginx configuration:
 </li>
</ol>
<pre><code class="language-bash">   sudo nano /etc/nginx/sites-available/services
</code></pre>
<ol>
 <li>
  Find the Harbor location block and add/update:
 </li>
</ol>
<pre><code class="language-nginx">   location / {
       client_max_body_size 2G;  # Adjust as needed
       proxy_pass http://127.0.0.1:8080;
       # ... rest of config
   }
</code></pre>
<ol>
 <li>
  Test and reload nginx:
 </li>
</ol>
<pre><code class="language-bash">   sudo nginx -t
   sudo systemctl reload nginx
</code></pre>
<p>
 <strong>
  Note:
 </strong>
 Harbor's internal nginx is already set to
 <code>
  client_max_body_size 0;
 </code>
 (unlimited) in its
 <code>
  /etc/nginx/nginx.conf
 </code>
 , so you only need to fix the external/system nginx configuration at
 <code>
  /etc/nginx/sites-available/services
 </code>
 .
</p>
<p>
 <strong>
  Verify Harbor's internal nginx (optional):
 </strong>
</p>
<pre><code class="language-bash">docker exec nginx cat /etc/nginx/nginx.conf | grep client_max_body_size
# Should show: client_max_body_size 0;
</code></pre>
<h4>
 2. Cannot Connect to Harbor
</h4>
<p>
 <strong>
  Check these:
 </strong>
</p>
<pre><code class="language-bash"># 1. Is Harbor running?
sudo systemctl status harbor
docker ps | grep harbor

# 2. Is nginx running?
sudo systemctl status nginx

# 3. Check logs
sudo journalctl -u harbor -n 50
docker logs nginx
</code></pre>
<h4>
 3. Login Issues
</h4>
<pre><code class="language-bash"># Reset admin password
cd /opt/harbor
sudo docker-compose stop
sudo ./prepare
sudo docker-compose up -d
</code></pre>
<h4>
 4. Disk Space Full
</h4>
<pre><code class="language-bash"># Check disk usage
df -h /data

# Run garbage collection
docker exec harbor-core harbor-gc

# Or via UI: Administration ‚Üí Garbage Collection ‚Üí Run Now
</code></pre>
<h4>
 5. Slow Image Pushes
</h4>
<p>
 Check nginx configuration for these settings:
</p>
<pre><code class="language-nginx">proxy_buffering off;
proxy_request_buffering off;
proxy_connect_timeout 300;
proxy_send_timeout 300;
proxy_read_timeout 300;
</code></pre>
<h3>
 Next Steps
</h3>
<p>
 After setting up Harbor:
</p>
<ol>
 <li>
  Create projects for different teams
 </li>
 <li>
  Configure robot accounts for CI/CD
 </li>
 <li>
  Set up vulnerability scan policies
 </li>
 <li>
  Configure image retention rules
 </li>
 <li>
  Enable garbage collection
 </li>
 <li>
  Set up replication (if multi-site)
 </li>
 <li>
  Integrate with CI/CD pipelines
 </li>
</ol>
<p>
 My Harbor instance: https://harbor.arpansahu.space
</p>
<p>
 For CI/CD integration, see Jenkins documentation.
</p>
<pre><code class="language-bash">FROM python:3.10.7

WORKDIR /app

COPY . .

RUN pip3 install -r requirements.txt

EXPOSE 8001

CMD bash -c &quot;python manage.py migrate --noinput &amp;&amp; python manage.py collectstatic --noinput &amp;&amp; gunicorn --bind 0.0.0.0:8001 chew_and_cheer.wsgi&quot;
</code></pre>
<p>
 Create a file named docker-compose.yml and add following lines in it
</p>
<pre><code class="language-bash">version: &#x27;3&#x27;

services:
  web:
    build:  # This section will be used when running locally
      context: .
      dockerfile: Dockerfile
    image: harbor.arpansahu.me/library/chew_and_cheer:latest
    env_file: ./.env
    command: bash -c &quot;python manage.py makemigrations &amp;&amp; python manage.py migrate &amp;&amp; gunicorn --bind 0.0.0.0:8001 chew_and_cheer.wsgi&quot;
    container_name: chew_and_cheer
    volumes:
      - .:/app
    ports:
      - &quot;8001:8001&quot;
    restart: unless-stopped
</code></pre>
<h3>
 <strong>
  What is Difference in Dockerfile and docker-compose.yml?
 </strong>
</h3>
<p>
 A Dockerfile is a simple text file that contains the commands a user could call to assemble an image whereas Docker Compose is a tool for defining and running multi-container Docker applications.
</p>
<p>
 Docker Compose define the services that make up your app in docker-compose.yml so they can be run together in an isolated environment. It gets an app running in one command by just running docker-compose up. Docker compose uses the Dockerfile if you add the build command to your project‚Äôs docker-compose.yml. Your Docker workflow should be to build a suitable Dockerfile for each image you wish to create, then use compose to assemble the images using the build command.
</p>
<p>
 Running Docker
</p>
<pre><code class="language-bash">docker compose up --build --detach 
</code></pre>
<p>
 --detach tag is for running the docker even if terminal is closed
 <br/>
 if you remove this tag it will be attached to terminal, and you will be able to see the logs too
</p>
<p>
 --build tag with docker compose up will force image to be rebuild every time before starting the container
</p>
<h3>
 Step 3: Containerizing with Kubernetes
</h3>
<h1>
 K3s Kubernetes with Portainer Agent
</h1>
<p>
 Lightweight Kubernetes cluster using K3s with Portainer Agent for centralized management through your existing Portainer instance.
</p>
<h2>
 Prerequisites
</h2>
<ul>
 <li>
  Ubuntu Server 22.04+
 </li>
 <li>
  At least 1 CPU core and 512MB RAM (2GB recommended)
 </li>
 <li>
  Existing Portainer instance (https://portainer.arpansahu.space)
 </li>
 <li>
  Root or sudo access
 </li>
</ul>
<h2>
 Quick Start
</h2>
<pre><code class="language-bash"># 1. Copy files to server
scp -r kubernetes_k3s/ user@server:&quot;AWS Deployment/&quot;

# 2. SSH to server
ssh user@server
cd &quot;AWS Deployment/kubernetes_k3s&quot;

# 3. Create .env from example
cp .env.example .env
nano .env  # Edit if needed

# 4. Install K3s
chmod +x install.sh
sudo ./install.sh

# 5. Deploy Portainer Agent
export KUBECONFIG=/home/$USER/.kube/config
kubectl apply -n portainer -f https://downloads.portainer.io/ce2-19/portainer-agent-k8s-nodeport.yaml

# 6. Get agent port
kubectl get svc -n portainer portainer-agent

# 7. Connect to Portainer
# Login to: https://portainer.arpansahu.space
# Go to: Environments ‚Üí Add Environment ‚Üí Agent
# Enter: &lt;server-ip&gt;:&lt;nodeport&gt;
</code></pre>
<h2>
 Configuration
</h2>
<p>
 <code>
  .env.example
 </code>
 :
</p>
<pre><code class="language-bash">K3S_VERSION=stable
K3S_CLUSTER_NAME=arpansahu-k3s
PORTAINER_AGENT_NAMESPACE=portainer
PORTAINER_AGENT_PORT=9001
PORTAINER_URL=https://portainer.arpansahu.space
K3S_DATA_DIR=/var/lib/rancher/k3s
K3S_DISABLE_TRAEFIK=true
</code></pre>
<h2>
 Installation Details
</h2>
<h3>
 kubectl Installation
</h3>
<p>
 The
 <code>
  install.sh
 </code>
 script first installs kubectl if not already present:
 <br/>
 - Downloads latest stable kubectl binary
 <br/>
 - Installs to
 <code>
  /usr/local/bin/kubectl
 </code>
 <br/>
 - Skips if kubectl already exists
</p>
<h3>
 K3s Installation
</h3>
<p>
 The
 <code>
  install.sh
 </code>
 script:
 <br/>
 1. Installs K3s (lightweight Kubernetes)
 <br/>
 2. Waits for cluster to be ready
 <br/>
 3. Sets up kubeconfig for non-root user (
 <code>
  ~/.kube/config
 </code>
 )
 <br/>
 4. Creates portainer namespace
</p>
<h3>
 Portainer Agent Deployment
</h3>
<p>
 Deploy the agent manually after K3s installation:
</p>
<pre><code class="language-bash"># Set kubeconfig
export KUBECONFIG=/home/$USER/.kube/config

# Deploy agent
kubectl apply -n portainer -f https://downloads.portainer.io/ce2-19/portainer-agent-k8s-nodeport.yaml

# Verify deployment
kubectl get pods -n portainer
kubectl get svc -n portainer
</code></pre>
<h2>
 Connecting to Portainer
</h2>
<h3>
 Get Connection Details
</h3>
<pre><code class="language-bash"># Get server IP
hostname -I | awk &#x27;{print $1}&#x27;

# Get NodePort
kubectl get svc -n portainer portainer-agent -o jsonpath=&#x27;{.spec.ports[0].nodePort}&#x27;

# Example endpoint: 192.168.1.200:30778
</code></pre>
<h3>
 Add Environment in Portainer
</h3>
<ol>
 <li>
  Login: https://portainer.arpansahu.space
 </li>
 <li>
  <strong>
   Environments
  </strong>
  ‚Üí
  <strong>
   Add environment
  </strong>
 </li>
 <li>
  Select
  <strong>
   Agent
  </strong>
 </li>
 <li>
  <strong>
   Environment details:
  </strong>
 </li>
 <li>
  Name:
  <code>
   K3s Cluster
  </code>
 </li>
 <li>
  Environment URL:
  <code>
   192.168.1.200:30778
  </code>
  (use your IP and port)
 </li>
 <li>
  Click
  <strong>
   Connect
  </strong>
 </li>
</ol>
<h3>
 Verify Connection
</h3>
<pre><code class="language-bash"># Check agent status
kubectl get pods -n portainer

# View agent logs
kubectl logs -n portainer -l app=portainer-agent

# Test connectivity
curl http://localhost:&lt;nodeport&gt;
</code></pre>
<h2>
 Managing Applications
</h2>
<h3>
 Via Portainer UI
</h3>
<ol>
 <li>
  Select K3s environment in Portainer
 </li>
 <li>
  <strong>
   Applications
  </strong>
  ‚Üí
  <strong>
   Add application
  </strong>
 </li>
 <li>
  Configure deployment settings
 </li>
 <li>
  Click
  <strong>
   Deploy
  </strong>
 </li>
</ol>
<h3>
 Via kubectl
</h3>
<pre><code class="language-bash"># Create deployment
kubectl create deployment nginx --image=nginx:alpine

# Expose as service
kubectl expose deployment nginx --port=80 --type=NodePort

# Check resources
kubectl get all
kubectl get pods
kubectl get services

# Get service URL
kubectl get svc nginx -o jsonpath=&#x27;{.spec.ports[0].nodePort}&#x27;
# Access: http://&lt;server-ip&gt;:&lt;nodeport&gt;
</code></pre>
<h3>
 Via YAML Manifests
</h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: nginx:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: my-app
spec:
  type: NodePort
  selector:
    app: my-app
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30080
</code></pre>
<p>
 Apply:
</p>
<pre><code class="language-bash">kubectl apply -f deployment.yaml
</code></pre>
<h2>
 kubectl Commands
</h2>
<h3>
 Basic Operations
</h3>
<pre><code class="language-bash"># Cluster information
kubectl cluster-info
kubectl get nodes

# View resources
kubectl get all -A
kubectl get pods -A
kubectl get services -A
kubectl get namespaces

# Describe resources
kubectl describe pod &lt;pod-name&gt;
kubectl describe svc &lt;service-name&gt;

# Logs
kubectl logs &lt;pod-name&gt;
kubectl logs -f &lt;pod-name&gt;  # Follow logs
kubectl logs &lt;pod-name&gt; --previous  # Previous container logs

# Execute commands
kubectl exec -it &lt;pod-name&gt; -- /bin/sh
kubectl exec &lt;pod-name&gt; -- ls /app

# Port forwarding
kubectl port-forward pod/&lt;pod-name&gt; 8080:80
kubectl port-forward svc/&lt;service-name&gt; 8080:80
</code></pre>
<h3>
 Deployment Management
</h3>
<pre><code class="language-bash"># Scale deployment
kubectl scale deployment &lt;name&gt; --replicas=3

# Update image
kubectl set image deployment/&lt;name&gt; container-name=new-image:tag

# Restart deployment
kubectl rollout restart deployment/&lt;name&gt;

# Rollout history
kubectl rollout history deployment/&lt;name&gt;

# Rollback
kubectl rollout undo deployment/&lt;name&gt;

# Delete resources
kubectl delete deployment &lt;name&gt;
kubectl delete service &lt;name&gt;
kubectl delete -f deployment.yaml
</code></pre>
<h3>
 Namespace Management
</h3>
<pre><code class="language-bash"># List namespaces
kubectl get namespaces

# Create namespace
kubectl create namespace my-namespace

# Switch context to namespace
kubectl config set-context --current --namespace=my-namespace

# Delete namespace
kubectl delete namespace my-namespace
</code></pre>
<h2>
 Backup and Restore
</h2>
<h3>
 Backup Script
</h3>
<pre><code class="language-bash">#!/bin/bash
# backup-k3s.sh

BACKUP_DIR=&quot;/backup/k3s/$(date +%Y%m%d_%H%M%S)&quot;
mkdir -p &quot;$BACKUP_DIR&quot;

# Backup K3s data directory
sudo tar czf &quot;$BACKUP_DIR/k3s-data.tar.gz&quot; /var/lib/rancher/k3s

# Backup all Kubernetes resources
kubectl get all -A -o yaml &gt; &quot;$BACKUP_DIR/all-resources.yaml&quot;

# Backup persistent volumes
kubectl get pv,pvc -A -o yaml &gt; &quot;$BACKUP_DIR/volumes.yaml&quot;

# Backup namespaces and configs
kubectl get namespaces -o yaml &gt; &quot;$BACKUP_DIR/namespaces.yaml&quot;
kubectl get configmaps -A -o yaml &gt; &quot;$BACKUP_DIR/configmaps.yaml&quot;
kubectl get secrets -A -o yaml &gt; &quot;$BACKUP_DIR/secrets.yaml&quot;

echo &quot;Backup completed: $BACKUP_DIR&quot;
</code></pre>
<h3>
 Restore Script
</h3>
<pre><code class="language-bash">#!/bin/bash
# restore-k3s.sh

BACKUP_DIR=&quot;/backup/k3s/20260201_100000&quot;

# Stop K3s
sudo systemctl stop k3s

# Restore K3s data
sudo tar xzf &quot;$BACKUP_DIR/k3s-data.tar.gz&quot; -C /

# Start K3s
sudo systemctl start k3s
sleep 30

# Wait for cluster to be ready
until kubectl get nodes | grep -q &quot;Ready&quot;; do
    echo &quot;Waiting for cluster...&quot;
    sleep 5
done

# Restore resources
kubectl apply -f &quot;$BACKUP_DIR/all-resources.yaml&quot;

echo &quot;Restore completed&quot;
</code></pre>
<h2>
 Troubleshooting
</h2>
<h3>
 K3s Issues
</h3>
<pre><code class="language-bash"># Check K3s status
sudo systemctl status k3s

# View K3s logs
sudo journalctl -u k3s -n 100 --no-pager
sudo journalctl -u k3s -f  # Follow logs

# Restart K3s
sudo systemctl restart k3s

# Check K3s version
k3s --version

# Check ports
sudo netstat -tlnp | grep -E &#x27;6443|10250&#x27;
</code></pre>
<h3>
 Portainer Agent Issues
</h3>
<pre><code class="language-bash"># Check agent pod status
kubectl get pods -n portainer

# View agent logs
kubectl logs -n portainer -l app=portainer-agent
kubectl logs -n portainer -l app=portainer-agent -f  # Follow

# Check agent service
kubectl get svc -n portainer

# Describe agent pod
kubectl describe pod -n portainer -l app=portainer-agent

# Test agent port
kubectl get svc -n portainer portainer-agent -o jsonpath=&#x27;{.spec.ports[0].nodePort}&#x27;
curl http://localhost:&lt;nodeport&gt;

# Restart agent
kubectl rollout restart deployment -n portainer portainer-agent
</code></pre>
<h3>
 Pod Issues
</h3>
<pre><code class="language-bash"># Check pod status
kubectl get pods -n &lt;namespace&gt;

# Describe pod (shows events)
kubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;

# View pod logs
kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;

# Check events
kubectl get events -A --sort-by=&#x27;.lastTimestamp&#x27;

# Check node resources
kubectl top nodes
kubectl describe nodes
</code></pre>
<h3>
 Network Issues
</h3>
<pre><code class="language-bash"># Check CoreDNS pods
kubectl get pods -n kube-system -l k8s-app=kube-dns

# Test DNS resolution
kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup kubernetes.default

# Check network pods
kubectl get pods -n kube-system

# Restart CoreDNS
kubectl rollout restart deployment -n kube-system coredns
</code></pre>
<h3>
 Storage Issues
</h3>
<pre><code class="language-bash"># Check persistent volumes
kubectl get pv
kubectl get pvc -A

# Describe PVC
kubectl describe pvc &lt;pvc-name&gt; -n &lt;namespace&gt;

# Check disk space
df -h
du -sh /var/lib/rancher/k3s/*
</code></pre>
<h3>
 Connection Issues from Portainer
</h3>
<pre><code class="language-bash"># From Portainer server, test connection
telnet &lt;k3s-server-ip&gt; &lt;nodeport&gt;
curl http://&lt;k3s-server-ip&gt;:&lt;nodeport&gt;

# Check firewall
sudo ufw status
sudo ufw allow &lt;nodeport&gt;/tcp

# Check if agent is listening
sudo netstat -tlnp | grep &lt;nodeport&gt;
</code></pre>
<h3>
 Performance Issues
</h3>
<pre><code class="language-bash"># Check resource usage
kubectl top nodes
kubectl top pods -A

# Check system resources
free -h
df -h
vmstat 5

# Check K3s resource limits
sudo cat /etc/systemd/system/k3s.service
</code></pre>
<h3>
 Uninstall K3s
</h3>
<pre><code class="language-bash"># Complete uninstall
sudo /usr/local/bin/k3s-uninstall.sh

# Verify removal
which k3s
which kubectl
ls /var/lib/rancher/k3s
</code></pre>
<h2>
 Security Best Practices
</h2>
<ol>
 <li>
  <strong>
   Kubeconfig Permissions
  </strong>
  : Ensure
  <code>
   ~/.kube/config
  </code>
  has proper permissions (600)
 </li>
 <li>
  <strong>
   RBAC
  </strong>
  : Use role-based access control for users and services
 </li>
 <li>
  <strong>
   Network Policies
  </strong>
  : Implement network policies for pod communication
 </li>
 <li>
  <strong>
   Secrets Management
  </strong>
  : Use Kubernetes secrets for sensitive data
 </li>
 <li>
  <strong>
   Regular Updates
  </strong>
  : Keep K3s and container images updated
 </li>
 <li>
  <strong>
   Resource Limits
  </strong>
  : Set CPU/memory limits on pods
 </li>
 <li>
  <strong>
   Security Context
  </strong>
  : Define security contexts for pods
 </li>
</ol>
<h2>
 Resources
</h2>
<ul>
 <li>
  <a href="https://docs.k3s.io/">
   K3s Official Documentation
  </a>
 </li>
 <li>
  <a href="https://docs.portainer.io/admin/environments/add/kubernetes/agent">
   Portainer Agent Documentation
  </a>
 </li>
 <li>
  <a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">
   kubectl Cheat Sheet
  </a>
 </li>
 <li>
  <a href="https://kubernetes.io/docs/">
   Kubernetes Documentation
  </a>
 </li>
</ul>
<h2>
 Support
</h2>
<p>
 For issues:
 <br/>
 1. Check
 <a href="#troubleshooting">
  Troubleshooting
 </a>
 section
 <br/>
 2. View K3s logs:
 <code>
  sudo journalctl -u k3s -f
 </code>
 <br/>
 3. View agent logs:
 <code>
  kubectl logs -n portainer -l app=portainer-agent
 </code>
 <br/>
 4.
 <a href="https://github.com/k3s-io/k3s/issues">
  K3s GitHub Issues
 </a>
 <br/>
 5.
 <a href="https://www.portainer.io/community">
  Portainer Community Forums
 </a>
</p>
<hr/>
<h2>
 SSL Certificates for Kubernetes
</h2>
<h3>
 Overview
</h3>
<p>
 K3s requires SSL certificates for TLS Ingress and secure pod communication (Java apps, Kafka, etc.). Certificates are
 <strong>
  automatically managed
 </strong>
 - see
 <a href="../ssl-automation/README.md">
  SSL Automation Documentation
 </a>
 .
</p>
<h3>
 Quick Reference
</h3>
<p>
 <strong>
  Automated Certificate Management:
 </strong>
 <br/>
 - ‚úÖ K3s secrets updated after SSL renewal (arpansahu-tls, kafka-ssl-keystore)
 <br/>
 - ‚úÖ Keystores stored in
 <code>
  /var/lib/rancher/k3s/ssl/keystores/
 </code>
 <br/>
 - ‚úÖ Uploaded to MinIO for Django projects
 <br/>
 - ‚úÖ See
 <a href="./DJANGO_INTEGRATION.md">
  Django Integration Guide
 </a>
</p>
<p>
 <strong>
  Manual testing:
 </strong>
</p>
<pre><code class="language-bash"># On server
cd ~/k3s_scripts
./1_renew_k3s_ssl_keystores.sh   # Update K3s secrets
./2_upload_keystores_to_minio.sh # Upload to MinIO
</code></pre>
<h3>
 Using Certificates in Deployments
</h3>
<h4>
 Ingress with TLS
</h4>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
spec:
  tls:
  - hosts:
    - app.arpansahu.space
    secretName: arpansahu-tls  # Auto-managed secret
  rules:
  - host: app.arpansahu.space
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app-service
            port:
              number: 80
</code></pre>
<h4>
 Kafka Pod with SSL
</h4>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
spec:
  template:
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.8.0
        env:
        - name: KAFKA_SSL_KEYSTORE_LOCATION
          value: /etc/kafka/secrets/kafka.keystore.jks
        - name: KAFKA_SSL_KEYSTORE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: kafka-ssl-keystore  # Auto-managed secret
              key: keystore-password
        volumeMounts:
        - name: kafka-ssl
          mountPath: /etc/kafka/secrets
          readOnly: true
      volumes:
      - name: kafka-ssl
        secret:
          secretName: kafka-ssl-keystore
</code></pre>
<h3>
 Monitoring
</h3>
<pre><code class="language-bash"># List secrets
kubectl get secrets

# Check certificate expiry
kubectl get secret arpansahu-tls -o jsonpath=&#x27;{.data.tls\.crt}&#x27; | \
  base64 -d | openssl x509 -noout -dates

# View keystore secret
kubectl describe secret kafka-ssl-keystore
</code></pre>
<h3>
 Troubleshooting
</h3>
<p>
 <strong>
  Pods not using new certificates:
 </strong>
 <br/>
 - Restart deployment:
 <code>
  kubectl rollout restart deployment/your-app
 </code>
 <br/>
 - K8s doesn't auto-reload secrets - manual restart required
</p>
<p>
 <strong>
  Certificate verification failed:
 </strong>
 <br/>
 - Check secret exists:
 <code>
  kubectl get secret arpansahu-tls
 </code>
 <br/>
 - Verify expiry date (see Monitoring above)
 <br/>
 - Force renewal: See
 <a href="../ssl-automation/README.md">
  SSL Automation
 </a>
</p>
<p>
 <strong>
  For complete automation details, troubleshooting, and manual procedures:
 </strong>
 <a href="../ssl-automation/README.md">
  SSL Automation Documentation
 </a>
</p>
<hr/>
<h3>
 Step 4: Serving the requests from Nginx
</h3>
<h2>
 Nginx - Web Server & Reverse Proxy
</h2>
<p>
 Nginx is a high-performance web server and reverse proxy used to route HTTPS traffic to all services.
</p>
<h3>
 Access Details
</h3>
<ul>
 <li>
  <strong>
   HTTP Port:
  </strong>
  80 (redirects to HTTPS)
 </li>
 <li>
  <strong>
   HTTPS Port:
  </strong>
  443
 </li>
 <li>
  <strong>
   Config Directory:
  </strong>
  <code>
   /etc/nginx/sites-available/
  </code>
 </li>
 <li>
  <strong>
   Enabled Sites:
  </strong>
  <code>
   /etc/nginx/sites-enabled/
  </code>
 </li>
 <li>
  <strong>
   SSL Certificates:
  </strong>
  <code>
   /etc/nginx/ssl/arpansahu.space/
  </code>
 </li>
 <li>
  <strong>
   Logs:
  </strong>
  <code>
   /var/log/nginx/
  </code>
 </li>
</ul>
<h3>
 Quick Install
</h3>
<pre><code class="language-bash">cd &quot;AWS Deployment/nginx&quot;
chmod +x install.sh
./install.sh
</code></pre>
<h3>
 Installation Script
</h3>
<p>
 ```bash file=install.sh
</p>
<pre><code>
### SSL Certificate Installation

```bash file=install-ssl.sh
</code></pre>
<p>
 <strong>
  Prerequisites for SSL:
 </strong>
 <br/>
 1. Namecheap account with API access enabled
 <br/>
 2. Server IP whitelisted in Namecheap API settings
 <br/>
 3. Environment variables set:
</p>
<pre><code class="language-bash">export NAMECHEAP_USERNAME=&quot;your_username&quot;
export NAMECHEAP_API_KEY=&quot;your_api_key&quot;
export NAMECHEAP_SOURCEIP=&quot;your_server_ip&quot;
./install-ssl.sh
</code></pre>
<h3>
 Manual Installation
</h3>
<h4>
 1. Install Nginx
</h4>
<pre><code class="language-bash">sudo apt update
sudo apt install -y nginx
sudo systemctl start nginx
sudo systemctl enable nginx
</code></pre>
<h4>
 2. Configure Firewall
</h4>
<pre><code class="language-bash">sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw reload
</code></pre>
<h4>
 3. Configure DNS
</h4>
<p>
 Add A records to your DNS provider:
</p>
<pre><code>Type: A Record
Name: @
Value: YOUR_SERVER_IP

Type: A Record  
Name: *
Value: YOUR_SERVER_IP
</code></pre>
<p>
 This allows all subdomains (*.arpansahu.space) to point to your server.
</p>
<h4>
 4. Create Service Configuration
</h4>
<pre><code class="language-bash">sudo nano /etc/nginx/sites-available/services
</code></pre>
<p>
 Add server blocks for each service (see individual service nginx configs).
</p>
<h4>
 5. Enable Configuration
</h4>
<pre><code class="language-bash">sudo ln -sf /etc/nginx/sites-available/services /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
</code></pre>
<h3>
 SSL Certificate Setup (acme.sh)
</h3>
<h4>
 Why acme.sh?
</h4>
<ul>
 <li>
  Native DNS-01 challenge support
 </li>
 <li>
  Works perfectly with Namecheap
 </li>
 <li>
  Automatic renewal via cron
 </li>
 <li>
  Supports wildcard certificates
 </li>
 <li>
  Simpler than Certbot for DNS challenges
 </li>
</ul>
<h4>
 Install acme.sh
</h4>
<pre><code class="language-bash">curl https://get.acme.sh | sh
source ~/.bashrc
acme.sh --set-default-ca --server letsencrypt
</code></pre>
<h4>
 Configure Namecheap API
</h4>
<ol>
 <li>
  Login to Namecheap ‚Üí Profile ‚Üí Tools ‚Üí API Access
 </li>
 <li>
  Enable API Access
 </li>
 <li>
  Whitelist your server's public IP
 </li>
 <li>
  Get API credentials
 </li>
</ol>
<h4>
 Issue Wildcard Certificate
</h4>
<pre><code class="language-bash">export NAMECHEAP_USERNAME=&quot;your_username&quot;
export NAMECHEAP_API_KEY=&quot;your_api_key&quot;
export NAMECHEAP_SOURCEIP=&quot;your_server_ip&quot;

acme.sh --issue \
  --dns dns_namecheap \
  -d arpansahu.space \
  -d &quot;*.arpansahu.space&quot; \
  --server letsencrypt
</code></pre>
<h4>
 Install Certificate for Nginx
</h4>
<pre><code class="language-bash">sudo mkdir -p /etc/nginx/ssl/arpansahu.space

acme.sh --install-cert \
  -d arpansahu.space \
  -d &quot;*.arpansahu.space&quot; \
  --key-file /etc/nginx/ssl/arpansahu.space/privkey.pem \
  --fullchain-file /etc/nginx/ssl/arpansahu.space/fullchain.pem \
  --reloadcmd &quot;systemctl reload nginx&quot;
</code></pre>
<h4>
 Setup Auto-Renewal
</h4>
<pre><code class="language-bash">crontab -e
</code></pre>
<p>
 Add:
</p>
<pre><code>0 0 * * * ~/.acme.sh/acme.sh --cron --home ~/.acme.sh &gt; /dev/null
</code></pre>
<h3>
 Nginx Configuration Structure
</h3>
<p>
 Each service has its own nginx config with this pattern:
</p>
<pre><code class="language-nginx"># HTTP to HTTPS redirect
server {
    listen 80;
    listen [::]:80;
    server_name service.arpansahu.space;
    return 301 https://$host$request_uri;
}

# HTTPS server block
server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;
    server_name service.arpansahu.space;

    # SSL Configuration
    ssl_certificate /etc/nginx/ssl/arpansahu.space/fullchain.pem;
    ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;
    ssl_protocols TLSv1.2 TLSv1.3;

    # Proxy to backend service
    location / {
        proxy_pass http://127.0.0.1:PORT;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto https;
    }
}
</code></pre>
<h3>
 Service Routing Table
</h3>
<table>
 <thead>
  <tr>
   <th>
    Service
   </th>
   <th>
    Domain
   </th>
   <th>
    Backend Port
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    Harbor
   </td>
   <td>
    harbor.arpansahu.space
   </td>
   <td>
    8888
   </td>
  </tr>
  <tr>
   <td>
    RabbitMQ
   </td>
   <td>
    rabbitmq.arpansahu.space
   </td>
   <td>
    15672
   </td>
  </tr>
  <tr>
   <td>
    PgAdmin
   </td>
   <td>
    pgadmin.arpansahu.space
   </td>
   <td>
    5050
   </td>
  </tr>
  <tr>
   <td>
    SSH Terminal
   </td>
   <td>
    ssh.arpansahu.space
   </td>
   <td>
    8084
   </td>
  </tr>
  <tr>
   <td>
    Jenkins
   </td>
   <td>
    jenkins.arpansahu.space
   </td>
   <td>
    8080
   </td>
  </tr>
  <tr>
   <td>
    Portainer
   </td>
   <td>
    portainer.arpansahu.space
   </td>
   <td>
    9443
   </td>
  </tr>
  <tr>
   <td>
    Redis (stream)
   </td>
   <td>
    redis.arpansahu.space
   </td>
   <td>
    6380 (TCP)
   </td>
  </tr>
 </tbody>
</table>
<h3>
 Common Commands
</h3>
<p>
 <strong>
  Test configuration:
 </strong>
</p>
<pre><code class="language-bash">sudo nginx -t
</code></pre>
<p>
 <strong>
  Reload (no downtime):
 </strong>
</p>
<pre><code class="language-bash">sudo systemctl reload nginx
</code></pre>
<p>
 <strong>
  Restart:
 </strong>
</p>
<pre><code class="language-bash">sudo systemctl restart nginx
</code></pre>
<p>
 <strong>
  View status:
 </strong>
</p>
<pre><code class="language-bash">sudo systemctl status nginx
</code></pre>
<p>
 <strong>
  View logs:
 </strong>
</p>
<pre><code class="language-bash"># Access logs
sudo tail -f /var/log/nginx/access.log

# Error logs
sudo tail -f /var/log/nginx/error.log

# Service-specific
sudo tail -f /var/log/nginx/services.access.log
</code></pre>
<p>
 <strong>
  Check active connections:
 </strong>
</p>
<pre><code class="language-bash">sudo ss -tuln | grep -E &#x27;:80|:443&#x27;
</code></pre>
<p>
 <strong>
  List enabled sites:
 </strong>
</p>
<pre><code class="language-bash">ls -la /etc/nginx/sites-enabled/
</code></pre>
<h3>
 Redis TCP Stream Configuration
</h3>
<p>
 Redis requires TCP stream instead of HTTP proxy:
</p>
<pre><code class="language-nginx">stream {
    upstream redis_backend {
        server 127.0.0.1:6380;
    }

    server {
        listen 6379 ssl;
        proxy_pass redis_backend;
        proxy_connect_timeout 1s;

        ssl_certificate /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
    }
}
</code></pre>
<p>
 This goes in
 <code>
  /etc/nginx/nginx.conf
 </code>
 at the root level (outside http block).
</p>
<h3>
 Troubleshooting
</h3>
<p>
 <strong>
  502 Bad Gateway:
 </strong>
</p>
<pre><code class="language-bash"># Check backend service is running
sudo ss -tuln | grep PORT

# Check nginx can connect
curl http://127.0.0.1:PORT

# Check logs
sudo tail -f /var/log/nginx/error.log
</code></pre>
<p>
 <strong>
  Certificate errors:
 </strong>
</p>
<pre><code class="language-bash"># Check certificate files exist
ls -la /etc/nginx/ssl/arpansahu.space/

# Check certificate validity
openssl x509 -in /etc/nginx/ssl/arpansahu.space/fullchain.pem -text -noout

# Check acme.sh status
acme.sh --list
</code></pre>
<p>
 <strong>
  Configuration not loading:
 </strong>
</p>
<pre><code class="language-bash"># Test syntax
sudo nginx -t

# Check enabled sites
ls -la /etc/nginx/sites-enabled/

# Reload nginx
sudo systemctl reload nginx
</code></pre>
<p>
 <strong>
  Port already in use:
 </strong>
</p>
<pre><code class="language-bash"># Find what&#x27;s using port 80/443
sudo ss -tuln | grep -E &#x27;:80|:443&#x27;
sudo lsof -i :80
</code></pre>
<h3>
 Security Best Practices
</h3>
<ol>
 <li>
  <strong>
   Hide server version:
  </strong>
 </li>
</ol>
<pre><code class="language-nginx">   server_tokens off;
</code></pre>
<ol>
 <li>
  <strong>
   Enable HTTP/2:
  </strong>
 </li>
</ol>
<pre><code class="language-nginx">   listen 443 ssl http2;
</code></pre>
<ol>
 <li>
  <strong>
   Strong SSL protocols:
  </strong>
 </li>
</ol>
<pre><code class="language-nginx">   ssl_protocols TLSv1.2 TLSv1.3;
   ssl_prefer_server_ciphers off;
</code></pre>
<ol>
 <li>
  <strong>
   Security headers:
  </strong>
 </li>
</ol>
<pre><code class="language-nginx">   add_header X-Frame-Options &quot;SAMEORIGIN&quot; always;
   add_header X-Content-Type-Options &quot;nosniff&quot; always;
   add_header X-XSS-Protection &quot;1; mode=block&quot; always;
</code></pre>
<ol>
 <li>
  <strong>
   Rate limiting:
  </strong>
 </li>
</ol>
<pre><code class="language-nginx">   limit_req_zone $binary_remote_addr zone=general:10m rate=10r/s;
   limit_req zone=general burst=20 nodelay;
</code></pre>
<h3>
 Certificate Renewal
</h3>
<p>
 acme.sh automatically renews certificates via cron. To manually renew:
</p>
<pre><code class="language-bash">acme.sh --renew -d arpansahu.space -d &quot;*.arpansahu.space&quot; --force
</code></pre>
<p>
 Check renewal log:
</p>
<pre><code class="language-bash">cat ~/.acme.sh/arpansahu.space/arpansahu.space.log
</code></pre>
<hr/>
<h2>
 SSL Certificate Automation & Renewal
</h2>
<p>
 <strong>
  Complete SSL automation is now centralized.
 </strong>
 See
 <strong>
  <a href="../ssl-automation/README.md">
   SSL Automation Documentation
  </a>
 </strong>
 for:
</p>
<ul>
 <li>
  ‚úÖ Automated renewal (acme.sh + deploy_certs.sh)
 </li>
 <li>
  ‚úÖ Nginx certificate deployment
 </li>
 <li>
  ‚úÖ Kafka keystore regeneration
 </li>
 <li>
  ‚úÖ Kubernetes secret updates
 </li>
 <li>
  ‚úÖ MinIO upload for Django projects
 </li>
 <li>
  ‚úÖ Complete troubleshooting guide
 </li>
</ul>
<p>
 <strong>
  Quick verification:
 </strong>
</p>
<pre><code class="language-bash"># Check certificate expiry
openssl x509 -in /etc/nginx/ssl/arpansahu.space/fullchain.pem -noout -dates

# Test automation
ssh arpansahu@arpansahu.space &#x27;~/deploy_certs.sh&#x27;
</code></pre>
<hr/>
<h3>
 Backup Configuration
</h3>
<pre><code class="language-bash"># Backup nginx configs
sudo tar -czf nginx-backup-$(date +%Y%m%d).tar.gz \
  /etc/nginx/sites-available/ \
  /etc/nginx/sites-enabled/ \
  /etc/nginx/nginx.conf \
  /etc/nginx/ssl/

# Backup SSL certificates
tar -czf ssl-backup-$(date +%Y%m%d).tar.gz ~/.acme.sh/
</code></pre>
<h3>
 Migration to New Server
</h3>
<ol>
 <li>
  Backup on old server (see above)
 </li>
 <li>
  Install nginx on new server
 </li>
 <li>
  Restore configs
 </li>
 <li>
  Issue new certificates (acme.sh requires DNS validation)
 </li>
 <li>
  Update DNS records to new server IP
 </li>
</ol>
<h3>
 Architecture Diagram
</h3>
<pre><code>Internet (Client)
   ‚îÇ
   ‚ñº
[ Nginx - Port 443 (SSL/TLS Termination) ]
   ‚îÇ
   ‚îú‚îÄ‚îÄ‚ñ∂ Harbor (8888)
   ‚îú‚îÄ‚îÄ‚ñ∂ RabbitMQ (15672)
   ‚îú‚îÄ‚îÄ‚ñ∂ PgAdmin (5050)
   ‚îú‚îÄ‚îÄ‚ñ∂ SSH Terminal (8084)
   ‚îú‚îÄ‚îÄ‚ñ∂ Jenkins (8080)
   ‚îî‚îÄ‚îÄ‚ñ∂ Portainer (9443)
</code></pre>
<p>
 <strong>
  Key Points:
 </strong>
 <br/>
 - Nginx handles all SSL/TLS
 <br/>
 - Backend services run on localhost (secure)
 <br/>
 - Single wildcard certificate covers all subdomains
 <br/>
 - Automatic certificate renewal
 <br/>
 - Zero downtime reloads
</p>
<h3>
 Configuration Files
</h3>
<ul>
 <li>
  Installation:
  <a href="./install.sh">
   <code>
    install.sh
   </code>
  </a>
 </li>
 <li>
  SSL setup:
  <a href="./install-ssl.sh">
   <code>
    install-ssl.sh
   </code>
  </a>
 </li>
 <li>
  Main config:
  <code>
   /etc/nginx/nginx.conf
  </code>
 </li>
 <li>
  Sites:
  <code>
   /etc/nginx/sites-available/
  </code>
 </li>
 <li>
  SSL certs:
  <code>
   /etc/nginx/ssl/arpansahu.space/
  </code>
 </li>
 <li>
  Service configs: See individual service folders
 </li>
</ul>
<h3>
 Performance Tuning
</h3>
<pre><code class="language-nginx"># /etc/nginx/nginx.conf
worker_processes auto;
worker_connections 1024;

# Enable gzip
gzip on;
gzip_vary on;
gzip_proxied any;
gzip_types text/plain text/css application/json application/javascript;

# Buffer sizes
client_body_buffer_size 128k;
client_max_body_size 500M;
</code></pre>
<h3>
 Monitoring
</h3>
<pre><code class="language-bash"># Active connections
sudo ss -s

# Request rate
sudo tail -f /var/log/nginx/access.log | pv -l -i1 -r &gt; /dev/null

# Error rate
sudo grep error /var/log/nginx/error.log | tail -20
</code></pre>
<p>
 After all these steps your Nginx configuration file located at /etc/nginx/sites-available/chew-and-cheer will be looking similar to this
</p>
<pre><code class="language-bash"># ================= SERVICE PROXY TEMPLATE =================

# HTTP ‚Üí HTTPS redirect
server {
    listen 80;
    listen [::]:80;

    server_name chew-and-cheer.arpansahu.me;
    return 301 https://$host$request_uri;
}

# HTTPS reverse proxy
server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;

    server_name chew-and-cheer.arpansahu.me;

    # üîê Wildcard SSL (acme.sh + Namecheap DNS-01)
    ssl_certificate     /etc/nginx/ssl/arpansahu.space/fullchain.pem;
         proxy_set_header Connection &quot;upgrade&quot;;
    }

    listen 443 ssl; # managed by Certbot
    ssl_certificate /etc/letsencrypt/live/arpansahu.me/fullchain.pem; # managed by Certbot
    ssl_certificate_key /etc/letsencrypt/live/arpansahu.me/privkey.pem; # managed by Certbot
    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot
}
</code></pre>
<h3>
 Step 6: CI/CD using Jenkins
</h3>
<h2>
 Jenkins (CI/CD Automation Server)
</h2>
<p>
 Jenkins is an open-source automation server that enables developers to build, test, and deploy applications through continuous integration and continuous delivery (CI/CD). This guide provides a complete, production-ready setup with Java 21, Jenkins LTS, Nginx reverse proxy, and comprehensive credential management.
</p>
<h3>
 Prerequisites
</h3>
<p>
 Before installing Jenkins, ensure you have:
</p>
<ol>
 <li>
  Ubuntu Server 22.04 LTS
 </li>
 <li>
  Nginx with SSL certificates configured
 </li>
 <li>
  Domain name (example: jenkins.arpansahu.space)
 </li>
 <li>
  Wildcard SSL certificate already issued (via acme.sh)
 </li>
 <li>
  Minimum 2GB RAM, 20GB disk space
 </li>
 <li>
  Root or sudo access
 </li>
 <li>
  Docker installed (for containerized builds)
 </li>
</ol>
<h3>
 Architecture Overview
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (Port 443) - TLS Termination
        ‚îÇ
        ‚îî‚îÄ jenkins.arpansahu.space
             ‚îÇ
             ‚îî‚îÄ Jenkins (localhost:8080)
                  ‚îÇ
                  ‚îú‚îÄ Jenkins Controller (Web UI + API)
                  ‚îú‚îÄ Build Agents (local/remote)
                  ‚îú‚îÄ Workspace (/var/lib/jenkins)
                  ‚îî‚îÄ Credentials Store
</code></pre>
<p>
 Key Principles:
 <br/>
 - Jenkins runs on localhost only (port 8080)
 <br/>
 - Nginx handles all TLS termination
 <br/>
 - Credentials stored in Jenkins encrypted store
 <br/>
 - Pipelines defined as code (Jenkinsfile)
 <br/>
 - Docker-based builds for isolation
</p>
<h3>
 Why Jenkins
</h3>
<p>
 <strong>
  Advantages:
 </strong>
 <br/>
 - Open-source and free
 <br/>
 - Extensive plugin ecosystem (1800+)
 <br/>
 - Pipeline as Code (Jenkinsfile)
 <br/>
 - Distributed builds
 <br/>
 - Docker integration
 <br/>
 - GitHub/GitLab integration
 <br/>
 - Email notifications
 <br/>
 - Role-based access control
</p>
<p>
 <strong>
  Use Cases:
 </strong>
 <br/>
 - Automated builds on commit
 <br/>
 - Automated testing
 <br/>
 - Docker image building
 <br/>
 - Deployment automation
 <br/>
 - Scheduled jobs
 <br/>
 - Integration with Harbor registry
 <br/>
 - Multi-branch pipelines
</p>
<h3>
 Part 1: Install Java 21
</h3>
<p>
 Jenkins requires Java to run. We'll install OpenJDK 21 (latest LTS).
</p>
<p>
 <strong>
  ‚ö†Ô∏è Important:
 </strong>
 Java 17 support ends March 31, 2026. Use Java 21 for continued support.
</p>
<h4>
 Check Current Java Version
</h4>
<pre><code class="language-bash">java -version
</code></pre>
<p>
 If you see Java 17 or older, follow the upgrade steps below.
</p>
<h4>
 Upgrade from Java 17 to Java 21 (If Needed)
</h4>
<p>
 If Jenkins is already installed on Java 17:
</p>
<ol>
 <li>
  Install Java 21
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
    sudo apt install -y openjdk-21-jdk
</code></pre>
<ol>
 <li>
  Check Jenkins service status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  Update Jenkins to use Java 21
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop jenkins
    sudo update-alternatives --config java
</code></pre>
<pre><code>Select Java 21 from the list (e.g., `/usr/lib/jvm/java-21-openjdk-amd64/bin/java`)
</code></pre>
<ol>
 <li>
  Verify Java version
 </li>
</ol>
<pre><code class="language-bash">    java -version
</code></pre>
<pre><code>Should show: `openjdk version &quot;21.0.x&quot;`
</code></pre>
<ol>
 <li>
  Update JAVA_HOME for Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/default/jenkins
</code></pre>
<pre><code>Add or update:
</code></pre>
<pre><code class="language-bash">    JAVA_HOME=&quot;/usr/lib/jvm/java-21-openjdk-amd64&quot;
    JENKINS_JAVA_CMD=&quot;$JAVA_HOME/bin/java&quot;
</code></pre>
<ol>
 <li>
  Restart Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  <p>
   Verify in Jenkins UI
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System Information ‚Üí Look for
   <code>
    java.version
   </code>
   (should be 21.x)
  </p>
 </li>
</ol>
<h4>
 Fresh Installation of Java 21
</h4>
<p>
 For new installations:
</p>
<ol>
 <li>
  Update system packages
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
</code></pre>
<ol>
 <li>
  Install OpenJDK 21
 </li>
</ol>
<pre><code class="language-bash">    sudo apt install -y openjdk-21-jdk
</code></pre>
<ol>
 <li>
  Verify Java installation
 </li>
</ol>
<pre><code class="language-bash">    java -version
</code></pre>
<pre><code>Expected output:
</code></pre>
<pre><code>    openjdk version &quot;21.0.x&quot; 2024-xx-xx
    OpenJDK Runtime Environment (build 21.0.x+x)
    OpenJDK 64-Bit Server VM (build 21.0.x+x, mixed mode, sharing)
</code></pre>
<ol>
 <li>
  Set JAVA_HOME (optional but recommended)
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/environment
</code></pre>
<pre><code>Add:
</code></pre>
<pre><code class="language-bash">    JAVA_HOME=&quot;/usr/lib/jvm/java-21-openjdk-amd64&quot;
</code></pre>
<pre><code>Apply changes:
</code></pre>
<pre><code class="language-bash">    source /etc/environment
    echo $JAVA_HOME
</code></pre>
<h3>
 Part 2: Install Jenkins LTS
</h3>
<p>
 Jenkins Long-Term Support (LTS) releases are recommended for production environments. Current LTS:
 <strong>
  2.528.3
 </strong>
</p>
<ol>
 <li>
  Add Jenkins repository key (both legacy and modern format for compatibility)
 </li>
</ol>
<pre><code class="language-bash">    # Modern keyring format (recommended)
    curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo gpg --dearmor -o /usr/share/keyrings/jenkins-archive-keyring.gpg

    # Also add legacy key for repository compatibility
    gpg --keyserver keyserver.ubuntu.com --recv-keys 7198F4B714ABFC68
    gpg --export 7198F4B714ABFC68 &gt; /tmp/jenkins-key.gpg
    sudo gpg --dearmor &lt; /tmp/jenkins-key.gpg &gt; /usr/share/keyrings/jenkins-old-keyring.gpg
</code></pre>
<ol>
 <li>
  Add Jenkins repository
 </li>
</ol>
<pre><code class="language-bash">    echo &quot;deb [signed-by=/usr/share/keyrings/jenkins-old-keyring.gpg] https://pkg.jenkins.io/debian-stable binary/&quot; | sudo tee /etc/apt/sources.list.d/jenkins.list &gt; /dev/null
</code></pre>
<ol>
 <li>
  Update package list
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
</code></pre>
<ol>
 <li>
  Install Jenkins (latest LTS)
 </li>
</ol>
<pre><code class="language-bash">    # Install latest LTS version
    sudo apt install -y jenkins

    # Or install specific LTS version
    # sudo apt install -y jenkins=2.528.3
</code></pre>
<ol>
 <li>
  Check installed version
 </li>
</ol>
<pre><code class="language-bash">    jenkins --version
</code></pre>
<pre><code>Expected: `2.528.3` or newer LTS
</code></pre>
<ol>
 <li>
  Enable Jenkins service
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl enable jenkins
</code></pre>
<ol>
 <li>
  Start Jenkins service
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Verify Jenkins is running
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status jenkins
</code></pre>
<pre><code>Expected: Active (running)
</code></pre>
<ol>
 <li>
  Check Jenkins is listening on port 8080
 </li>
</ol>
<pre><code class="language-bash">    sudo ss -tulnp | grep 8080
</code></pre>
<pre><code>Expected: Jenkins listening on 127.0.0.1:8080
</code></pre>
<h3>
 Part 2.1: Upgrade Jenkins to Latest LTS
</h3>
<p>
 To upgrade an existing Jenkins installation:
</p>
<ol>
 <li>
  Check current version
 </li>
</ol>
<pre><code class="language-bash">    jenkins --version
    # Or via API:
    curl -s -I https://jenkins.arpansahu.space/api/json | grep X-Jenkins
</code></pre>
<ol>
 <li>
  Check available versions
 </li>
</ol>
<pre><code class="language-bash">    apt-cache policy jenkins | head -30
</code></pre>
<pre><code>Note: Look for versions 2.xxx.x (LTS releases), not 2.5xx+ (weekly releases)
</code></pre>
<ol>
 <li>
  Backup Jenkins before upgrade
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -czf /tmp/jenkins-backup-$(date +%Y%m%d-%H%M%S).tar.gz /var/lib/jenkins/
</code></pre>
<ol>
 <li>
  Stop Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop jenkins
</code></pre>
<ol>
 <li>
  Upgrade to latest LTS
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
    sudo apt install --only-upgrade jenkins -y

    # Or install specific LTS version:
    # sudo apt install jenkins=2.528.3 -y
</code></pre>
<ol>
 <li>
  Start Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Verify upgrade
 </li>
</ol>
<pre><code class="language-bash">    jenkins --version
    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  <p>
   Check Jenkins UI
  </p>
  <p>
   https://jenkins.arpansahu.space ‚Üí Manage Jenkins ‚Üí About Jenkins
  </p>
 </li>
</ol>
<h3>
 Part 3: Configure Nginx Reverse Proxy
</h3>
<ol>
 <li>
  Edit Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/nginx/sites-available/services
</code></pre>
<ol>
 <li>
  Add Jenkins server block
 </li>
</ol>
<pre><code class="language-nginx">    # Jenkins CI/CD - HTTP ‚Üí HTTPS
    server {
        listen 80;
        listen [::]:80;
        server_name jenkins.arpansahu.space;
        return 301 https://$host$request_uri;
    }

    # Jenkins CI/CD - HTTPS
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name jenkins.arpansahu.space;

        ssl_certificate     /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;

        # Jenkins-specific timeouts
        proxy_read_timeout 300;
        proxy_connect_timeout 300;
        proxy_send_timeout 300;

        location / {
            proxy_pass http://127.0.0.1:8080;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;

            # Required for Jenkins CLI and agent connections
            proxy_http_version 1.1;
            proxy_request_buffering off;
        }
    }
</code></pre>
<ol>
 <li>
  Test Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nginx -t
</code></pre>
<ol>
 <li>
  Reload Nginx
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl reload nginx
</code></pre>
<h3>
 Part 4: Initial Jenkins Setup
</h3>
<ol>
 <li>
  Get initial admin password
 </li>
</ol>
<pre><code class="language-bash">    sudo cat /var/lib/jenkins/secrets/initialAdminPassword
</code></pre>
<pre><code>Copy this password (example: a1b2c3d4e5f6...)
</code></pre>
<ol>
 <li>
  <p>
   Access Jenkins Web UI
  </p>
  <p>
   Go to: https://jenkins.arpansahu.space
  </p>
 </li>
 <li>
  <p>
   Enter initial admin password
  </p>
  <p>
   Paste the password from step 1.
  </p>
 </li>
 <li>
  <p>
   Install suggested plugins
  </p>
  <ul>
   <li>
    Click: Install suggested plugins
   </li>
   <li>
    Wait for plugin installation (5-10 minutes)
   </li>
  </ul>
 </li>
 <li>
  <p>
   Create admin user
  </p>
  <p>
   Configure:
   <br/>
   - Username:
   <code>
    admin
   </code>
   <br/>
   - Password: (your strong password)
   <br/>
   - Full name:
   <code>
    Admin User
   </code>
   <br/>
   - Email: your-email@example.com
  </p>
  <p>
   Click: Save and Continue
  </p>
 </li>
 <li>
  <p>
   Configure Jenkins URL
  </p>
  <p>
   Jenkins URL:
   <code>
    https://jenkins.arpansahu.space
   </code>
  </p>
  <p>
   Click: Save and Finish
  </p>
 </li>
 <li>
  <p>
   Start using Jenkins
  </p>
  <p>
   Click: Start using Jenkins
  </p>
 </li>
</ol>
<h3>
 Part 5: Configure Jenkins Credentials
</h3>
<p>
 Jenkins stores credentials securely for use in pipelines. We'll configure 4 essential credentials.
</p>
<h4>
 5.1: GitHub Authentication Credentials
</h4>
<ol>
 <li>
  <p>
   Navigate to credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure GitHub credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    :
    <code>
     arpansahu
    </code>
    (your GitHub username)
   </li>
   <li>
    <strong>
     Password
    </strong>
    :
    <code>
     ghp_xxxxxxxxxxxx
    </code>
    (GitHub Personal Access Token)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     github-auth
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     Github Auth
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   Note: Generate GitHub PAT at https://github.com/settings/tokens with scopes: repo, admin:repo_hook
  </p>
 </li>
</ol>
<h4>
 5.2: Harbor Registry Credentials
</h4>
<ol>
 <li>
  <p>
   Add Harbor credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure Harbor credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    :
    <code>
     admin
    </code>
    (or robot account:
    <code>
     robot$ci-bot
    </code>
    )
   </li>
   <li>
    <strong>
     Password
    </strong>
    : (Harbor password or robot token)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     harbor-credentials
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     harbor-credentials
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
 </li>
</ol>
<h4>
 5.3: Jenkins Admin API Credentials
</h4>
<ol>
 <li>
  <p>
   Add Jenkins admin credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure Jenkins API credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    :
    <code>
     admin
    </code>
    (Jenkins admin username)
   </li>
   <li>
    <strong>
     Password
    </strong>
    : (Jenkins admin password)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     jenkins-admin-credentials
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     Jenkins admin credentials for API authentication and pipeline usage
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   Use case: Pipeline triggers, REST API calls, remote job execution
  </p>
 </li>
</ol>
<h4>
 5.4: Sentry Authentication Token
</h4>
<ol>
 <li>
  <p>
   Add Sentry CLI token
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure Sentry credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Secret text
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Secret
    </strong>
    : (Sentry auth token from https://sentry.io/settings/account/api/auth-tokens/)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     sentry-auth-token
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     Sentry CLI Authentication Token
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   Use case: Sentry release tracking, source map uploads, error monitoring integration
  </p>
 </li>
</ol>
<h4>
 5.5: GitHub Authentication Credentials
</h4>
<ol>
 <li>
  <p>
   Add GitHub credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure GitHub credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    : (GitHub username)
   </li>
   <li>
    <strong>
     Password
    </strong>
    : (GitHub Personal Access Token with repo permissions)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     github_auth
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     GitHub authentication for branch merging and repository operations
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   <strong>
    How to generate GitHub PAT:
   </strong>
   <br/>
   1. Go to GitHub ‚Üí Settings ‚Üí Developer settings ‚Üí Personal access tokens ‚Üí Tokens (classic)
   <br/>
   2. Generate new token with permissions:
   <code>
    repo
   </code>
   (Full control of private repositories)
   <br/>
   3. Copy token immediately (shown only once)
  </p>
  <p>
   Use case: Automated branch merging, repository operations, deployment workflows
  </p>
 </li>
</ol>
<h3>
 Part 6: Configure Global Jenkins Variables
</h3>
<p>
 Global variables are available to all Jenkins pipelines.
</p>
<ol>
 <li>
  <p>
   Navigate to system configuration
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System
  </p>
 </li>
 <li>
  <p>
   Scroll to Global properties
  </p>
  <p>
   Check: Environment variables
  </p>
 </li>
 <li>
  <p>
   Add global variables
  </p>
  <p>
   Click: Add (for each variable)
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Name
     </th>
     <th>
      Value
     </th>
     <th>
      Description
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      MAIL_JET_API_KEY
     </td>
     <td>
      (your Mailjet API key)
     </td>
     <td>
      Email notification service
     </td>
    </tr>
    <tr>
     <td>
      MAIL_JET_API_SECRET
     </td>
     <td>
      (your Mailjet secret)
     </td>
     <td>
      Email notification service
     </td>
    </tr>
    <tr>
     <td>
      MAIL_JET_EMAIL_ADDRESS
     </td>
     <td>
      noreply@arpansahu.space
     </td>
     <td>
      Sender email address
     </td>
    </tr>
    <tr>
     <td>
      MY_EMAIL_ADDRESS
     </td>
     <td>
      your-email@example.com
     </td>
     <td>
      Notification recipient
     </td>
    </tr>
   </tbody>
  </table>
 </li>
 <li>
  <p>
   Save configuration
  </p>
  <p>
   Scroll down and click: Save
  </p>
 </li>
</ol>
<h3>
 Part 7: Configure Jenkins for Docker Builds
</h3>
<p>
 Jenkins needs Docker access to build containerized applications.
</p>
<ol>
 <li>
  Add Jenkins user to Docker group
 </li>
</ol>
<pre><code class="language-bash">    sudo usermod -aG docker jenkins
</code></pre>
<ol>
 <li>
  Restart Jenkins to apply group changes
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl restart jenkins
</code></pre>
<ol>
 <li>
  Verify Jenkins can access Docker
 </li>
</ol>
<pre><code class="language-bash">    sudo -u jenkins docker ps
</code></pre>
<pre><code>Expected: Docker container list (even if empty)
</code></pre>
<h3>
 Part 8: Configure Jenkins Sudo Access (Optional)
</h3>
<p>
 Required if pipelines need to copy files from protected directories.
</p>
<ol>
 <li>
  Edit sudoers file
 </li>
</ol>
<pre><code class="language-bash">    sudo visudo
</code></pre>
<ol>
 <li>
  <p>
   Add Jenkins sudo permissions
  </p>
  <p>
   Add at end of file:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Allow Jenkins to run specific commands without password
    jenkins ALL=(ALL) NOPASSWD: /bin/cp, /bin/mkdir, /bin/chown
</code></pre>
<pre><code>Or for full sudo access (less secure):
</code></pre>
<pre><code class="language-bash">    jenkins ALL=(ALL) NOPASSWD: ALL
</code></pre>
<ol>
 <li>
  <p>
   Save and exit
  </p>
  <p>
   In nano:
   <code>
    Ctrl + O
   </code>
   ,
   <code>
    Enter
   </code>
   ,
   <code>
    Ctrl + X
   </code>
   <br/>
   In vi:
   <code>
    Esc
   </code>
   ,
   <code>
    :wq
   </code>
   ,
   <code>
    Enter
   </code>
  </p>
 </li>
 <li>
  <p>
   Verify sudo access
  </p>
 </li>
</ol>
<pre><code class="language-bash">    sudo -u jenkins sudo -l
</code></pre>
<h3>
 Part 9: Create Project Nginx Configuration
</h3>
<p>
 Each project needs its own Nginx configuration for deployment.
</p>
<ol>
 <li>
  Create project Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/nginx/sites-available/my-django-app
</code></pre>
<ol>
 <li>
  Add project server block (Docker deployment)
 </li>
</ol>
<pre><code class="language-nginx">    # Django App - HTTP ‚Üí HTTPS
    server {
        listen 80;
        listen [::]:80;
        server_name myapp.arpansahu.space;
        return 301 https://$host$request_uri;
    }

    # Django App - HTTPS
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name myapp.arpansahu.space;

        ssl_certificate     /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;

        location / {
            proxy_pass http://127.0.0.1:8000;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;

            # WebSocket support
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection &quot;upgrade&quot;;
        }
    }
</code></pre>
<ol>
 <li>
  <p>
   For Kubernetes deployment (alternative)
  </p>
  <p>
   Replace
   <code>
    proxy_pass
   </code>
   line:
  </p>
 </li>
</ol>
<pre><code class="language-nginx">    proxy_pass http://&lt;CLUSTER_IP&gt;:30080;
</code></pre>
<ol>
 <li>
  Enable site configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo ln -s /etc/nginx/sites-available/my-django-app /etc/nginx/sites-enabled/
</code></pre>
<ol>
 <li>
  Test Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nginx -t
</code></pre>
<ol>
 <li>
  Reload Nginx
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl reload nginx
</code></pre>
<h3>
 Part 10: Create Jenkinsfile for Build Pipeline
</h3>
<p>
 Create
 <code>
  Jenkinsfile-build
 </code>
 in your project repository root.
</p>
<p>
 Example Jenkinsfile-build:
</p>
<pre><code class="language-groovy">pipeline {
    agent { label &#x27;local&#x27; }

    environment {
        HARBOR_URL = &#x27;harbor.arpansahu.space&#x27;
        HARBOR_PROJECT = &#x27;library&#x27;
        IMAGE_NAME = &#x27;my-django-app&#x27;
        IMAGE_TAG = &quot;${env.BUILD_NUMBER}&quot;
    }

    stages {
        stage(&#x27;Checkout&#x27;) {
            steps {
                checkout scm
            }
        }

        stage(&#x27;Build Docker Image&#x27;) {
            steps {
                script {
                    docker.build(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:${IMAGE_TAG}&quot;)
                }
            }
        }

        stage(&#x27;Push to Harbor&#x27;) {
            steps {
                script {
                    docker.withRegistry(&quot;https://${HARBOR_URL}&quot;, &#x27;harbor-credentials&#x27;) {
                        docker.image(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:${IMAGE_TAG}&quot;).push()
                        docker.image(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:${IMAGE_TAG}&quot;).push(&#x27;latest&#x27;)
                    }
                }
            }
        }

        stage(&#x27;Trigger Deploy&#x27;) {
            steps {
                build job: &#x27;my-django-app-deploy&#x27;, wait: false
            }
        }
    }

    post {
        success {
            emailext(
                subject: &quot;Build Success: ${env.JOB_NAME} #${env.BUILD_NUMBER}&quot;,
                body: &quot;Build completed successfully.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
        failure {
            emailext(
                subject: &quot;Build Failed: ${env.JOB_NAME} #${env.BUILD_NUMBER}&quot;,
                body: &quot;Build failed. Check Jenkins console output.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
    }
}
</code></pre>
<h3>
 Part 11: Create Jenkinsfile for Deploy Pipeline
</h3>
<p>
 Create
 <code>
  Jenkinsfile-deploy
 </code>
 in your project repository root.
</p>
<p>
 Example Jenkinsfile-deploy:
</p>
<pre><code class="language-groovy">pipeline {
    agent { label &#x27;local&#x27; }

    environment {
        HARBOR_URL = &#x27;harbor.arpansahu.space&#x27;
        HARBOR_PROJECT = &#x27;library&#x27;
        IMAGE_NAME = &#x27;my-django-app&#x27;
        CONTAINER_NAME = &#x27;my-django-app&#x27;
        CONTAINER_PORT = &#x27;8000&#x27;
    }

    stages {
        stage(&#x27;Stop Old Container&#x27;) {
            steps {
                script {
                    sh &quot;&quot;&quot;
                        docker stop ${CONTAINER_NAME} || true
                        docker rm ${CONTAINER_NAME} || true
                    &quot;&quot;&quot;
                }
            }
        }

        stage(&#x27;Pull Latest Image&#x27;) {
            steps {
                script {
                    docker.withRegistry(&quot;https://${HARBOR_URL}&quot;, &#x27;harbor-credentials&#x27;) {
                        docker.image(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:latest&quot;).pull()
                    }
                }
            }
        }

        stage(&#x27;Deploy Container&#x27;) {
            steps {
                script {
                    sh &quot;&quot;&quot;
                        docker run -d \
                          --name ${CONTAINER_NAME} \
                          --restart unless-stopped \
                          -p ${CONTAINER_PORT}:8000 \
                          --env-file /var/lib/jenkins/.env/${IMAGE_NAME} \
                          ${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:latest
                    &quot;&quot;&quot;
                }
            }
        }

        stage(&#x27;Health Check&#x27;) {
            steps {
                script {
                    sleep(time: 10, unit: &#x27;SECONDS&#x27;)
                    sh &quot;curl -f http://localhost:${CONTAINER_PORT}/health || exit 1&quot;
                }
            }
        }
    }

    post {
        success {
            emailext(
                subject: &quot;Deploy Success: ${env.JOB_NAME}&quot;,
                body: &quot;Deployment completed successfully.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
        failure {
            emailext(
                subject: &quot;Deploy Failed: ${env.JOB_NAME}&quot;,
                body: &quot;Deployment failed. Check Jenkins console output.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
    }
}
</code></pre>
<h3>
 Part 12: Create Jenkins Pipeline Projects
</h3>
<h4>
 12.1: Create Build Pipeline
</h4>
<ol>
 <li>
  <p>
   Create new pipeline
  </p>
  <p>
   Dashboard ‚Üí New Item
  </p>
 </li>
 <li>
  <p>
   Configure pipeline
  </p>
  <ul>
   <li>
    <strong>
     Name
    </strong>
    :
    <code>
     my-django-app-build
    </code>
   </li>
   <li>
    <strong>
     Type
    </strong>
    : Pipeline
   </li>
   <li>
    Click: OK
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure pipeline settings
  </p>
  <ul>
   <li>
    <strong>
     Description
    </strong>
    : Build and push Docker image to Harbor
   </li>
   <li>
    <strong>
     GitHub project
    </strong>
    : (check and add your repo URL)
   </li>
   <li>
    <strong>
     Build Triggers
    </strong>
    : GitHub hook trigger for GITScm polling
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure Pipeline definition
  </p>
  <ul>
   <li>
    <strong>
     Definition
    </strong>
    : Pipeline script from SCM
   </li>
   <li>
    <strong>
     SCM
    </strong>
    : Git
   </li>
   <li>
    <strong>
     Repository URL
    </strong>
    :
    <code>
     https://github.com/arpansahu/my-django-app.git
    </code>
   </li>
   <li>
    <strong>
     Credentials
    </strong>
    :
    <code>
     github-auth
    </code>
   </li>
   <li>
    <strong>
     Branch
    </strong>
    :
    <code>
     */build
    </code>
   </li>
   <li>
    <strong>
     Script Path
    </strong>
    :
    <code>
     Jenkinsfile-build
    </code>
   </li>
  </ul>
 </li>
 <li>
  <p>
   Save pipeline
  </p>
  <p>
   Click: Save
  </p>
 </li>
</ol>
<h4>
 12.2: Create Deploy Pipeline
</h4>
<ol>
 <li>
  <p>
   Create new pipeline
  </p>
  <p>
   Dashboard ‚Üí New Item
  </p>
 </li>
 <li>
  <p>
   Configure pipeline
  </p>
  <ul>
   <li>
    <strong>
     Name
    </strong>
    :
    <code>
     my-django-app-deploy
    </code>
   </li>
   <li>
    <strong>
     Type
    </strong>
    : Pipeline
   </li>
   <li>
    Click: OK
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure pipeline settings
  </p>
  <ul>
   <li>
    <strong>
     Description
    </strong>
    : Deploy Docker container from Harbor
   </li>
   <li>
    <strong>
     Build Triggers
    </strong>
    : None (triggered by build pipeline)
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure Pipeline definition
  </p>
  <ul>
   <li>
    <strong>
     Definition
    </strong>
    : Pipeline script from SCM
   </li>
   <li>
    <strong>
     SCM
    </strong>
    : Git
   </li>
   <li>
    <strong>
     Repository URL
    </strong>
    :
    <code>
     https://github.com/arpansahu/my-django-app.git
    </code>
   </li>
   <li>
    <strong>
     Credentials
    </strong>
    :
    <code>
     github-auth
    </code>
   </li>
   <li>
    <strong>
     Branch
    </strong>
    :
    <code>
     */main
    </code>
   </li>
   <li>
    <strong>
     Script Path
    </strong>
    :
    <code>
     Jenkinsfile-deploy
    </code>
   </li>
  </ul>
 </li>
 <li>
  <p>
   Save pipeline
  </p>
  <p>
   Click: Save
  </p>
 </li>
</ol>
<h3>
 Part 13: Configure Environment Files
</h3>
<p>
 Store sensitive environment variables outside the repository.
</p>
<ol>
 <li>
  Create environment file directory
 </li>
</ol>
<pre><code class="language-bash">    sudo mkdir -p /var/lib/jenkins/.env
    sudo chown jenkins:jenkins /var/lib/jenkins/.env
</code></pre>
<ol>
 <li>
  Create project environment file
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /var/lib/jenkins/.env/my-django-app
</code></pre>
<ol>
 <li>
  Add environment variables
 </li>
</ol>
<pre><code class="language-bash">    # Django settings
    SECRET_KEY=your-secret-key-here
    DEBUG=False
    ALLOWED_HOSTS=myapp.arpansahu.space

    # Database
    DATABASE_URL=postgresql://user:pass@db:5432/myapp

    # Redis
    REDIS_URL=redis://redis:6379/0

    # Email
    EMAIL_BACKEND=django.core.mail.backends.smtp.EmailBackend
    EMAIL_HOST=smtp.mailjet.com
    EMAIL_PORT=587
    EMAIL_USE_TLS=True
    EMAIL_HOST_USER=your-mailjet-api-key
    EMAIL_HOST_PASSWORD=your-mailjet-secret

    # Sentry
    SENTRY_DSN=https://xxx@sentry.io/xxx
</code></pre>
<ol>
 <li>
  Set proper permissions
 </li>
</ol>
<pre><code class="language-bash">    sudo chown jenkins:jenkins /var/lib/jenkins/.env/my-django-app
    sudo chmod 600 /var/lib/jenkins/.env/my-django-app
</code></pre>
<h3>
 Part 14: Configure Email Notifications
</h3>
<ol>
 <li>
  <p>
   Install Email Extension Plugin
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Plugins ‚Üí Available plugins
  </p>
  <p>
   Search:
   <code>
    Email Extension Plugin
   </code>
  </p>
  <p>
   Click: Install
  </p>
 </li>
 <li>
  <p>
   Configure SMTP settings
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System ‚Üí Extended E-mail Notification
  </p>
  <p>
   Configure:
   <br/>
   -
   <strong>
    SMTP server
   </strong>
   :
   <code>
    in-v3.mailjet.com
   </code>
   <br/>
   -
   <strong>
    SMTP port
   </strong>
   :
   <code>
    587
   </code>
   <br/>
   -
   <strong>
    Use SMTP Authentication
   </strong>
   : ‚úì Checked
   <br/>
   -
   <strong>
    User Name
   </strong>
   :
   <code>
    ${MAIL_JET_API_KEY}
   </code>
   <br/>
   -
   <strong>
    Password
   </strong>
   :
   <code>
    ${MAIL_JET_API_SECRET}
   </code>
   <br/>
   -
   <strong>
    Use TLS
   </strong>
   : ‚úì Checked
   <br/>
   -
   <strong>
    Default user e-mail suffix
   </strong>
   :
   <code>
    @arpansahu.space
   </code>
  </p>
 </li>
 <li>
  <p>
   Test email configuration
  </p>
  <p>
   Click: Test configuration by sending test e-mail
  </p>
  <p>
   Enter:
   <code>
    ${MY_EMAIL_ADDRESS}
   </code>
  </p>
  <p>
   Expected: Email received
  </p>
 </li>
 <li>
  <p>
   Save configuration
  </p>
  <p>
   Click: Save
  </p>
 </li>
</ol>
<h3>
 Managing Jenkins Service
</h3>
<ol>
 <li>
  Check Jenkins status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  Stop Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop jenkins
</code></pre>
<ol>
 <li>
  Start Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Restart Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl restart jenkins
</code></pre>
<ol>
 <li>
  View Jenkins logs
 </li>
</ol>
<pre><code class="language-bash">    sudo journalctl -u jenkins -f
</code></pre>
<ol>
 <li>
  View Jenkins application logs
 </li>
</ol>
<pre><code class="language-bash">    sudo tail -f /var/log/jenkins/jenkins.log
</code></pre>
<h3>
 Backup and Restore
</h3>
<ol>
 <li>
  Backup Jenkins home directory
 </li>
</ol>
<pre><code class="language-bash">    # Stop Jenkins
    sudo systemctl stop jenkins

    # Backup Jenkins home
    sudo tar -czf jenkins-backup-$(date +%Y%m%d).tar.gz /var/lib/jenkins

    # Start Jenkins
    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Backup only critical data
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -czf jenkins-config-backup-$(date +%Y%m%d).tar.gz \
      /var/lib/jenkins/config.xml \
      /var/lib/jenkins/jobs/ \
      /var/lib/jenkins/users/ \
      /var/lib/jenkins/credentials.xml \
      /var/lib/jenkins/secrets/
</code></pre>
<ol>
 <li>
  Restore Jenkins backup
 </li>
</ol>
<pre><code class="language-bash">    # Stop Jenkins
    sudo systemctl stop jenkins

    # Restore backup
    sudo tar -xzf jenkins-backup-YYYYMMDD.tar.gz -C /

    # Set ownership
    sudo chown -R jenkins:jenkins /var/lib/jenkins

    # Start Jenkins
    sudo systemctl start jenkins
</code></pre>
<h3>
 Common Issues and Fixes
</h3>
<ol>
 <li>
  <p>
   Jenkins not starting
  </p>
  <p>
   Cause: Java not found or port conflict
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check Java installation
    java -version

    # Check if port 8080 is in use
    sudo ss -tulnp | grep 8080

    # Check Jenkins logs
    sudo journalctl -u jenkins -n 50
</code></pre>
<ol>
 <li>
  <p>
   Cannot push to Harbor from Jenkins
  </p>
  <p>
   Cause: Docker credentials or network issue
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Test Docker login as Jenkins user
    sudo -u jenkins docker login harbor.arpansahu.space

    # Check Jenkins can reach Harbor
    sudo -u jenkins curl -I https://harbor.arpansahu.space
</code></pre>
<ol>
 <li>
  <p>
   Pipeline fails with permission denied
  </p>
  <p>
   Cause: Jenkins doesn't have Docker access
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Add Jenkins to Docker group
    sudo usermod -aG docker jenkins

    # Restart Jenkins
    sudo systemctl restart jenkins

    # Verify
    sudo -u jenkins docker ps
</code></pre>
<ol>
 <li>
  <p>
   Email notifications not working
  </p>
  <p>
   Cause: SMTP configuration incorrect
  </p>
  <p>
   Fix:
  </p>
  <ul>
   <li>
    Verify Mailjet API credentials in global variables
   </li>
   <li>
    Check SMTP settings in Email Extension configuration
   </li>
   <li>
    Send test email from Jenkins
   </li>
   <li>
    Check Mailjet dashboard for send logs
   </li>
  </ul>
 </li>
 <li>
  <p>
   GitHub webhook not triggering builds
  </p>
  <p>
   Cause: Webhook not configured or firewall blocking
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Verify Jenkins is accessible from internet
    curl -I https://jenkins.arpansahu.space

    # Configure GitHub webhook
    # Repository ‚Üí Settings ‚Üí Webhooks ‚Üí Add webhook
    # Payload URL: https://jenkins.arpansahu.space/github-webhook/
    # Content type: application/json
    # Events: Just the push event
</code></pre>
<h3>
 Security Best Practices
</h3>
<ol>
 <li>
  <p>
   Use HTTPS only
  </p>
  <ul>
   <li>
    Never access Jenkins over HTTP
   </li>
   <li>
    Always use Nginx reverse proxy with TLS
   </li>
  </ul>
 </li>
 <li>
  <p>
   Strong authentication
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Enable security realm
    Dashboard ‚Üí Manage Jenkins ‚Üí Security ‚Üí Security Realm
    Select: Jenkins&#x27; own user database
</code></pre>
<ol>
 <li>
  <p>
   Enable CSRF protection
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Security ‚Üí CSRF Protection
   <br/>
   Check: Enable CSRF Protection
  </p>
 </li>
 <li>
  <p>
   Limit build agent connections
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Security ‚Üí Agents
   <br/>
   Set: Fixed port (50000) or disable
  </p>
 </li>
 <li>
  <p>
   Use credentials store
  </p>
  <ul>
   <li>
    Never hardcode credentials in Jenkinsfile
   </li>
   <li>
    Always use Jenkins credentials store
   </li>
   <li>
    Rotate credentials regularly
   </li>
  </ul>
 </li>
 <li>
  <p>
   Regular updates
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check for Jenkins updates
    Dashboard ‚Üí Manage Jenkins ‚Üí System Information

    # Update Jenkins
    sudo apt update
    sudo apt upgrade jenkins
</code></pre>
<ol>
 <li>
  Backup regularly
 </li>
</ol>
<pre><code class="language-bash">    # Automate with cron
    sudo crontab -e
</code></pre>
<pre><code>Add:
</code></pre>
<pre><code class="language-bash">    0 2 * * * /usr/local/bin/backup-jenkins.sh
</code></pre>
<h3>
 Performance Optimization
</h3>
<ol>
 <li>
  Increase Java heap size
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/default/jenkins
</code></pre>
<pre><code>Add/modify:
</code></pre>
<pre><code class="language-bash">    JAVA_ARGS=&quot;-Xmx2048m -Xms1024m&quot;
</code></pre>
<pre><code>Restart Jenkins:
</code></pre>
<pre><code class="language-bash">    sudo systemctl restart jenkins
</code></pre>
<ol>
 <li>
  <p>
   Clean old builds
  </p>
  <p>
   Configure in project:
   <br/>
   - Discard old builds
   <br/>
   - Keep max 10 builds
   <br/>
   - Keep builds for 7 days
  </p>
 </li>
 <li>
  <p>
   Use build agents
  </p>
  <p>
   Distribute builds across multiple machines instead of building everything on controller.
  </p>
 </li>
</ol>
<h3>
 Monitoring Jenkins
</h3>
<ol>
 <li>
  <p>
   Check Jenkins system info
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System Information
  </p>
 </li>
 <li>
  <p>
   Monitor disk usage
  </p>
 </li>
</ol>
<pre><code class="language-bash">    du -sh /var/lib/jenkins/*
</code></pre>
<ol>
 <li>
  <p>
   Monitor build queue
  </p>
  <p>
   Dashboard ‚Üí Build Queue (left sidebar)
  </p>
 </li>
 <li>
  <p>
   View build history
  </p>
  <p>
   Dashboard ‚Üí Build History (left sidebar)
  </p>
 </li>
</ol>
<h3>
 Final Verification Checklist
</h3>
<p>
 Run these commands to verify Jenkins is working:
</p>
<pre><code class="language-bash"># Check Jenkins service
sudo systemctl status jenkins

# Check Java version
java -version

# Check port binding
sudo ss -tulnp | grep 8080

# Check Nginx config
sudo nginx -t

# Test HTTPS access
curl -I https://jenkins.arpansahu.space

# Verify Docker access
sudo -u jenkins docker ps
</code></pre>
<p>
 Then test in browser:
 <br/>
 - Access: https://jenkins.arpansahu.space
 <br/>
 - Login with admin credentials
 <br/>
 - Verify all 4 credentials exist
 <br/>
 - Create test pipeline
 <br/>
 - Run manual build
 <br/>
 - Check email notification received
</p>
<h3>
 What This Setup Provides
</h3>
<p>
 After following this guide, you will have:
</p>
<ol>
 <li>
  Jenkins LTS with Java 21
 </li>
 <li>
  HTTPS access via Nginx reverse proxy
 </li>
 <li>
  4 configured credentials (GitHub, Harbor, Jenkins API, Sentry)
 </li>
 <li>
  Global environment variables for emails
 </li>
 <li>
  Docker integration for builds
 </li>
 <li>
  Email notifications via Mailjet
 </li>
 <li>
  Build and deploy pipeline examples
 </li>
 <li>
  Production-ready configuration
 </li>
 <li>
  Automatic startup with systemd
 </li>
 <li>
  Comprehensive monitoring and logging
 </li>
</ol>
<h3>
 Example Configuration Summary
</h3>
<table>
 <thead>
  <tr>
   <th>
    Component
   </th>
   <th>
    Value
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    Jenkins URL
   </td>
   <td>
    https://jenkins.arpansahu.space
   </td>
  </tr>
  <tr>
   <td>
    Jenkins Port
   </td>
   <td>
    8080 (localhost only)
   </td>
  </tr>
  <tr>
   <td>
    Jenkins Home
   </td>
   <td>
    /var/lib/jenkins
   </td>
  </tr>
  <tr>
   <td>
    Java Version
   </td>
   <td>
    OpenJDK 21
   </td>
  </tr>
  <tr>
   <td>
    Admin User
   </td>
   <td>
    admin
   </td>
  </tr>
  <tr>
   <td>
    Nginx Config
   </td>
   <td>
    /etc/nginx/sites-available/services
   </td>
  </tr>
 </tbody>
</table>
<h3>
 Architecture Summary
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (TLS Termination)
        ‚îÇ [Wildcard Certificate: *.arpansahu.space]
        ‚îÇ
        ‚îî‚îÄ jenkins.arpansahu.space (Port 443 ‚Üí 8080)
             ‚îÇ
             ‚îî‚îÄ Jenkins Controller
                  ‚îÇ
                  ‚îú‚îÄ Credentials Store
                  ‚îÇ   ‚îú‚îÄ github-auth
                  ‚îÇ   ‚îú‚îÄ harbor-credentials
                  ‚îÇ   ‚îú‚îÄ jenkins-admin-credentials
                  ‚îÇ   ‚îî‚îÄ sentry-auth-token
                  ‚îÇ
                  ‚îú‚îÄ Build Pipelines
                  ‚îÇ   ‚îú‚îÄ Jenkinsfile-build (Docker build + push)
                  ‚îÇ   ‚îî‚îÄ Jenkinsfile-deploy (Docker deploy)
                  ‚îÇ
                  ‚îî‚îÄ Integration
                      ‚îú‚îÄ GitHub (webhooks)
                      ‚îú‚îÄ Harbor (registry)
                      ‚îú‚îÄ Docker (builds)
                      ‚îú‚îÄ Mailjet (notifications)
                      ‚îî‚îÄ Sentry (error tracking)
</code></pre>
<h3>
 Key Rules to Remember
</h3>
<ol>
 <li>
  Jenkins port 8080 never exposed externally
 </li>
 <li>
  Always use credentials store, never hardcode
 </li>
 <li>
  Use Jenkinsfile for pipeline as code
 </li>
 <li>
  Separate build and deploy pipelines
 </li>
 <li>
  Store .env files outside repository
 </li>
 <li>
  Enable email notifications for failures
 </li>
 <li>
  Regular backups of /var/lib/jenkins
 </li>
 <li>
  Keep Jenkins and plugins updated
 </li>
 <li>
  Use Harbor for private registry
 </li>
 <li>
  Monitor build queue and disk usage
 </li>
</ol>
<h3>
 Next Steps
</h3>
<p>
 After setting up Jenkins:
</p>
<ol>
 <li>
  Configure GitHub webhooks for automatic builds
 </li>
 <li>
  Create pipelines for each project
 </li>
 <li>
  Set up build agents for distributed builds
 </li>
 <li>
  Configure Slack/Teams notifications
 </li>
 <li>
  Implement automated testing in pipelines
 </li>
 <li>
  Set up deployment approvals
 </li>
 <li>
  Configure Jenkins metrics monitoring
 </li>
</ol>
<p>
 My Jenkins instance: https://jenkins.arpansahu.space
</p>
<p>
 For Harbor integration, see harbor.md documentation.
</p>
<h1>
 Backend Services Used
</h1>
<h2>
 PostgreSQL Server (System Service)
</h2>
<p>
 PostgreSQL is a powerful, open-source relational database system. This setup installs PostgreSQL as a native system service with remote access enabled.
</p>
<hr/>
<h2>
 Test Files Overview
</h2>
<table>
 <thead>
  <tr>
   <th>
    Test File
   </th>
   <th>
    Where to Run
   </th>
   <th>
    Connection Type
   </th>
   <th>
    Purpose
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <code>
     test_postgres_localhost.py
    </code>
   </td>
   <td>
    <strong>
     On Server
    </strong>
   </td>
   <td>
    localhost:5432
   </td>
   <td>
    Test PostgreSQL on server without TLS
   </td>
  </tr>
  <tr>
   <td>
    <code>
     test_postgres_mac.sh
    </code>
   </td>
   <td>
    <strong>
     From Mac
    </strong>
   </td>
   <td>
    192.168.1.200:5432
   </td>
   <td>
    Test PostgreSQL from Mac (direct IP, no TLS)
   </td>
  </tr>
  <tr>
   <td>
    <code>
     test_postgres_domain_tls.sh
    </code>
   </td>
   <td>
    <strong>
     From Mac
    </strong>
   </td>
   <td>
    postgres.arpansahu.space:9552
   </td>
   <td>
    Test PostgreSQL from Mac with TLS via domain
   </td>
  </tr>
 </tbody>
</table>
<p>
 <strong>
  Quick Test Commands:
 </strong>
</p>
<pre><code class="language-bash"># On Server (localhost)
python3 test_postgres_localhost.py

# From Mac (direct IP, no TLS)
PG_PASSWORD=your_password ./test_postgres_mac.sh

# From Mac (domain with TLS)
PG_PASSWORD=your_password ./test_postgres_domain_tls.sh
</code></pre>
<p>
 <strong>
  CLI Testing (psql):
 </strong>
</p>
<pre><code class="language-bash"># On Server (localhost) - As postgres superuser
sudo -u postgres psql -c &quot;SELECT version();&quot;
sudo -u postgres psql -c &quot;\l&quot;  # List databases

# On Server (localhost) - With password auth
psql -h localhost -U postgres -d postgres -c &quot;SELECT current_database(), current_user, version();&quot;

# From Mac (direct IP, no TLS)
export PGPASSWORD=your_password
psql -h 192.168.1.200 -p 5432 -U postgres -d postgres -c &quot;SELECT version();&quot;

# From Mac (domain with TLS)
export PGPASSWORD=your_password
psql &quot;host=postgres.arpansahu.space port=9552 user=postgres dbname=postgres sslmode=require&quot; -c &quot;SELECT version();&quot;

# Interactive connection with TLS
psql &quot;host=postgres.arpansahu.space port=9552 user=postgres dbname=postgres sslmode=require&quot;
</code></pre>
<hr/>
<h2>
 Step-by-Step Installation Guide
</h2>
<h3>
 Step 1: Create Environment Configuration
</h3>
<p>
 First, create the environment configuration file that will store your PostgreSQL password.
</p>
<p>
 <strong>
  Create
  <code>
   .env.example
  </code>
  (Template file):
 </strong>
</p>
<pre><code class="language-bash"># PostgreSQL Configuration
POSTGRES_PASSWORD=your_secure_password_here
</code></pre>
<p>
 <strong>
  Create your actual
  <code>
   .env
  </code>
  file:
 </strong>
</p>
<pre><code class="language-bash">cd &quot;AWS Deployment/Postgres&quot;
cp .env.example .env
nano .env
</code></pre>
<p>
 <strong>
  Your
  <code>
   .env
  </code>
  file should look like this (with your actual password):
 </strong>
</p>
<pre><code class="language-bash"># PostgreSQL Configuration
POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
</code></pre>
<p>
 <strong>
  ‚ö†Ô∏è Important:
 </strong>
 <br/>
 - Always use a strong password in production!
 <br/>
 - Never commit your
 <code>
  .env
 </code>
 file to version control
 <br/>
 - Keep the
 <code>
  .env.example
 </code>
 file as a template
</p>
<hr/>
<h3>
 Step 2: Create Installation Script
</h3>
<p>
 The
 <code>
  install.sh
 </code>
 script installs PostgreSQL and configures it for remote access.
</p>
<p>
 <strong>
  Content of
  <code>
   install.sh
  </code>
  :
 </strong>
</p>
<pre><code class="language-bash">#!/bin/bash
set -e

echo &quot;=== PostgreSQL Installation Script ===&quot;

# Colors
GREEN=&#x27;\033[0;32m&#x27;
YELLOW=&#x27;\033[1;33m&#x27;
NC=&#x27;\033[0m&#x27;

# Load environment variables
SCRIPT_DIR=&quot;$(cd &quot;$(dirname &quot;${BASH_SOURCE[0]}&quot;)&quot; &amp;&amp; pwd)&quot;
if [ -f &quot;$SCRIPT_DIR/.env&quot; ]; then
    export $(grep -v &#x27;^#&#x27; &quot;$SCRIPT_DIR/.env&quot; | xargs)
    echo -e &quot;${GREEN}Loaded configuration from .env file${NC}&quot;
else
    echo -e &quot;${YELLOW}Warning: .env file not found. Using defaults.${NC}&quot;
    echo -e &quot;${YELLOW}Please copy .env.example to .env and configure it.${NC}&quot;
fi

# Configuration with defaults
POSTGRES_PASSWORD=&quot;${POSTGRES_PASSWORD:-changeme}&quot;

echo -e &quot;${YELLOW}Step 1: Installing PostgreSQL${NC}&quot;
sudo apt update
sudo apt install -y postgresql postgresql-contrib

echo -e &quot;${YELLOW}Step 2: Starting PostgreSQL${NC}&quot;
sudo systemctl start postgresql
sudo systemctl enable postgresql

echo -e &quot;${YELLOW}Step 3: Setting postgres user password${NC}&quot;
sudo -u postgres psql -c &quot;ALTER USER postgres WITH PASSWORD &#x27;$POSTGRES_PASSWORD&#x27;;&quot;

echo -e &quot;${YELLOW}Step 4: Configuring PostgreSQL for remote connections${NC}&quot;
# Backup original config
sudo cp /etc/postgresql/*/main/postgresql.conf /etc/postgresql/*/main/postgresql.conf.bak
sudo cp /etc/postgresql/*/main/pg_hba.conf /etc/postgresql/*/main/pg_hba.conf.bak

# Allow remote connections
PG_VERSION=$(ls /etc/postgresql/)
echo &quot;listen_addresses = &#x27;*&#x27;&quot; | sudo tee -a /etc/postgresql/$PG_VERSION/main/postgresql.conf

# Allow password authentication
echo &quot;host    all             all             0.0.0.0/0               md5&quot; | sudo tee -a /etc/postgresql/$PG_VERSION/main/pg_hba.conf
echo &quot;host    all             all             ::/0                    md5&quot; | sudo tee -a /etc/postgresql/$PG_VERSION/main/pg_hba.conf

echo -e &quot;${YELLOW}Step 5: Restarting PostgreSQL${NC}&quot;
sudo systemctl restart postgresql

echo -e &quot;${YELLOW}Step 6: Verifying Installation${NC}&quot;
sudo -u postgres psql -c &quot;SELECT version();&quot;

echo -e &quot;${GREEN}PostgreSQL installed successfully!${NC}&quot;
echo -e &quot;Connection details:&quot;
echo -e &quot;  Host: localhost (or 192.168.1.200)&quot;
echo -e &quot;  Port: 5432&quot;
echo -e &quot;  User: postgres&quot;
echo -e &quot;  Password: $POSTGRES_PASSWORD&quot;
echo &quot;&quot;
echo -e &quot;${YELLOW}Test connection:${NC}&quot;
echo &quot;  psql -h localhost -U postgres -d postgres&quot;
</code></pre>
<p>
 <strong>
  What this script does:
 </strong>
 <br/>
 - Installs PostgreSQL and contrib packages
 <br/>
 - Enables PostgreSQL service to start on boot
 <br/>
 - Sets password for
 <code>
  postgres
 </code>
 superuser
 <br/>
 - Configures PostgreSQL to accept remote connections
 <br/>
 - Updates authentication to use password (md5)
 <br/>
 - Backs up original configuration files
</p>
<p>
 <strong>
  Run the installation:
 </strong>
</p>
<pre><code class="language-bash">chmod +x install.sh
./install.sh
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>=== PostgreSQL Installation Script ===
Loaded configuration from .env file
Step 1: Installing PostgreSQL
Step 2: Starting PostgreSQL
Step 3: Setting postgres user password
ALTER ROLE
Step 4: Configuring PostgreSQL for remote connections
Step 5: Restarting PostgreSQL
Step 6: Verifying Installation
PostgreSQL installed successfully!
</code></pre>
<hr/>
<h2>
 Testing Your PostgreSQL Installation
</h2>
<h3>
 Test 1: Check Service Status
</h3>
<p>
 Verify that PostgreSQL service is running:
</p>
<pre><code class="language-bash"># Check service status
sudo systemctl status postgresql

# Check if port is listening
sudo ss -lntp | grep 5432
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>Active: active (exited) since ...
LISTEN 0 244 0.0.0.0:5432 0.0.0.0:*
</code></pre>
<hr/>
<h3>
 Test 2: Connect Locally
</h3>
<p>
 Test PostgreSQL connection from the server:
</p>
<pre><code class="language-bash"># Connect as postgres user
sudo -u postgres psql

# Or with password authentication
psql -h localhost -U postgres -d postgres
# Enter password when prompted
</code></pre>
<hr/>
<h3>
 Test 3: Check Version and Databases
</h3>
<pre><code class="language-bash"># Check version
sudo -u postgres psql -c &quot;SELECT version();&quot;

# List databases
sudo -u postgres psql -c &quot;\l&quot;

# List users
sudo -u postgres psql -c &quot;\du&quot;
</code></pre>
<hr/>
<h2>
 Automated Connection Testing
</h2>
<h3>
 Test Script 1: Server Connection Test (Python)
</h3>
<p>
 This script tests PostgreSQL connectivity from the server using psycopg2.
</p>
<p>
 <strong>
  Create
  <code>
   test_postgres_server.py
  </code>
  file:
 </strong>
</p>
<pre><code class="language-python">#!/usr/bin/env python3
&quot;&quot;&quot;
PostgreSQL Server Connection Test
Tests PostgreSQL connectivity from the server using psycopg2
&quot;&quot;&quot;

import sys

try:
    import psycopg2
except ImportError:
    print(&quot;‚úó Error: psycopg2 not installed&quot;)
    print(&quot;Install with: pip3 install psycopg2-binary&quot;)
    sys.exit(1)

def test_postgres():
    try:
        print(&quot;=== Testing PostgreSQL Connection from Server ===\n&quot;)

        # Connection parameters
        conn_params = {
            &#x27;host&#x27;: &#x27;localhost&#x27;,
            &#x27;port&#x27;: 5432,
            &#x27;user&#x27;: &#x27;postgres&#x27;,
            &#x27;password&#x27;: &#x27;${POSTGRES_PASSWORD}&#x27;,
            &#x27;database&#x27;: &#x27;postgres&#x27;
        }

        print(f&quot;Connecting to PostgreSQL at {conn_params[&#x27;host&#x27;]}:{conn_params[&#x27;port&#x27;]}...&quot;)
        conn = psycopg2.connect(**conn_params)
        print(&quot;‚úì Connection successful\n&quot;)

        # Get version
        cursor = conn.cursor()
        cursor.execute(&quot;SELECT version();&quot;)
        version = cursor.fetchone()[0]
        print(f&quot;‚úì PostgreSQL version: {version.split(&#x27;,&#x27;)[0]}\n&quot;)

        # Test database operations
        cursor.execute(&quot;CREATE TABLE IF NOT EXISTS test_table (id SERIAL PRIMARY KEY, data TEXT);&quot;)
        print(&quot;‚úì Table created: test_table\n&quot;)

        cursor.execute(&quot;INSERT INTO test_table (data) VALUES (%s) RETURNING id;&quot;, (&quot;Hello from Server!&quot;,))
        test_id = cursor.fetchone()[0]
        conn.commit()
        print(f&quot;‚úì Record inserted with ID: {test_id}\n&quot;)

        cursor.execute(&quot;SELECT * FROM test_table WHERE id = %s;&quot;, (test_id,))
        record = cursor.fetchone()
        print(f&quot;‚úì Record retrieved: ID={record[0]}, Data={record[1]}\n&quot;)

        # Clean up
        cursor.execute(&quot;DROP TABLE test_table;&quot;)
        conn.commit()
        print(&quot;‚úì Test table dropped\n&quot;)

        cursor.close()
        conn.close()

        print(&quot;‚úì All tests passed!&quot;)
        print(&quot;‚úì PostgreSQL is working correctly\n&quot;)
        return 0

    except psycopg2.OperationalError as e:
        print(f&quot;‚úó Connection Error: {e}&quot;)
        print(&quot;  Check if PostgreSQL is running: sudo systemctl status postgresql&quot;)
        return 1
    except psycopg2.Error as e:
        print(f&quot;‚úó Database Error: {e}&quot;)
        return 1
    except Exception as e:
        print(f&quot;‚úó Error: {e}&quot;)
        return 1

if __name__ == &quot;__main__&quot;:
    sys.exit(test_postgres())
</code></pre>
<p>
 <strong>
  Run on server:
 </strong>
</p>
<pre><code class="language-bash"># Install psycopg2 if not already installed
pip3 install psycopg2-binary

# Run the test
python3 test_postgres_server.py
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>=== Testing PostgreSQL Connection from Server ===

Connecting to PostgreSQL at localhost:5432...
‚úì Connection successful

‚úì PostgreSQL version: PostgreSQL 14.x

‚úì Table created: test_table

‚úì Record inserted with ID: 1

‚úì Record retrieved: ID=1, Data=Hello from Server!

‚úì Test table dropped

‚úì All tests passed!
‚úì PostgreSQL is working correctly
</code></pre>
<hr/>
<h3>
 Test Script 2: Mac Connection Test (Shell Script)
</h3>
<p>
 This script tests PostgreSQL connectivity from your Mac.
</p>
<p>
 <strong>
  Create
  <code>
   test_postgres_mac.sh
  </code>
  file:
 </strong>
</p>
<pre><code class="language-bash">#!/bin/bash

# PostgreSQL Mac Connection Test
# Tests PostgreSQL connectivity from your Mac

set -e

echo &quot;=== Testing PostgreSQL Connection from Mac ===&quot;
echo &quot;&quot;

# Colors
GREEN=&#x27;\033[0;32m&#x27;
RED=&#x27;\033[0;31m&#x27;
YELLOW=&#x27;\033[1;33m&#x27;
NC=&#x27;\033[0m&#x27; # No Color

# Configuration
PG_HOST=&quot;${PG_HOST:-192.168.1.200}&quot;
PG_PORT=&quot;${PG_PORT:-5432}&quot;
PG_USER=&quot;${PG_USER:-postgres}&quot;
PG_PASSWORD=&quot;${PG_PASSWORD:-changeme}&quot;
PG_DATABASE=&quot;${PG_DATABASE:-postgres}&quot;

# Test 1: Check if PostgreSQL is accessible
echo -e &quot;${YELLOW}Test 1: Checking PostgreSQL accessibility...${NC}&quot;
if command -v psql &amp;&gt; /dev/null; then
    export PGPASSWORD=&quot;$PG_PASSWORD&quot;
    if psql -h &quot;$PG_HOST&quot; -p &quot;$PG_PORT&quot; -U &quot;$PG_USER&quot; -d &quot;$PG_DATABASE&quot; -c &quot;SELECT 1;&quot; &gt; /dev/null 2&gt;&amp;1; then
        echo -e &quot;${GREEN}‚úì PostgreSQL is accessible${NC}&quot;
    else
        echo -e &quot;${RED}‚úó Failed to connect to PostgreSQL${NC}&quot;
        echo &quot;  Make sure PostgreSQL is configured to allow remote connections&quot;
        exit 1
    fi
else
    echo -e &quot;${RED}‚úó psql command not found${NC}&quot;
    echo &quot;  Install with: brew install postgresql&quot;
    exit 1
fi
echo &quot;&quot;

# Test 2: Get PostgreSQL version
echo -e &quot;${YELLOW}Test 2: Getting PostgreSQL version...${NC}&quot;
VERSION=$(psql -h &quot;$PG_HOST&quot; -p &quot;$PG_PORT&quot; -U &quot;$PG_USER&quot; -d &quot;$PG_DATABASE&quot; -t -c &quot;SELECT version();&quot; 2&gt;/dev/null | xargs)
echo -e &quot;${GREEN}‚úì PostgreSQL version: ${VERSION:0:50}...${NC}&quot;
echo &quot;&quot;

# Test 3: List databases
echo -e &quot;${YELLOW}Test 3: Listing databases...${NC}&quot;
DATABASES=$(psql -h &quot;$PG_HOST&quot; -p &quot;$PG_PORT&quot; -U &quot;$PG_USER&quot; -d &quot;$PG_DATABASE&quot; -t -c &quot;\l&quot; 2&gt;/dev/null | grep -c &quot;|&quot;)
echo -e &quot;${GREEN}‚úì Found $DATABASES databases${NC}&quot;
echo &quot;&quot;

# Test 4: Create test table
echo -e &quot;${YELLOW}Test 4: Creating test table...${NC}&quot;
psql -h &quot;$PG_HOST&quot; -p &quot;$PG_PORT&quot; -U &quot;$PG_USER&quot; -d &quot;$PG_DATABASE&quot; -c &quot;CREATE TABLE IF NOT EXISTS mac_test_table (id SERIAL PRIMARY KEY, data TEXT, created_at TIMESTAMP DEFAULT NOW());&quot; &gt; /dev/null 2&gt;&amp;1
echo -e &quot;${GREEN}‚úì Test table created${NC}&quot;
echo &quot;&quot;

# Test 5: Insert and retrieve data
echo -e &quot;${YELLOW}Test 5: Testing data operations...${NC}&quot;
psql -h &quot;$PG_HOST&quot; -p &quot;$PG_PORT&quot; -U &quot;$PG_USER&quot; -d &quot;$PG_DATABASE&quot; -c &quot;INSERT INTO mac_test_table (data) VALUES (&#x27;Hello from Mac!&#x27;);&quot; &gt; /dev/null 2&gt;&amp;1
RECORD=$(psql -h &quot;$PG_HOST&quot; -p &quot;$PG_PORT&quot; -U &quot;$PG_USER&quot; -d &quot;$PG_DATABASE&quot; -t -c &quot;SELECT data FROM mac_test_table ORDER BY id DESC LIMIT 1;&quot; 2&gt;/dev/null | xargs)
echo -e &quot;${GREEN}‚úì Record inserted and retrieved: &#x27;$RECORD&#x27;${NC}&quot;
echo &quot;&quot;

# Test 6: Clean up
echo -e &quot;${YELLOW}Test 6: Cleaning up test table...${NC}&quot;
psql -h &quot;$PG_HOST&quot; -p &quot;$PG_PORT&quot; -U &quot;$PG_USER&quot; -d &quot;$PG_DATABASE&quot; -c &quot;DROP TABLE IF EXISTS mac_test_table;&quot; &gt; /dev/null 2&gt;&amp;1
echo -e &quot;${GREEN}‚úì Test table dropped${NC}&quot;
echo &quot;&quot;

# Unset password
unset PGPASSWORD

echo -e &quot;${GREEN}========================================${NC}&quot;
echo -e &quot;${GREEN}‚úì All tests passed!${NC}&quot;
echo -e &quot;${GREEN}‚úì PostgreSQL is working correctly${NC}&quot;
echo -e &quot;${GREEN}========================================${NC}&quot;
</code></pre>
<p>
 <strong>
  Run from your Mac:
 </strong>
</p>
<pre><code class="language-bash"># Make script executable
chmod +x test_postgres_mac.sh

# Set environment variables (optional)
export PG_HOST=192.168.1.200
export PG_USER=postgres
export PG_PASSWORD=your_password

# Run the test
./test_postgres_mac.sh
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>=== Testing PostgreSQL Connection from Mac ===

Test 1: Checking PostgreSQL accessibility...
‚úì PostgreSQL is accessible

Test 2: Getting PostgreSQL version...
‚úì PostgreSQL version: PostgreSQL 14.x (Ubuntu 14.x-1.pgdg22.04+1) on x86...

Test 3: Listing databases...
‚úì Found 3 databases

Test 4: Creating test table...
‚úì Test table created

Test 5: Testing data operations...
‚úì Record inserted and retrieved: &#x27;Hello from Mac!&#x27;

Test 6: Cleaning up test table...
‚úì Test table dropped

========================================
‚úì All tests passed!
‚úì PostgreSQL is working correctly
========================================
</code></pre>
<hr/>
<h2>
 Secure Remote Access via Nginx TLS
</h2>
<p>
 For secure connections from outside your local network, you can set up an nginx stream proxy with TLS encryption.
</p>
<h3>
 Step 1: Create Nginx Stream Configuration
</h3>
<p>
 <strong>
  Create
  <code>
   nginx-stream.conf
  </code>
  file:
 </strong>
</p>
<pre><code class="language-nginx"># Add this to the stream block in /etc/nginx/nginx.conf

    # PostgreSQL TCP Passthrough (PostgreSQL handles SSL itself)
    # Note: Unlike Redis, PostgreSQL uses binary protocol that cannot work
    # through nginx SSL termination. We use TCP passthrough instead.
    upstream postgres_backend {
        server 127.0.0.1:5432;
    }

    server {
        listen 9552;
        proxy_pass postgres_backend;
        proxy_connect_timeout 10s;
        proxy_timeout 300s;
    }
</code></pre>
<p>
 <strong>
  Important: Why TCP Passthrough Instead of SSL Termination?
 </strong>
</p>
<p>
 PostgreSQL uses a complex binary protocol with specific handshake requirements that get corrupted when nginx terminates SSL and forwards plain TCP. This is different from Redis, which uses a simple text-based protocol that works fine with nginx SSL termination.
</p>
<p>
 With TCP passthrough:
 <br/>
 - Nginx simply forwards TCP packets without decryption (no SSL configuration on nginx)
 <br/>
 - PostgreSQL handles SSL/TLS encryption itself (already configured in
 <code>
  postgresql.conf
 </code>
 with
 <code>
  ssl=on
 </code>
 )
 <br/>
 - Connection is still encrypted end-to-end using PostgreSQL's native SSL
 <br/>
 - Port 9552 is used instead of default 5432 for security (avoiding bot scans on standard ports)
</p>
<hr/>
<h3>
 Step 2: Configure Router Port Forwarding
</h3>
<p>
 <strong>
  ‚ö†Ô∏è Required for external access (from outside your home network)
 </strong>
</p>
<p>
 If you want to access PostgreSQL from outside your local network (e.g., from mobile data, other locations), you need to configure port forwarding on your router.
</p>
<p>
 <strong>
  Steps for Airtel Router:
 </strong>
</p>
<ol>
 <li>
  <strong>
   Login to router admin panel:
  </strong>
 </li>
 <li>
  Open browser and go to:
  <code>
   http://192.168.1.1
  </code>
 </li>
 <li>
  <p>
   Enter admin credentials
  </p>
 </li>
 <li>
  <p>
   <strong>
    Navigate to Port Forwarding:
   </strong>
  </p>
 </li>
 <li>
  Go to
  <code>
   NAT
  </code>
  ‚Üí
  <code>
   Port Forwarding
  </code>
  tab
 </li>
 <li>
  <p>
   Click "Add new rule"
  </p>
 </li>
 <li>
  <p>
   <strong>
    Configure port forwarding rule:
   </strong>
  </p>
 </li>
 <li>
  <strong>
   Service Name:
  </strong>
  User Define
 </li>
 <li>
  <strong>
   External Start Port:
  </strong>
  9552
 </li>
 <li>
  <strong>
   External End Port:
  </strong>
  9552
 </li>
 <li>
  <strong>
   Internal Start Port:
  </strong>
  9552
 </li>
 <li>
  <strong>
   Internal End Port:
  </strong>
  9552
 </li>
 <li>
  <strong>
   Server IP Address:
  </strong>
  192.168.1.200 (your server's local IP)
 </li>
 <li>
  <p>
   <strong>
    Protocol:
   </strong>
   TCP (or TCP/UDP)
  </p>
 </li>
 <li>
  <p>
   <strong>
    Activate the rule:
   </strong>
  </p>
 </li>
 <li>
  Click save/apply
 </li>
 <li>
  The rule should appear in the port forwarding list with status "Active"
 </li>
</ol>
<p>
 <strong>
  Verify port forwarding:
 </strong>
</p>
<pre><code class="language-bash"># From external network (mobile data or different location)
psql &quot;host=postgres.arpansahu.space port=9552 user=postgres dbname=postgres sslmode=require&quot; -c &quot;SELECT version();&quot;
</code></pre>
<p>
 <strong>
  Note:
 </strong>
 Port forwarding is NOT required if you only access PostgreSQL from devices on the same local network (192.168.1.x).
</p>
<hr/>
<h3>
 Step 3: Create Automated Setup Script
</h3>
<p>
 <strong>
  Create
  <code>
   add-nginx-stream.sh
  </code>
  file:
 </strong>
</p>
<pre><code class="language-bash">#!/bin/bash
set -e

echo &quot;=== PostgreSQL Nginx Stream Configuration Script ===&quot;

# Colors
GREEN=&#x27;\033[0;32m&#x27;
YELLOW=&#x27;\033[1;33m&#x27;
RED=&#x27;\033[0;31m&#x27;
NC=&#x27;\033[0m&#x27;

# Check if running as root
if [ &quot;$EUID&quot; -ne 0 ]; then 
    echo -e &quot;${RED}Please run with sudo${NC}&quot;
    exit 1
fi

echo -e &quot;${YELLOW}Step 1: Backing up nginx.conf${NC}&quot;
cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.backup-postgres-$(date +%Y%m%d-%H%M%S)

echo -e &quot;${YELLOW}Step 2: Adding PostgreSQL stream configuration${NC}&quot;
# Check if stream block already exists
if ! grep -q &quot;stream {&quot; /etc/nginx/nginx.conf; then
    echo -e &quot;${YELLOW}Stream block not found, adding it to nginx.conf${NC}&quot;
    cat &gt;&gt; /etc/nginx/nginx.conf &lt;&lt; &#x27;EOF&#x27;

# Stream configuration for TCP/UDP load balancing
stream {
    # PostgreSQL TCP Passthrough (PostgreSQL handles SSL itself)
    upstream postgres_backend {
        server 127.0.0.1:5432;
    }

    server {
        listen 9552;
        proxy_pass postgres_backend;
        proxy_connect_timeout 10s;
        proxy_timeout 300s;
    }
}
EOF
    echo -e &quot;${GREEN}Stream block with PostgreSQL configuration added${NC}&quot;
else
    # Check if PostgreSQL stream config already exists
    if grep -q &quot;# PostgreSQL&quot; /etc/nginx/nginx.conf; then
        echo -e &quot;${YELLOW}PostgreSQL stream configuration already exists, skipping...${NC}&quot;
    else
        # Get the script directory
        SCRIPT_DIR=&quot;$(cd &quot;$(dirname &quot;${BASH_SOURCE[0]}&quot;)&quot; &amp;&amp; pwd)&quot;

        # Insert the configuration before the closing brace of the stream block
        # Read the stream config and append it
        grep -v &quot;^# Add this to&quot; &quot;$SCRIPT_DIR/nginx-stream.conf&quot; | \
            sed -i &#x27;/^stream {/r /dev/stdin&#x27; /etc/nginx/nginx.conf

        echo -e &quot;${GREEN}PostgreSQL stream configuration added${NC}&quot;
    fi
fi

echo -e &quot;${YELLOW}Step 3: Testing nginx configuration${NC}&quot;
if nginx -t; then
    echo -e &quot;${GREEN}Nginx configuration is valid${NC}&quot;
else
    echo -e &quot;${RED}Nginx configuration test failed!${NC}&quot;
    echo &quot;Restoring backup...&quot;
    cp /etc/nginx/nginx.conf.backup-postgres-$(date +%Y%m%d-%H%M%S) /etc/nginx/nginx.conf
    exit 1
fi

echo -e &quot;${YELLOW}Step 4: Reloading nginx${NC}&quot;
systemctl reload nginx

echo -e &quot;${YELLOW}Step 5: Checking if port 9552 is listening${NC}&quot;
sleep 2
if ss -lntp | grep -q &quot;:9552&quot;; then
    echo -e &quot;${GREEN}‚úì Nginx is listening on port 9552${NC}&quot;
else
    echo -e &quot;${RED}‚úó Port 9552 is not listening${NC}&quot;
    exit 1
fi

echo -e &quot;${GREEN}========================================${NC}&quot;
echo -e &quot;${GREEN}PostgreSQL Nginx Stream Setup Complete!${NC}&quot;
echo -e &quot;${GREEN}========================================${NC}&quot;
echo &quot;&quot;
echo &quot;PostgreSQL is now accessible via:&quot;
echo &quot;  - Local: localhost:5432&quot;
echo &quot;  - TLS (via nginx): postgres.arpansahu.space:9552&quot;
echo &quot;&quot;
echo &quot;Test connection:&quot;
echo &quot;  psql &#x27;host=postgres.arpansahu.space port=9552 user=postgres dbname=postgres sslmode=require&#x27;&quot;
</code></pre>
<p>
 <strong>
  Run the setup:
 </strong>
</p>
<pre><code class="language-bash">chmod +x add-nginx-stream.sh
sudo ./add-nginx-stream.sh
</code></pre>
<hr/>
<h3>
 Step 4: Test TLS Connection from Mac
</h3>
<p>
 <strong>
  Create
  <code>
   test_postgres_mac_tls.sh
  </code>
  file:
 </strong>
</p>
<pre><code class="language-bash">#!/bin/bash

# PostgreSQL Mac TLS Connection Test (via Nginx)
# Tests PostgreSQL connectivity from your Mac through nginx TLS proxy

set -e

echo &quot;=== Testing PostgreSQL TLS Connection from Mac (via Nginx) ===&quot;
echo &quot;&quot;

# Colors
GREEN=&#x27;\033[0;32m&#x27;
RED=&#x27;\033[0;31m&#x27;
YELLOW=&#x27;\033[1;33m&#x27;
NC=&#x27;\033[0m&#x27; # No Color

# Configuration
PG_HOST=&quot;${PG_HOST:-postgres.arpansahu.space}&quot;
PG_PORT=&quot;${PG_PORT:-9552}&quot;
PG_USER=&quot;${PG_USER:-postgres}&quot;
PG_PASSWORD=&quot;${PG_PASSWORD:-changeme}&quot;
PG_DATABASE=&quot;${PG_DATABASE:-postgres}&quot;

# Test 1: Check if PostgreSQL is accessible via TLS
echo -e &quot;${YELLOW}Test 1: Checking PostgreSQL TLS accessibility...${NC}&quot;
if command -v psql &amp;&gt; /dev/null; then
    export PGPASSWORD=&quot;$PG_PASSWORD&quot;
    if psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -c &quot;SELECT 1;&quot; &gt; /dev/null 2&gt;&amp;1; then
        echo -e &quot;${GREEN}‚úì PostgreSQL is accessible via TLS (nginx proxy)${NC}&quot;
    else
        echo -e &quot;${RED}‚úó Failed to connect to PostgreSQL via TLS${NC}&quot;
        echo &quot;  Make sure nginx stream is configured and port 9552 is open&quot;
        exit 1
    fi
else
    echo -e &quot;${RED}‚úó psql command not found${NC}&quot;
    echo &quot;  Install with: brew install postgresql&quot;
    exit 1
fi
echo &quot;&quot;

# Test 2: Verify TLS connection is being used
echo -e &quot;${YELLOW}Test 2: Verifying TLS connection...${NC}&quot;
CONNECTION_INFO=$(psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -t -c &quot;SELECT &#x27;Connected via TLS on port $PG_PORT&#x27;;&quot; 2&gt;/dev/null | xargs)
echo -e &quot;${GREEN}‚úì $CONNECTION_INFO${NC}&quot;
echo &quot;&quot;

# Test 3: Get PostgreSQL version via TLS
echo -e &quot;${YELLOW}Test 3: Getting PostgreSQL version via TLS...${NC}&quot;
VERSION=$(psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -t -c &quot;SELECT version();&quot; 2&gt;/dev/null | xargs)
echo -e &quot;${GREEN}‚úì PostgreSQL version: ${VERSION:0:50}...${NC}&quot;
echo &quot;&quot;

# Test 4: List databases via TLS
echo -e &quot;${YELLOW}Test 4: Listing databases via TLS...${NC}&quot;
DATABASES=$(psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -t -c &quot;\l&quot; 2&gt;/dev/null | grep -c &quot;|&quot;)
echo -e &quot;${GREEN}‚úì Found $DATABASES databases${NC}&quot;
echo &quot;&quot;

# Test 5: Create test table via TLS
echo -e &quot;${YELLOW}Test 5: Creating test table via TLS...${NC}&quot;
psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -c &quot;CREATE TABLE IF NOT EXISTS mac_tls_test_table (id SERIAL PRIMARY KEY, data TEXT, created_at TIMESTAMP DEFAULT NOW());&quot; &gt; /dev/null 2&gt;&amp;1
echo -e &quot;${GREEN}‚úì Test table created via TLS${NC}&quot;
echo &quot;&quot;

# Test 6: Insert and retrieve data via TLS
echo -e &quot;${YELLOW}Test 6: Testing data operations via TLS...${NC}&quot;
psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -c &quot;INSERT INTO mac_tls_test_table (data) VALUES (&#x27;Hello from Mac via TLS!&#x27;);&quot; &gt; /dev/null 2&gt;&amp;1
RECORD=$(psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -t -c &quot;SELECT data FROM mac_tls_test_table ORDER BY id DESC LIMIT 1;&quot; 2&gt;/dev/null | xargs)
echo -e &quot;${GREEN}‚úì Record inserted and retrieved via TLS: &#x27;$RECORD&#x27;${NC}&quot;
echo &quot;&quot;

# Test 7: Clean up
echo -e &quot;${YELLOW}Test 7: Cleaning up test table...${NC}&quot;
psql &quot;host=$PG_HOST port=$PG_PORT user=$PG_USER dbname=$PG_DATABASE sslmode=require&quot; -c &quot;DROP TABLE IF EXISTS mac_tls_test_table;&quot; &gt; /dev/null 2&gt;&amp;1
echo -e &quot;${GREEN}‚úì Test table dropped${NC}&quot;
echo &quot;&quot;

# Unset password
unset PGPASSWORD

echo -e &quot;${GREEN}========================================${NC}&quot;
echo -e &quot;${GREEN}‚úì All TLS tests passed!${NC}&quot;
echo -e &quot;${GREEN}‚úì PostgreSQL is working correctly via Nginx TLS proxy${NC}&quot;
echo -e &quot;${GREEN}========================================${NC}&quot;
echo &quot;&quot;
echo &quot;Connection used:&quot;
echo &quot;  Host: $PG_HOST&quot;
echo &quot;  Port: $PG_PORT (TLS via nginx)&quot;
echo &quot;  SSL Mode: require&quot;
</code></pre>
<p>
 <strong>
  Run from your Mac:
 </strong>
</p>
<pre><code class="language-bash"># Make script executable
chmod +x test_postgres_mac_tls.sh

# Set password and run
PG_PASSWORD=your_password ./test_postgres_mac_tls.sh
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>=== Testing PostgreSQL TLS Connection from Mac (via Nginx) ===

Test 1: Checking PostgreSQL TLS accessibility...
‚úì PostgreSQL is accessible via TLS (nginx proxy)

Test 2: Verifying TLS connection...
‚úì Connected via TLS on port 9552

Test 3: Getting PostgreSQL version via TLS...
‚úì PostgreSQL version: PostgreSQL 14.x (Ubuntu 14.x-1.pgdg22.04+1) on x86...

Test 4: Listing databases via TLS...
‚úì Found 3 databases

Test 5: Creating test table via TLS...
‚úì Test table created via TLS

Test 6: Testing data operations via TLS...
‚úì Record inserted and retrieved via TLS: &#x27;Hello from Mac via TLS!&#x27;

Test 7: Cleaning up test table...
‚úì Test table dropped

========================================
‚úì All TLS tests passed!
‚úì PostgreSQL is working correctly via Nginx TLS proxy
========================================

Connection used:
  Host: postgres.arpansahu.space
  Port: 9552 (TLS via nginx)
  SSL Mode: require
</code></pre>
<hr/>
<h2>
 Connection Details Summary
</h2>
<p>
 After successful installation, your PostgreSQL setup will have:
</p>
<ul>
 <li>
  <strong>
   Service Type:
  </strong>
  Native system service (not Docker)
 </li>
 <li>
  <strong>
   Host (Local):
  </strong>
  <code>
   192.168.1.200
  </code>
  or
  <code>
   localhost
  </code>
 </li>
 <li>
  <strong>
   Port (Local):
  </strong>
  <code>
   5432
  </code>
 </li>
 <li>
  <strong>
   Host (TLS/Remote):
  </strong>
  <code>
   postgres.arpansahu.space
  </code>
 </li>
 <li>
  <strong>
   Port (TLS/Remote):
  </strong>
  <code>
   9552
  </code>
  (via nginx)
 </li>
 <li>
  <strong>
   Superuser:
  </strong>
  <code>
   postgres
  </code>
 </li>
 <li>
  <strong>
   Password:
  </strong>
  <code>
   ${POSTGRES_PASSWORD}
  </code>
  (from your .env file)
 </li>
 <li>
  <strong>
   Remote Access:
  </strong>
  Enabled (direct and via TLS proxy)
 </li>
 <li>
  <strong>
   Authentication:
  </strong>
  MD5 password authentication
 </li>
 <li>
  <strong>
   TLS Encryption:
  </strong>
  Available via nginx stream on port 9552
 </li>
</ul>
<hr/>
<h2>
 Database Management
</h2>
<h3>
 Create Database
</h3>
<pre><code class="language-bash"># Method 1: Using createdb command
sudo -u postgres createdb myapp_db

# Method 2: Using SQL
sudo -u postgres psql -c &quot;CREATE DATABASE myapp_db;&quot;
</code></pre>
<hr/>
<h3>
 Create User and Grant Permissions
</h3>
<pre><code class="language-bash">sudo -u postgres psql &lt;&lt; EOF
CREATE USER myapp_user WITH PASSWORD &#x27;myapp_password&#x27;;
GRANT ALL PRIVILEGES ON DATABASE myapp_db TO myapp_user;
ALTER DATABASE myapp_db OWNER TO myapp_user;
EOF
</code></pre>
<hr/>
<h3>
 Connect to Database
</h3>
<pre><code class="language-bash"># As postgres superuser
sudo -u postgres psql -d myapp_db

# As custom user
psql -h localhost -U myapp_user -d myapp_db

# From remote machine
psql -h 192.168.1.200 -U myapp_user -d myapp_db
</code></pre>
<hr/>
<h3>
 Backup Database
</h3>
<pre><code class="language-bash"># Backup single database
sudo -u postgres pg_dump myapp_db &gt; myapp_db_backup_$(date +%Y%m%d).sql

# Backup all databases
sudo -u postgres pg_dumpall &gt; all_databases_backup_$(date +%Y%m%d).sql

# Compressed backup
sudo -u postgres pg_dump myapp_db | gzip &gt; myapp_db_backup_$(date +%Y%m%d).sql.gz
</code></pre>
<hr/>
<h3>
 Restore Database
</h3>
<pre><code class="language-bash"># Restore from backup
sudo -u postgres psql myapp_db &lt; myapp_db_backup_20240101.sql

# Restore compressed backup
gunzip &lt; myapp_db_backup_20240101.sql.gz | sudo -u postgres psql myapp_db

# Restore all databases
sudo -u postgres psql &lt; all_databases_backup_20240101.sql
</code></pre>
<hr/>
<h2>
 Using PostgreSQL in Your Applications
</h2>
<h3>
 Python Connection Example
</h3>
<p>
 Install the psycopg2 library:
</p>
<pre><code class="language-bash">pip install psycopg2-binary
</code></pre>
<p>
 <strong>
  Basic connection:
 </strong>
</p>
<pre><code class="language-python">import psycopg2

# Connection parameters
conn = psycopg2.connect(
    host=&#x27;192.168.1.200&#x27;,
    port=5432,
    database=&#x27;myapp_db&#x27;,
    user=&#x27;myapp_user&#x27;,
    password=&#x27;myapp_password&#x27;
)

# Create cursor
cursor = conn.cursor()

# Execute query
cursor.execute(&quot;SELECT * FROM users;&quot;)
rows = cursor.fetchall()

for row in rows:
    print(row)

# Close connection
cursor.close()
conn.close()
</code></pre>
<hr/>
<h3>
 Django Configuration
</h3>
<p>
 Add PostgreSQL configuration in
 <code>
  settings.py
 </code>
 :
</p>
<pre><code class="language-python">DATABASES = {
    &#x27;default&#x27;: {
        &#x27;ENGINE&#x27;: &#x27;django.db.backends.postgresql&#x27;,
        &#x27;NAME&#x27;: &#x27;myapp_db&#x27;,
        &#x27;USER&#x27;: &#x27;myapp_user&#x27;,
        &#x27;PASSWORD&#x27;: &#x27;myapp_password&#x27;,
        &#x27;HOST&#x27;: &#x27;192.168.1.200&#x27;,
        &#x27;PORT&#x27;: &#x27;5432&#x27;,
    }
}
</code></pre>
<p>
 <strong>
  Install psycopg2:
 </strong>
</p>
<pre><code class="language-bash">pip install psycopg2-binary
</code></pre>
<p>
 <strong>
  Run migrations:
 </strong>
</p>
<pre><code class="language-bash">python manage.py migrate
</code></pre>
<hr/>
<h2>
 Troubleshooting
</h2>
<h3>
 Service Issues
</h3>
<p>
 If PostgreSQL service is not running:
</p>
<pre><code class="language-bash"># Check service status
sudo systemctl status postgresql

# Start service
sudo systemctl start postgresql

# Restart service
sudo systemctl restart postgresql

# View logs
sudo journalctl -u postgresql -n 50
</code></pre>
<hr/>
<h3>
 Connection Refused
</h3>
<p>
 If you cannot connect remotely:
</p>
<pre><code class="language-bash"># Check if PostgreSQL is listening on all interfaces
sudo ss -lntp | grep 5432
# Should show: 0.0.0.0:5432

# Check postgresql.conf
PG_VERSION=$(ls /etc/postgresql/)
sudo grep listen_addresses /etc/postgresql/$PG_VERSION/main/postgresql.conf
# Should show: listen_addresses = &#x27;*&#x27;

# Check pg_hba.conf for remote access rules
sudo cat /etc/postgresql/$PG_VERSION/main/pg_hba.conf | grep &quot;0.0.0.0/0&quot;
# Should show: host    all             all             0.0.0.0/0               md5

# Restart after changes
sudo systemctl restart postgresql
</code></pre>
<hr/>
<h3>
 Authentication Failed
</h3>
<p>
 If you get "authentication failed" errors:
</p>
<pre><code class="language-bash"># Reset postgres password
sudo -u postgres psql -c &quot;ALTER USER postgres WITH PASSWORD &#x27;new_password&#x27;;&quot;

# Check pg_hba.conf authentication method
PG_VERSION=$(ls /etc/postgresql/)
sudo cat /etc/postgresql/$PG_VERSION/main/pg_hba.conf

# Ensure md5 authentication is enabled (not peer or ident)
</code></pre>
<hr/>
<h3>
 Nginx Connection Issues (Port 9552)
</h3>
<p>
 <strong>
  "Server closed connection unexpectedly" error:
 </strong>
</p>
<p>
 This occurs when trying to use nginx SSL termination with PostgreSQL. Unlike Redis (text protocol), PostgreSQL uses a binary protocol that cannot work through nginx SSL termination.
</p>
<p>
 <strong>
  Solution:
 </strong>
 Use TCP passthrough configuration (already configured in our setup):
 <br/>
 - Nginx configuration should NOT have SSL directives (
 <code>
  listen 9552;
 </code>
 instead of
 <code>
  listen 9552 ssl;
 </code>
 )
 <br/>
 - PostgreSQL handles SSL encryption itself (configured with
 <code>
  ssl=on
 </code>
 in postgresql.conf)
 <br/>
 - Connection is still encrypted end-to-end, just by PostgreSQL instead of nginx
</p>
<p>
 <strong>
  Verify configuration:
 </strong>
</p>
<pre><code class="language-bash"># Check nginx stream configuration
sudo grep -A 10 &quot;postgres_backend&quot; /etc/nginx/nginx.conf
# Should NOT show ssl_certificate or ssl_certificate_key

# Check if port 9552 is listening
sudo ss -lntp | grep 9552
# Should show nginx listening on port 9552

# Test connection from Mac
psql &quot;host=postgres.arpansahu.space port=9552 user=postgres dbname=postgres sslmode=prefer&quot;
</code></pre>
<p>
 <strong>
  Why TCP passthrough instead of SSL termination?
 </strong>
 <br/>
 -
 <strong>
  Redis:
 </strong>
 Simple text-based protocol ‚Üí Works with nginx SSL termination
 <br/>
 -
 <strong>
  PostgreSQL:
 </strong>
 Complex binary protocol with handshake ‚Üí Requires TCP passthrough
 <br/>
 - Both methods provide end-to-end encryption, just handled at different layers
</p>
<hr/>
<h3>
 Port Already in Use
</h3>
<p>
 If port 5432 is already in use:
</p>
<pre><code class="language-bash"># Check what&#x27;s using the port
sudo ss -lntp | grep 5432

# Kill the process if needed
sudo kill -9 &lt;PID&gt;

# Or change PostgreSQL port in postgresql.conf
</code></pre>
<hr/>
<h2>
 Security Best Practices
</h2>
<ol>
 <li>
  <strong>
   Strong Passwords:
  </strong>
  Always use strong passwords for database users
 </li>
 <li>
  <strong>
   Limited Access:
  </strong>
  Only allow remote access from trusted IPs
 </li>
 <li>
  <strong>
   Regular Backups:
  </strong>
  Schedule automated backups
 </li>
 <li>
  <strong>
   Update Regularly:
  </strong>
  Keep PostgreSQL updated
 </li>
 <li>
  <strong>
   User Permissions:
  </strong>
  Follow principle of least privilege
 </li>
 <li>
  <strong>
   TLS Encryption:
  </strong>
  PostgreSQL handles its own SSL/TLS (configured with
  <code>
   ssl=on
  </code>
  )
 </li>
 <li>
  <strong>
   Non-Standard Ports:
  </strong>
  Use port 9552 via nginx to avoid bot scanning of default port 5432
 </li>
 <li>
  <strong>
   Firewall Rules:
  </strong>
  Close external access to port 5432, only expose port 9552
 </li>
 <li>
  <strong>
   Monitor Logs:
  </strong>
  Regularly check PostgreSQL logs for suspicious activity
 </li>
</ol>
<hr/>
<h2>
 Quick Reference
</h2>
<h3>
 Important Files
</h3>
<ul>
 <li>
  <strong>
   Environment template:
  </strong>
  <a href="./.env.example">
   <code>
    .env.example
   </code>
  </a>
 </li>
 <li>
  <strong>
   Environment config:
  </strong>
  <code>
   .env
  </code>
  (create from .env.example)
 </li>
 <li>
  <strong>
   Installation script:
  </strong>
  <a href="./install.sh">
   <code>
    install.sh
   </code>
  </a>
 </li>
 <li>
  <strong>
   Nginx stream config:
  </strong>
  <a href="./nginx-stream.conf">
   <code>
    nginx-stream.conf
   </code>
  </a>
 </li>
 <li>
  <strong>
   Nginx setup script:
  </strong>
  <a href="./add-nginx-stream.sh">
   <code>
    add-nginx-stream.sh
   </code>
  </a>
 </li>
 <li>
  <strong>
   Test script (localhost):
  </strong>
  <a href="./test_postgres_localhost.py">
   <code>
    test_postgres_localhost.py
   </code>
  </a>
  - Run on server
 </li>
 <li>
  <strong>
   Test script (direct IP):
  </strong>
  <a href="./test_postgres_mac.sh">
   <code>
    test_postgres_mac.sh
   </code>
  </a>
  - Run from Mac
 </li>
 <li>
  <strong>
   Test script (domain TLS):
  </strong>
  <a href="./test_postgres_domain_tls.sh">
   <code>
    test_postgres_domain_tls.sh
   </code>
  </a>
  - Run from Mac
 </li>
</ul>
<h3>
 Important Commands
</h3>
<pre><code class="language-bash"># Install PostgreSQL
./install.sh

# Set up nginx TLS proxy (optional)
sudo ./add-nginx-stream.sh

# Service management
sudo systemctl start postgresql
sudo systemctl stop postgresql
sudo systemctl restart postgresql
sudo systemctl status postgresql

# Connect to database
sudo -u postgres psql
psql -h localhost -U postgres -d postgres

# Connect via TLS (from remote)
psql &#x27;host=postgres.arpansahu.space port=9552 user=postgres dbname=postgres sslmode=require&#x27;

# Create database
sudo -u postgres createdb myapp_db

# Backup database
sudo -u postgres pg_dump myapp_db &gt; backup.sql

# Test connections
python3 test_postgres_localhost.py       # On server
PG_PASSWORD=password ./test_postgres_mac.sh           # From Mac (direct)
PG_PASSWORD=password ./test_postgres_domain_tls.sh    # From Mac (TLS)

# View logs
sudo journalctl -u postgresql -f
</code></pre>
<h3>
 Configuration Files
</h3>
<ul>
 <li>
  <strong>
   Main config:
  </strong>
  <code>
   /etc/postgresql/*/main/postgresql.conf
  </code>
 </li>
 <li>
  <strong>
   Auth config:
  </strong>
  <code>
   /etc/postgresql/*/main/pg_hba.conf
  </code>
 </li>
 <li>
  <strong>
   Data directory:
  </strong>
  <code>
   /var/lib/postgresql/*/main/
  </code>
 </li>
 <li>
  <strong>
   Log files:
  </strong>
  <code>
   /var/log/postgresql/
  </code>
 </li>
</ul>
<hr/>
<h2>
 PgAdmin Integration
</h2>
<p>
 Use PgAdmin for GUI management:
 <br/>
 - URL: https://pgadmin.arpansahu.space
 <br/>
 - Add server with: Host=192.168.1.200, Port=5432, User=postgres
 <br/>
 - See
 <a href="../Pgadmin/README.md">
  PgAdmin README
 </a>
 for details
</p>
<hr/>
<h2>
 Architecture Diagram
</h2>
<pre><code>[Your Application] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                                 ‚îÇ
       ‚îÇ Direct: Port 5432 (TCP)         ‚îÇ TLS: Port 9552 (TCP)
       ‚Üì                                 ‚Üì
[PostgreSQL Server]            [Nginx Stream Proxy]
(Native system service)         (TLS Termination)
       ‚Üì                                 ‚îÇ
[/var/lib/postgresql/data]               ‚îÇ
       ‚Üë                                 ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                localhost:5432
</code></pre>
<p>
 <strong>
  Access Methods:
 </strong>
 <br/>
 -
 <strong>
  Local/Direct:
 </strong>
 Connect directly to 192.168.1.200:5432 (no encryption)
 <br/>
 -
 <strong>
  Remote/TLS:
 </strong>
 Connect via postgres.arpansahu.space:9552 (TLS encrypted via nginx)
 <br/>
 -
 <strong>
  No Proxy Layer:
 </strong>
 Direct database access on port 5432
 <br/>
 -
 <strong>
  TLS Proxy:
 </strong>
 Nginx stream proxies TLS connections to PostgreSQL
</p>
<h2>
 Redis Server (Docker + Nginx STREAM + TLS)
</h2>
<p>
 Redis is a high-performance in-memory data store. This setup provides secure Redis with TLS encryption via Nginx.
</p>
<hr/>
<h2>
 Test Files Overview
</h2>
<table>
 <thead>
  <tr>
   <th>
    Test File
   </th>
   <th>
    Where to Run
   </th>
   <th>
    Connection Type
   </th>
   <th>
    Purpose
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <code>
     test_redis_localhost.py
    </code>
   </td>
   <td>
    <strong>
     On Server
    </strong>
   </td>
   <td>
    localhost:6380
   </td>
   <td>
    Test Redis on server without TLS
   </td>
  </tr>
  <tr>
   <td>
    <code>
     test_redis_domain_tls.py
    </code>
   </td>
   <td>
    <strong>
     From Mac
    </strong>
   </td>
   <td>
    redis.arpansahu.space:9551
   </td>
   <td>
    Test Redis from Mac with TLS via domain
   </td>
  </tr>
 </tbody>
</table>
<p>
 <strong>
  Quick Test Commands:
 </strong>
</p>
<pre><code class="language-bash"># On Server (localhost)
python3 test_redis_localhost.py

# From Mac (domain with TLS)
python3 test_redis_domain_tls.py
</code></pre>
<p>
 <strong>
  CLI Testing (redis-cli):
 </strong>
</p>
<pre><code class="language-bash"># On Server (localhost) - Basic commands
redis-cli -h 127.0.0.1 -p 6380 -a ${REDIS_PASSWORD} ping
redis-cli -h 127.0.0.1 -p 6380 -a ${REDIS_PASSWORD} SET test &quot;hello&quot;
redis-cli -h 127.0.0.1 -p 6380 -a ${REDIS_PASSWORD} GET test

# From Mac (domain with TLS) - Requires redis-cli with TLS support
redis-cli -h redis.arpansahu.space -p 9551 --tls --insecure -a ${REDIS_PASSWORD} ping
redis-cli -h redis.arpansahu.space -p 9551 --tls --insecure -a ${REDIS_PASSWORD} INFO server
</code></pre>
<hr/>
<h2>
 Step-by-Step Installation Guide
</h2>
<h3>
 Step 1: Create Environment Configuration
</h3>
<p>
 First, create the environment configuration file that will store your Redis password and port.
</p>
<p>
 <strong>
  Create
  <code>
   .env.example
  </code>
  (Template file):
 </strong>
</p>
<pre><code class="language-bash"># Redis Configuration
REDIS_PASSWORD=your_secure_password_here
REDIS_PORT=6380
</code></pre>
<p>
 <strong>
  Create your actual
  <code>
   .env
  </code>
  file:
 </strong>
</p>
<pre><code class="language-bash">cd &quot;AWS Deployment/redis&quot;
cp .env.example .env
nano .env
</code></pre>
<p>
 <strong>
  Your
  <code>
   .env
  </code>
  file should look like this (with your actual password):
 </strong>
</p>
<pre><code class="language-bash"># Redis Configuration
REDIS_PASSWORD=Kesar302redis
REDIS_PORT=6380
</code></pre>
<p>
 <strong>
  ‚ö†Ô∏è Important:
 </strong>
 <br/>
 - Always change the default password in production!
 <br/>
 - Never commit your
 <code>
  .env
 </code>
 file to version control
 <br/>
 - Keep the
 <code>
  .env.example
 </code>
 file as a template
</p>
<hr/>
<h3>
 Step 2: Create Installation Script
</h3>
<p>
 Create the
 <code>
  install.sh
 </code>
 script that will automatically install Redis using the environment variables.
</p>
<p>
 <strong>
  Create
  <code>
   install.sh
  </code>
  file:
 </strong>
</p>
<pre><code class="language-bash">#!/bin/bash
set -e

echo &quot;=== Redis Installation Script ===&quot;

# Colors
GREEN=&#x27;\033[0;32m&#x27;
YELLOW=&#x27;\033[1;33m&#x27;
NC=&#x27;\033[0m&#x27;

# Load environment variables
SCRIPT_DIR=&quot;$(cd &quot;$(dirname &quot;${BASH_SOURCE[0]}&quot;)&quot; &amp;&amp; pwd)&quot;
if [ -f &quot;$SCRIPT_DIR/.env&quot; ]; then
    export $(grep -v &#x27;^#&#x27; &quot;$SCRIPT_DIR/.env&quot; | xargs)
    echo -e &quot;${GREEN}Loaded configuration from .env file${NC}&quot;
else
    echo -e &quot;${YELLOW}Warning: .env file not found. Using defaults.${NC}&quot;
    echo -e &quot;${YELLOW}Please copy .env.example to .env and configure it.${NC}&quot;
fi

# Configuration with defaults
REDIS_PASSWORD=&quot;${REDIS_PASSWORD:-Kesar302redis}&quot;
REDIS_PORT=&quot;${REDIS_PORT:-6380}&quot;

echo -e &quot;${YELLOW}Step 1: Running Redis Container${NC}&quot;
docker run -d \
  --name redis-external \
  --restart unless-stopped \
  -p 127.0.0.1:${REDIS_PORT}:6379 \
  redis:7 \
  redis-server --requirepass &quot;$REDIS_PASSWORD&quot;

echo -e &quot;${YELLOW}Step 2: Waiting for Redis to start...${NC}&quot;
sleep 3

echo -e &quot;${YELLOW}Step 3: Verifying Installation${NC}&quot;
docker ps | grep redis-external

echo -e &quot;${GREEN}Redis installed successfully!${NC}&quot;
echo -e &quot;Container: redis-external&quot;
echo -e &quot;Port: 127.0.0.1:${REDIS_PORT}&quot;
echo -e &quot;Password: $REDIS_PASSWORD&quot;
echo &quot;&quot;
echo -e &quot;${YELLOW}Test connection:${NC}&quot;
echo &quot;redis-cli -h 127.0.0.1 -p ${REDIS_PORT} -a $REDIS_PASSWORD ping&quot;
echo &quot;&quot;
echo -e &quot;${YELLOW}Next steps for HTTPS access:${NC}&quot;
echo &quot;1. Configure Nginx stream block in /etc/nginx/nginx.conf&quot;
echo &quot;2. See nginx-stream.conf for configuration&quot;
echo &quot;3. Test and reload: sudo nginx -t &amp;&amp; sudo systemctl reload nginx&quot;
</code></pre>
<p>
 <strong>
  Make it executable and run:
 </strong>
</p>
<pre><code class="language-bash">chmod +x install.sh
./install.sh
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>=== Redis Installation Script ===
Loaded configuration from .env file
Step 1: Running Redis Container
Step 2: Waiting for Redis to start...
Step 3: Verifying Installation
redis-external
Redis installed successfully!
Container: redis-external
Port: 127.0.0.1:6380
Password: Kesar302redis
</code></pre>
<hr/>
<h3>
 Step 3: Configure Nginx Stream for TLS Access
</h3>
<p>
 Redis uses TCP protocol, not HTTP, so we need to configure Nginx's stream module (Layer 4 proxy).
</p>
<p>
 <strong>
  Create
  <code>
   nginx-stream.conf
  </code>
  file:
 </strong>
</p>
<pre><code class="language-nginx"># Add this to the stream {} block in /etc/nginx/nginx.conf

stream {
    # Redis upstream
    upstream redis_upstream {
        server 127.0.0.1:6380;
    }

    # Redis with TLS
    server {
        listen 9551 ssl;
        proxy_pass redis_upstream;

        # SSL Configuration
        ssl_certificate /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;

        # Connection settings
        proxy_connect_timeout 5s;
        proxy_timeout 300s;
        proxy_buffer_size 16k;
    }
}
</code></pre>
<p>
 <strong>
  What this configuration does:
 </strong>
 <br/>
 - Listens on port 9551 with SSL/TLS encryption
 <br/>
 - Proxies TCP connections to Redis on localhost:6380
 <br/>
 - Uses your wildcard SSL certificate for *.arpansahu.space
 <br/>
 - Allows external TLS connections to redis.arpansahu.space:9551
</p>
<hr/>
<h3>
 Step 4: Apply Nginx Stream Configuration
</h3>
<p>
 You have two options to apply the stream configuration:
</p>
<h4>
 Option 1: Automated (Recommended)
</h4>
<p>
 Create
 <code>
  add-nginx-stream.sh
 </code>
 script:
</p>
<pre><code class="language-bash">#!/bin/bash
set -e

echo &quot;=== Adding Redis Stream Block to Nginx ===&quot;

# Colors
GREEN=&#x27;\033[0;32m&#x27;
YELLOW=&#x27;\033[1;33m&#x27;
NC=&#x27;\033[0m&#x27;

# Get script directory
SCRIPT_DIR=&quot;$(cd &quot;$(dirname &quot;${BASH_SOURCE[0]}&quot;)&quot; &amp;&amp; pwd)&quot;

echo -e &quot;${YELLOW}Step 1: Backing up nginx.conf${NC}&quot;
sudo cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.backup-$(date +%Y%m%d-%H%M%S)

echo -e &quot;${YELLOW}Step 2: Adding stream block from nginx-stream.conf${NC}&quot;
# Remove the comment line and add to nginx.conf
grep -v &quot;^# Add this to&quot; &quot;$SCRIPT_DIR/nginx-stream.conf&quot; | sudo tee -a /etc/nginx/nginx.conf &gt; /dev/null

echo -e &quot;${YELLOW}Step 3: Testing nginx configuration${NC}&quot;
sudo nginx -t

echo -e &quot;${YELLOW}Step 4: Reloading nginx${NC}&quot;
sudo systemctl reload nginx

echo -e &quot;${YELLOW}Step 5: Verifying port 9551${NC}&quot;
ss -lntp | grep 9551 || echo &quot;Port not yet visible (may need a moment)&quot;

echo -e &quot;${GREEN}Redis TLS stream configured successfully!${NC}&quot;
echo -e &quot;Test with: redis-cli -h redis.arpansahu.space -p 9551 --tls --insecure -a PASSWORD ping&quot;
</code></pre>
<p>
 <strong>
  Run the script:
 </strong>
</p>
<pre><code class="language-bash">chmod +x add-nginx-stream.sh
sudo bash add-nginx-stream.sh
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>=== Adding Redis Stream Block to Nginx ===
Step 1: Backing up nginx.conf
Step 2: Adding stream block from nginx-stream.conf
Step 3: Testing nginx configuration
nginx: configuration file /etc/nginx/nginx.conf test is successful
Step 4: Reloading nginx
Step 5: Verifying port 9551
LISTEN 0 511 0.0.0.0:9551 0.0.0.0:*
Redis TLS stream configured successfully!
</code></pre>
<h4>
 Option 2: Manual Configuration
</h4>
<pre><code class="language-bash"># 1. Backup nginx.conf
sudo cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.backup

# 2. Edit nginx.conf
sudo nano /etc/nginx/nginx.conf

# 3. Add the stream block from nginx-stream.conf at the END of the file
# (outside the http block, at the same level)

# 4. Test configuration
sudo nginx -t

# 5. Reload nginx
sudo systemctl reload nginx

# 6. Verify port is listening
sudo ss -lntp | grep 9551
</code></pre>
<hr/>
<hr/>
<h2>
 Testing Your Redis Installation
</h2>
<p>
 After installation and Nginx configuration, test Redis connectivity using multiple methods:
</p>
<h3>
 Test 1: From Docker Container
</h3>
<p>
 Test Redis directly inside the container:
</p>
<pre><code class="language-bash"># Simple ping test
docker exec redis-external redis-cli -a ${REDIS_PASSWORD} ping

# Set and get a value
docker exec redis-external redis-cli -a ${REDIS_PASSWORD} SET mykey &quot;Hello Redis&quot;
docker exec redis-external redis-cli -a ${REDIS_PASSWORD} GET mykey
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>PONG
OK
&quot;Hello Redis&quot;
</code></pre>
<hr/>
<h3>
 Test 2: From Server (Local)
</h3>
<p>
 Test Redis from the server itself using redis-cli:
</p>
<pre><code class="language-bash"># Install redis-tools if not already installed
sudo apt install -y redis-tools

# Test connection
redis-cli -h 127.0.0.1 -p ${REDIS_PORT} -a ${REDIS_PASSWORD} ping

# Set and get a value
redis-cli -h 127.0.0.1 -p ${REDIS_PORT} -a ${REDIS_PASSWORD} SET testkey &quot;Hello from Server&quot;
redis-cli -h 127.0.0.1 -p ${REDIS_PORT} -a ${REDIS_PASSWORD} GET testkey
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>PONG
OK
&quot;Hello from Server&quot;
</code></pre>
<hr/>
<h3>
 Test 3: From Your Mac (TLS Connection)
</h3>
<p>
 Test Redis from your local machine using TLS through Nginx:
</p>
<pre><code class="language-bash"># Install redis if not already installed
brew install redis

# Test connection via TLS (through nginx stream on port 9551)
redis-cli -h redis.arpansahu.space -p 9551 --tls --insecure -a ${REDIS_PASSWORD} ping

# Set and get a value
redis-cli -h redis.arpansahu.space -p 9551 --tls --insecure -a ${REDIS_PASSWORD} SET mackey &quot;Hello from Mac&quot;
redis-cli -h redis.arpansahu.space -p 9551 --tls --insecure -a ${REDIS_PASSWORD} GET mackey
</code></pre>
<p>
 <strong>
  Expected output:
 </strong>
</p>
<pre><code>PONG
OK
&quot;Hello from Mac&quot;
</code></pre>
<p>
 <strong>
  Note:
 </strong>
 The
 <code>
  --insecure
 </code>
 flag skips certificate verification. For production, you should verify certificates properly.
</p>
<hr/>
<h2>
 Connection Details Summary
</h2>
<p>
 After successful installation, your Redis setup will have:
</p>
<ul>
 <li>
  <strong>
   Container Name:
  </strong>
  <code>
   redis-external
  </code>
 </li>
 <li>
  <strong>
   Local Connection:
  </strong>
  <code>
   127.0.0.1:${REDIS_PORT}
  </code>
  (localhost only)
 </li>
 <li>
  <strong>
   TLS Connection:
  </strong>
  <code>
   redis.arpansahu.space:9551
  </code>
  (accessible externally)
 </li>
 <li>
  <strong>
   Password:
  </strong>
  <code>
   ${REDIS_PASSWORD}
  </code>
  (from your .env file)
 </li>
 <li>
  <strong>
   Data Directory:
  </strong>
  <code>
   ~/redis/data
  </code>
  (if you add volumes)
 </li>
</ul>
<hr/>
<h2>
 Using Redis in Your Applications
</h2>
<h3>
 Python Connection Example
</h3>
<p>
 Install the Redis Python client:
</p>
<pre><code class="language-bash">pip install redis
</code></pre>
<p>
 <strong>
  Local connection (from server):
 </strong>
</p>
<pre><code class="language-python">import redis

# Local connection
r = redis.Redis(
    host=&#x27;127.0.0.1&#x27;,
    port=${REDIS_PORT},
    password=&#x27;${REDIS_PASSWORD}&#x27;,
    decode_responses=True
)

# Test connection
r.set(&#x27;test&#x27;, &#x27;hello&#x27;)
print(r.get(&#x27;test&#x27;))  # Output: hello
</code></pre>
<p>
 <strong>
  TLS connection (from anywhere):
 </strong>
</p>
<pre><code class="language-python">import redis

# TLS connection
r = redis.Redis(
    host=&#x27;redis.arpansahu.space&#x27;,
    port=9551,
    password=&#x27;${REDIS_PASSWORD}&#x27;,
    ssl=True,
    ssl_cert_reqs=&#x27;required&#x27;,
    decode_responses=True
)

# Test connection
r.set(&#x27;test&#x27;, &#x27;hello&#x27;)
print(r.get(&#x27;test&#x27;))  # Output: hello
</code></pre>
<hr/>
<h3>
 Router Port Forwarding Configuration
</h3>
<p>
 <strong>
  ‚ö†Ô∏è Required for external access (from outside your home network)
 </strong>
</p>
<p>
 If you want to access Redis from outside your local network (e.g., from mobile data, other locations), you need to configure port forwarding on your router.
</p>
<p>
 <strong>
  Steps for Airtel Router:
 </strong>
</p>
<ol>
 <li>
  <strong>
   Login to router admin panel:
  </strong>
 </li>
 <li>
  Open browser and go to:
  <code>
   http://192.168.1.1
  </code>
 </li>
 <li>
  <p>
   Enter admin credentials
  </p>
 </li>
 <li>
  <p>
   <strong>
    Navigate to Port Forwarding:
   </strong>
  </p>
 </li>
 <li>
  Go to
  <code>
   NAT
  </code>
  ‚Üí
  <code>
   Port Forwarding
  </code>
  tab
 </li>
 <li>
  <p>
   Click "Add new rule"
  </p>
 </li>
 <li>
  <p>
   <strong>
    Configure port forwarding rule:
   </strong>
  </p>
 </li>
 <li>
  <strong>
   Service Name:
  </strong>
  User Define
 </li>
 <li>
  <strong>
   External Start Port:
  </strong>
  9551
 </li>
 <li>
  <strong>
   External End Port:
  </strong>
  9551
 </li>
 <li>
  <strong>
   Internal Start Port:
  </strong>
  9551
 </li>
 <li>
  <strong>
   Internal End Port:
  </strong>
  9551
 </li>
 <li>
  <strong>
   Server IP Address:
  </strong>
  192.168.1.200 (your server's local IP)
 </li>
 <li>
  <p>
   <strong>
    Protocol:
   </strong>
   TCP (or TCP/UDP)
  </p>
 </li>
 <li>
  <p>
   <strong>
    Activate the rule:
   </strong>
  </p>
 </li>
 <li>
  Click save/apply
 </li>
 <li>
  The rule should appear in the port forwarding list with status "Active"
 </li>
</ol>
<p>
 <strong>
  Verify port forwarding:
 </strong>
</p>
<pre><code class="language-bash"># From external network (mobile data or different location)
redis-cli -h redis.arpansahu.space -p 9551 --tls -a your_password PING
</code></pre>
<p>
 <strong>
  Note:
 </strong>
 Port forwarding is NOT required if you only access Redis from devices on the same local network (192.168.1.x).
</p>
<hr/>
<h3>
 Django Configuration
</h3>
<p>
 Add Redis as Django cache backend in
 <code>
  settings.py
 </code>
 :
</p>
<pre><code class="language-python">CACHES = {
    &#x27;default&#x27;: {
        &#x27;BACKEND&#x27;: &#x27;django_redis.cache.RedisCache&#x27;,
        &#x27;LOCATION&#x27;: &#x27;rediss://redis.arpansahu.space:9551/0&#x27;,
        &#x27;OPTIONS&#x27;: {
            &#x27;CLIENT_CLASS&#x27;: &#x27;django_redis.client.DefaultClient&#x27;,
            &#x27;PASSWORD&#x27;: &#x27;${REDIS_PASSWORD}&#x27;,
        }
    }
}
</code></pre>
<p>
 <strong>
  Install django-redis:
 </strong>
</p>
<pre><code class="language-bash">pip install django-redis
</code></pre>
<p>
 <strong>
  Use in your Django views:
 </strong>
</p>
<pre><code class="language-python">from django.core.cache import cache

# Set a value
cache.set(&#x27;my_key&#x27;, &#x27;my_value&#x27;, timeout=300)

# Get a value
value = cache.get(&#x27;my_key&#x27;)
</code></pre>
<hr/>
<h2>
 Troubleshooting
</h2>
<h3>
 Container Issues
</h3>
<p>
 If Redis container is not running properly:
</p>
<pre><code class="language-bash"># Check container logs
docker logs redis-external

# Restart container
docker restart redis-external

# Remove and reinstall
docker stop redis-external
docker rm redis-external
./install.sh
</code></pre>
<hr/>
<h3>
 Connection Test Failed
</h3>
<p>
 If you cannot connect to Redis:
</p>
<p>
 <strong>
  For local connection:
 </strong>
</p>
<pre><code class="language-bash"># Check if container is running
docker ps | grep redis-external

# Check if port is listening
sudo ss -lntp | grep ${REDIS_PORT}

# Test connection
redis-cli -h 127.0.0.1 -p ${REDIS_PORT} -a ${REDIS_PASSWORD} ping
</code></pre>
<p>
 <strong>
  For TLS connection:
 </strong>
</p>
<pre><code class="language-bash"># Check if nginx is listening on port 9551
sudo ss -lntp | grep 9551

# Check nginx stream configuration
sudo nginx -T | grep -A 20 &quot;stream {&quot;

# Test with redis-cli
redis-cli -h redis.arpansahu.space -p 9551 -a ${REDIS_PASSWORD} --tls --insecure ping
</code></pre>
<hr/>
<h3>
 Nginx Configuration Issues
</h3>
<p>
 If Nginx fails to start or reload:
</p>
<pre><code class="language-bash"># Test nginx configuration
sudo nginx -t

# Check nginx error logs
sudo tail -f /var/log/nginx/error.log

# Verify stream block exists
sudo grep -A 20 &quot;stream {&quot; /etc/nginx/nginx.conf

# Restore from backup if needed
sudo cp /etc/nginx/nginx.conf.backup-YYYYMMDD-HHMMSS /etc/nginx/nginx.conf
sudo nginx -t
sudo systemctl reload nginx
</code></pre>
<hr/>
<h2>
 Maintenance Operations
</h2>
<h3>
 View Real-time Logs
</h3>
<pre><code class="language-bash">docker logs -f redis-external
</code></pre>
<hr/>
<h3>
 Backup Redis Data
</h3>
<p>
 If you have persistence enabled (with volumes):
</p>
<pre><code class="language-bash"># Create backup
tar -czf redis-backup-$(date +%Y%m%d).tar.gz ~/redis/data

# List backups
ls -lh redis-backup-*.tar.gz
</code></pre>
<hr/>
<h3>
 Update Redis
</h3>
<p>
 To update to the latest Redis version:
</p>
<pre><code class="language-bash"># Pull latest Redis image
docker pull redis:7

# Stop and remove old container
docker stop redis-external
docker rm redis-external

# Run installation again
./install.sh
</code></pre>
<hr/>
<h2>
 Security Best Practices
</h2>
<ol>
 <li>
  <strong>
   Strong Password:
  </strong>
  Always use a strong, unique password in your
  <code>
   .env
  </code>
  file
 </li>
 <li>
  <strong>
   Localhost Binding:
  </strong>
  Redis container only binds to 127.0.0.1 (not accessible directly from internet)
 </li>
 <li>
  <strong>
   TLS Encryption:
  </strong>
  External access only through Nginx with TLS encryption
 </li>
 <li>
  <strong>
   Firewall Rules:
  </strong>
  Ensure port 6380 is not exposed to the internet, only port 9551 through Nginx
 </li>
 <li>
  <strong>
   Environment Variables:
  </strong>
  Never commit
  <code>
   .env
  </code>
  file to version control
 </li>
 <li>
  <strong>
   Regular Updates:
  </strong>
  Keep Redis and Nginx updated to latest stable versions
 </li>
</ol>
<hr/>
<h2>
 Quick Reference
</h2>
<h3>
 Important Files
</h3>
<ul>
 <li>
  <strong>
   Environment template:
  </strong>
  <a href="./.env.example">
   <code>
    .env.example
   </code>
  </a>
 </li>
 <li>
  <strong>
   Environment config:
  </strong>
  <code>
   .env
  </code>
  (create from .env.example)
 </li>
 <li>
  <strong>
   Installation script:
  </strong>
  <a href="./install.sh">
   <code>
    install.sh
   </code>
  </a>
 </li>
 <li>
  <strong>
   Nginx stream config:
  </strong>
  <a href="./nginx-stream.conf">
   <code>
    nginx-stream.conf
   </code>
  </a>
 </li>
 <li>
  <strong>
   Nginx setup script:
  </strong>
  <a href="./add-nginx-stream.sh">
   <code>
    add-nginx-stream.sh
   </code>
  </a>
 </li>
 <li>
  <strong>
   Test script (localhost):
  </strong>
  <a href="./test_redis_localhost.py">
   <code>
    test_redis_localhost.py
   </code>
  </a>
  - Run on server
 </li>
 <li>
  <strong>
   Test script (domain TLS):
  </strong>
  <a href="./test_redis_domain_tls.py">
   <code>
    test_redis_domain_tls.py
   </code>
  </a>
  - Run from Mac
 </li>
</ul>
<h3>
 Important Commands
</h3>
<pre><code class="language-bash"># Install Redis
./install.sh

# Configure Nginx stream
sudo bash add-nginx-stream.sh

# Test connections
python3 test_redis_localhost.py          # On server
python3 test_redis_domain_tls.py         # From Mac

# Test with redis-cli (manual)
redis-cli -h 127.0.0.1 -p ${REDIS_PORT} -a ${REDIS_PASSWORD} ping
redis-cli -h redis.arpansahu.space -p 9551 --tls --insecure -a ${REDIS_PASSWORD} ping

# View logs
docker logs -f redis-external

# Restart container
docker restart redis-external

# Check nginx stream
sudo nginx -T | grep -A 20 &quot;stream {&quot;
</code></pre>
<hr/>
<h2>
 Architecture Diagram
</h2>
<pre><code>[Your Application]
       ‚Üì
[redis.arpansahu.space:9551] ‚Üê TLS encrypted
       ‚Üì
[Nginx Stream Proxy] ‚Üê SSL termination
       ‚Üì
[127.0.0.1:6380] ‚Üê Redis Container (localhost only)
</code></pre>
<p>
 <strong>
  Security layers:
 </strong>
 <br/>
 1. Redis only accessible on localhost
 <br/>
 2. Nginx provides TLS encryption for external access
 <br/>
 3. Password authentication required for all connections
</p>
<hr/>
<h2>
 Django Integration with Redis TLS
</h2>
<h3>
 Environment Variables
</h3>
<pre><code class="language-env"># Redis with TLS (rediss:// scheme)
REDIS_CLOUD_URL=rediss://:your_redis_password@redis.arpansahu.space:9551
</code></pre>
<h3>
 Django Settings (settings.py)
</h3>
<h4>
 Cache Configuration
</h4>
<pre><code class="language-python">import ssl
import os

REDIS_CLOUD_URL = os.getenv(&#x27;REDIS_CLOUD_URL&#x27;)

# Django Cache with Redis TLS
CACHES = {
    &#x27;default&#x27;: {
        &#x27;BACKEND&#x27;: &#x27;django_redis.cache.RedisCache&#x27;,
        &#x27;LOCATION&#x27;: REDIS_CLOUD_URL,
        &#x27;OPTIONS&#x27;: {
            &#x27;CLIENT_CLASS&#x27;: &#x27;django_redis.client.DefaultClient&#x27;,
            &#x27;CONNECTION_POOL_KWARGS&#x27;: {
                &#x27;ssl_cert_reqs&#x27;: ssl.CERT_REQUIRED  # Verify Let&#x27;s Encrypt cert
            }
        }
    }
}
</code></pre>
<h4>
 Celery Configuration
</h4>
<pre><code class="language-python"># Celery broker and result backend
CELERY_BROKER_URL = REDIS_CLOUD_URL
CELERY_RESULT_BACKEND = REDIS_CLOUD_URL
CELERY_ACCEPT_CONTENT = [&#x27;json&#x27;]
CELERY_TASK_SERIALIZER = &#x27;json&#x27;
CELERY_RESULT_SERIALIZER = &#x27;json&#x27;
CELERY_TIMEZONE = &#x27;UTC&#x27;

# Celery SSL Configuration
CELERY_REDIS_BACKEND_USE_SSL = {
    &#x27;ssl_cert_reqs&#x27;: ssl.CERT_REQUIRED  # Verify SSL certificates
}
CELERY_BROKER_USE_SSL = {
    &#x27;ssl_cert_reqs&#x27;: ssl.CERT_REQUIRED  # Verify SSL certificates
}
</code></pre>
<h3>
 Celery App (celery.py)
</h3>
<pre><code class="language-python">import os
from celery import Celery

os.environ.setdefault(&#x27;DJANGO_SETTINGS_MODULE&#x27;, &#x27;your_project.settings&#x27;)

app = Celery(&#x27;your_project&#x27;)
app.config_from_object(&#x27;django.conf:settings&#x27;, namespace=&#x27;CELERY&#x27;)
app.autodiscover_tasks()

@app.task(bind=True)
def debug_task(self):
    print(f&#x27;Request: {self.request!r}&#x27;)
</code></pre>
<h3>
 Requirements
</h3>
<pre><code class="language-txt">django-redis&gt;=5.2.0
redis&gt;=4.5.0
celery&gt;=5.2.0
</code></pre>
<h3>
 Verification
</h3>
<pre><code class="language-bash"># Test Django cache
python manage.py shell
&gt;&gt;&gt; from django.core.cache import cache
&gt;&gt;&gt; cache.set(&#x27;test_key&#x27;, &#x27;test_value&#x27;, 300)
&gt;&gt;&gt; cache.get(&#x27;test_key&#x27;)
&#x27;test_value&#x27;

# Expected Celery worker logs
[INFO/MainProcess] Connected to rediss://:**@redis.arpansahu.space:9551//
[INFO/MainProcess] celery@your_project ready.
</code></pre>
<h3>
 Common Issues
</h3>
<table>
 <thead>
  <tr>
   <th>
    Issue
   </th>
   <th>
    Cause
   </th>
   <th>
    Solution
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <code>
     [SSL: CERTIFICATE_VERIFY_FAILED]
    </code>
   </td>
   <td>
    Wrong SSL verification setting
   </td>
   <td>
    Use
    <code>
     ssl.CERT_REQUIRED
    </code>
    - Let's Encrypt certs are trusted
   </td>
  </tr>
  <tr>
   <td>
    Connection timeout
   </td>
   <td>
    Wrong port or host
   </td>
   <td>
    Use port 9551, ensure nginx stream proxy is running
   </td>
  </tr>
  <tr>
   <td>
    Authentication failed
   </td>
   <td>
    Wrong password
   </td>
   <td>
    Check REDIS_CLOUD_URL password matches Redis setup
   </td>
  </tr>
  <tr>
   <td>
    Connection refused
   </td>
   <td>
    Redis not running
   </td>
   <td>
    Check:
    <code>
     docker ps \| grep redis
    </code>
   </td>
  </tr>
 </tbody>
</table>
<h3>
 SSL Certificate Verification
</h3>
<p>
 <strong>
  Important:
 </strong>
 Use
 <code>
  ssl.CERT_REQUIRED
 </code>
 (secure) instead of
 <code>
  ssl.CERT_NONE
 </code>
 (insecure).
</p>
<p>
 Let's Encrypt certificates at
 <code>
  /etc/nginx/ssl/arpansahu.space/
 </code>
 are automatically trusted by Python's SSL library. No need to disable certificate verification.
</p>
<pre><code class="language-python"># ‚úÖ CORRECT - Secure with certificate verification
&#x27;ssl_cert_reqs&#x27;: ssl.CERT_REQUIRED

# ‚ùå WRONG - Insecure, don&#x27;t use in production
&#x27;ssl_cert_reqs&#x27;: ssl.CERT_NONE
</code></pre>
<h1>
 MinIO - S3-Compatible Object Storage
</h1>
<p>
 MinIO is a high-performance, S3-compatible object storage solution perfect for storing static files, media uploads, backups, and any blob data.
</p>
<h2>
 üöÄ Quick Start
</h2>
<h3>
 Complete Installation (Recommended)
</h3>
<pre><code class="language-bash">cd &quot;AWS Deployment/Minio&quot;
./install.sh &amp;&amp; ./add-nginx-config.sh
</code></pre>
<p>
 This will:
 <br/>
 - Load environment variables from
 <code>
  .env
 </code>
 <br/>
 - Create data directory
 <br/>
 - Start MinIO container
 <br/>
 - Configure nginx for both Console and API
 <br/>
 - Reload nginx
</p>
<hr/>
<h2>
 üìã Prerequisites
</h2>
<ul>
 <li>
  Docker installed
 </li>
 <li>
  Nginx installed
 </li>
 <li>
  Domain/subdomain configured:
 </li>
 <li>
  <code>
   minio.arpansahu.space
  </code>
  ‚Üí 192.168.1.200 (Console)
 </li>
 <li>
  <code>
   minioapi.arpansahu.space
  </code>
  ‚Üí 192.168.1.200 (API)
 </li>
 <li>
  SSL certificates in
  <code>
   /etc/letsencrypt/live/arpansahu.space/
  </code>
 </li>
 <li>
  <code>
   .env
  </code>
  file (see Configuration)
 </li>
</ul>
<hr/>
<h2>
 ‚öôÔ∏è Configuration
</h2>
<h3>
 Environment Variables
</h3>
<p>
 Create
 <code>
  .env
 </code>
 from
 <code>
  .env.example
 </code>
 :
</p>
<pre><code class="language-bash">cp .env.example .env
</code></pre>
<p>
 Contents:
</p>
<pre><code class="language-env"># MinIO Root Credentials
MINIO_ROOT_USER=arpansahu
MINIO_ROOT_PASSWORD=Gandu302@minio

# Port Configuration
MINIO_PORT=9000          # S3 API port (localhost only)
MINIO_CONSOLE_PORT=9002  # Console web UI port (localhost only)

# AWS/Django Access Keys (create these in MinIO console after installation)
AWS_ACCESS_KEY_ID=django_user
AWS_SECRET_ACCESS_KEY=Gandu302@djangominio
AWS_STORAGE_BUCKET_NAME=arpansahu-one-bucket
</code></pre>
<blockquote>
 <p>
  <strong>
   Note:
  </strong>
  The AWS credentials are for application access. Create these access keys via MinIO Console after installation.
 </p>
</blockquote>
<hr/>
<h2>
 üì¶ Installation
</h2>
<h3>
 Option 1: Automated Install (Recommended)
</h3>
<pre><code class="language-bash">./install.sh
</code></pre>
<p>
 This script:
 <br/>
 1. Loads variables from
 <code>
  .env
 </code>
 <br/>
 2. Creates
 <code>
  ~/minio/data
 </code>
 directory
 <br/>
 3. Removes old container (if exists)
 <br/>
 4. Starts new MinIO container
 <br/>
 5. Exposes Console on port 9002 and API on port 9000 (localhost only)
</p>
<h3>
 Option 2: Manual Install
</h3>
<pre><code class="language-bash"># Load environment variables
source .env

# Create data directory
mkdir -p ~/minio/data

# Run MinIO
docker run -d \
  --name minio \
  --restart unless-stopped \
  -p 127.0.0.1:${MINIO_PORT}:9000 \
  -p 127.0.0.1:${MINIO_CONSOLE_PORT}:9001 \
  -e &quot;MINIO_ROOT_USER=${MINIO_ROOT_USER}&quot; \
  -e &quot;MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}&quot; \
  -v ~/minio/data:/data \
  quay.io/minio/minio:latest \
  server /data --console-address &quot;:9001&quot;
</code></pre>
<hr/>
<h2>
 üåê Nginx Configuration
</h2>
<h3>
 Automated Setup
</h3>
<pre><code class="language-bash">./add-nginx-config.sh
</code></pre>
<p>
 This configures:
 <br/>
 -
 <strong>
  Console (Web UI):
 </strong>
 minio.arpansahu.space ‚Üí localhost:9002
 <br/>
 -
 <strong>
  S3 API:
 </strong>
 minioapi.arpansahu.space ‚Üí localhost:9000
</p>
<h3>
 Key Features
</h3>
<ul>
 <li>
  SSL termination with Let's Encrypt certificates
 </li>
 <li>
  <code>
   client_max_body_size 500M
  </code>
  for large file uploads
 </li>
 <li>
  Proper WebSocket support for Console
 </li>
 <li>
  Security headers configured
 </li>
</ul>
<hr/>
<h2>
 üåç Router Configuration (External Access)
</h2>
<p>
 To access MinIO from outside your local network:
</p>
<h3>
 Port Forwarding Setup
</h3>
<ol>
 <li>
  <strong>
   Access Router Admin Panel:
  </strong>
 </li>
 <li>
  URL: http://192.168.1.1 (or https://airtel.arpansahu.space/cgi-bin/login_advance.cgi)
 </li>
 <li>
  Username:
  <code>
   admin
  </code>
 </li>
 <li>
  <p>
   Password:
   <code>
    Gandmara302@
   </code>
  </p>
 </li>
 <li>
  <p>
   <strong>
    Configure Port Forwarding:
   </strong>
  </p>
 </li>
 <li>
  <p>
   Navigate to:
   <strong>
    Advanced Settings
   </strong>
   ‚Üí
   <strong>
    NAT
   </strong>
   ‚Üí
   <strong>
    Virtual Server
   </strong>
  </p>
 </li>
 <li>
  <p>
   <strong>
    Add HTTPS Rule (443):
   </strong>
   <br/>
   | Field | Value |
   <br/>
   |-------|-------|
   <br/>
   | Service Name | MinIO HTTPS |
   <br/>
   | External Port | 443 |
   <br/>
   | Internal Port | 443 |
   <br/>
   | Internal IP | 192.168.1.200 |
   <br/>
   | Protocol | TCP |
   <br/>
   | Status | Enabled |
  </p>
 </li>
 <li>
  <p>
   <strong>
    Save and Apply
   </strong>
  </p>
 </li>
</ol>
<blockquote>
 <p>
  <strong>
   Note:
  </strong>
  Both
  <code>
   minio.arpansahu.space
  </code>
  and
  <code>
   minioapi.arpansahu.space
  </code>
  use port 443 (HTTPS), so only one port forwarding rule is needed.
 </p>
</blockquote>
<hr/>
<h2>
 üîê Access Details
</h2>
<table>
 <thead>
  <tr>
   <th>
    Component
   </th>
   <th>
    URL
   </th>
   <th>
    Port (localhost)
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    Console (Web UI)
   </td>
   <td>
    https://minio.arpansahu.space
   </td>
   <td>
    9002
   </td>
  </tr>
  <tr>
   <td>
    S3 API
   </td>
   <td>
    https://minioapi.arpansahu.space
   </td>
   <td>
    9000
   </td>
  </tr>
 </tbody>
</table>
<p>
 <strong>
  Root Credentials:
 </strong>
 <br/>
 - Username:
 <code>
  arpansahu
 </code>
 <br/>
 - Password:
 <code>
  Gandu302@minio
 </code>
</p>
<hr/>
<h2>
 üìÅ Initial Setup - Create Bucket & Access Keys
</h2>
<h3>
 1. Login to Console
</h3>
<p>
 Visit https://minio.arpansahu.space and login with root credentials.
</p>
<h3>
 2. Create Buckets
</h3>
<p>
 For Django applications, you typically need
 <strong>
  separate buckets
 </strong>
 for different types of content:
</p>
<h4>
 Option 1: Single Bucket (Simple Setup)
</h4>
<ol>
 <li>
  Navigate to
  <strong>
   Buckets
  </strong>
  ‚Üí
  <strong>
   Create Bucket
  </strong>
 </li>
 <li>
  <strong>
   Bucket Name:
  </strong>
  <code>
   arpansahu-one-bucket
  </code>
 </li>
 <li>
  <strong>
   Versioning:
  </strong>
  Enable (recommended for backup/recovery)
 </li>
 <li>
  <strong>
   Access Policy:
  </strong>
  Private (default)
 </li>
 <li>
  Click
  <strong>
   Create Bucket
  </strong>
 </li>
</ol>
<h4>
 Option 2: Multiple Buckets (Recommended for Production)
</h4>
<p>
 Create separate buckets for different access patterns:
</p>
<p>
 <strong>
  A. Static Files Bucket (Public Read)
 </strong>
 <br/>
 -
 <strong>
  Name:
 </strong>
 <code>
  arpansahu-static
 </code>
 <br/>
 -
 <strong>
  Purpose:
 </strong>
 CSS, JS, fonts, images
 <br/>
 -
 <strong>
  Policy:
 </strong>
 Public (download-only)
 <br/>
 -
 <strong>
  Why:
 </strong>
 Static files need to be publicly accessible by browsers
</p>
<p>
 <strong>
  B. Media Files Bucket (Private)
 </strong>
 <br/>
 -
 <strong>
  Name:
 </strong>
 <code>
  arpansahu-media
 </code>
 <br/>
 -
 <strong>
  Purpose:
 </strong>
 User uploads, documents, avatars
 <br/>
 -
 <strong>
  Policy:
 </strong>
 Private (access via Django only)
 <br/>
 -
 <strong>
  Why:
 </strong>
 User content should be access-controlled
</p>
<p>
 <strong>
  C. Backups Bucket (Private)
 </strong>
 <br/>
 -
 <strong>
  Name:
 </strong>
 <code>
  arpansahu-backups
 </code>
 <br/>
 -
 <strong>
  Purpose:
 </strong>
 Database backups, snapshots
 <br/>
 -
 <strong>
  Policy:
 </strong>
 Private (admin access only)
 <br/>
 -
 <strong>
  Why:
 </strong>
 Sensitive data, no public access
</p>
<h3>
 3. Set Bucket Policies
</h3>
<h4>
 Using MinIO Console (GUI)
</h4>
<ol>
 <li>
  Navigate to
  <strong>
   Buckets
  </strong>
  ‚Üí Select bucket ‚Üí
  <strong>
   Access Policy
  </strong>
 </li>
 <li>
  Choose policy type:
 </li>
</ol>
<table>
 <thead>
  <tr>
   <th>
    Policy Type
   </th>
   <th>
    Description
   </th>
   <th>
    Use Case
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <strong>
     Private
    </strong>
   </td>
   <td>
    No anonymous access
   </td>
   <td>
    Media uploads, user files, backups
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Public
    </strong>
   </td>
   <td>
    Full anonymous read/write
   </td>
   <td>
    ‚ùå
    <strong>
     Never use
    </strong>
    - security risk
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Download
    </strong>
   </td>
   <td>
    Anonymous read-only
   </td>
   <td>
    ‚úÖ Static files (CSS, JS, images)
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Upload
    </strong>
   </td>
   <td>
    Anonymous write-only
   </td>
   <td>
    Rare use case
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Custom
    </strong>
   </td>
   <td>
    JSON policy rules
   </td>
   <td>
    Fine-grained control
   </td>
  </tr>
 </tbody>
</table>
<h4>
 Using MinIO Client (mc)
</h4>
<pre><code class="language-bash"># Private (default) - no anonymous access
mc anonymous set none myminio/arpansahu-media

# Public download-only - for static files
mc anonymous set download myminio/arpansahu-static

# Check current policy
mc anonymous get myminio/arpansahu-static
</code></pre>
<h4>
 Custom JSON Policy (Advanced)
</h4>
<p>
 For fine-grained control, create a custom policy:
</p>
<pre><code class="language-json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {&quot;AWS&quot;: [&quot;*&quot;]},
      &quot;Action&quot;: [&quot;s3:GetObject&quot;],
      &quot;Resource&quot;: [&quot;arn:aws:s3:::arpansahu-static/*&quot;]
    }
  ]
}
</code></pre>
<p>
 Apply via Console:
 <strong>
  Buckets
 </strong>
 ‚Üí Select bucket ‚Üí
 <strong>
  Access Policy
 </strong>
 ‚Üí
 <strong>
  Add Custom Policy
 </strong>
</p>
<h4>
 Automated Bucket Policy Application
</h4>
<p>
 For easier policy management, use the included scripts:
</p>
<p>
 <strong>
  1. Create Policy File
 </strong>
</p>
<p>
 Copy the example and customize for your bucket:
</p>
<pre><code class="language-bash"># Copy template
cp minio_bucket_policy.json.example minio_bucket_policy.json

# Edit to match your bucket name and paths
nano minio_bucket_policy.json
</code></pre>
<p>
 Example policy for multi-project setup:
</p>
<pre><code class="language-json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {&quot;AWS&quot;: [&quot;*&quot;]},
      &quot;Action&quot;: [&quot;s3:GetObject&quot;],
      &quot;Resource&quot;: [
        &quot;arn:aws:s3:::arpansahu-one-bucket/portfolio/*/static/*&quot;,
        &quot;arn:aws:s3:::arpansahu-one-bucket/portfolio/*/media/*&quot;
      ]
    }
  ]
}
</code></pre>
<p>
 <strong>
  2. Update .env File
 </strong>
</p>
<p>
 Ensure your
 <code>
  .env
 </code>
 contains:
</p>
<pre><code class="language-env">MINIO_ROOT_USER=arpansahu
MINIO_ROOT_PASSWORD=your_password_here
AWS_STORAGE_BUCKET_NAME=arpansahu-one-bucket
MINIO_ENDPOINT=https://minioapi.arpansahu.space
POLICY_FILE=minio_bucket_policy.json
</code></pre>
<p>
 <strong>
  3. Apply Policy Using Script
 </strong>
</p>
<pre><code class="language-bash"># Option 1: Interactive script (recommended)
chmod +x apply_minio_policy.sh
./apply_minio_policy.sh

# Option 2: Python script
pip install boto3 python-dotenv
python3 apply_policy.py
</code></pre>
<p>
 <strong>
  Available Methods:
 </strong>
</p>
<table>
 <thead>
  <tr>
   <th>
    Method
   </th>
   <th>
    Tool Required
   </th>
   <th>
    Best For
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <strong>
     MinIO Client (mc)
    </strong>
   </td>
   <td>
    <code>
     brew install minio/stable/mc
    </code>
   </td>
   <td>
    Quick setup, simple policies
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     AWS CLI
    </strong>
   </td>
   <td>
    <code>
     brew install awscli
    </code>
   </td>
   <td>
    AWS compatibility, automation
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Python (boto3)
    </strong>
   </td>
   <td>
    <code>
     pip install boto3
    </code>
   </td>
   <td>
    Complex policies, validation
   </td>
  </tr>
 </tbody>
</table>
<p>
 <strong>
  Verify Policy Applied:
 </strong>
</p>
<pre><code class="language-bash"># Using mc
mc anonymous get myminio/arpansahu-one-bucket

# Using AWS CLI
aws --endpoint-url=https://minioapi.arpansahu.space \
    s3api get-bucket-policy \
    --bucket arpansahu-one-bucket

# Test public access
curl https://minioapi.arpansahu.space/arpansahu-one-bucket/portfolio/django_starter/static/test.txt
</code></pre>
<p>
 <strong>
  Security Notes:
 </strong>
 <br/>
 - ‚úÖ Scripts use environment variables (safe to commit)
 <br/>
 - ‚úÖ Never commit
 <code>
  .env
 </code>
 or
 <code>
  minio_bucket_policy.json
 </code>
 with real credentials
 <br/>
 - ‚úÖ
 <code>
  .gitignore
 </code>
 includes these files by default
 <br/>
 - ‚úÖ Use
 <code>
  .example
 </code>
 files as templates
</p>
<h4>
 Path-Based Policy (Single Bucket with Multiple Access Levels)
</h4>
<p>
 For
 <strong>
  one bucket
 </strong>
 with different paths having different access:
</p>
<pre><code class="language-json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {&quot;AWS&quot;: [&quot;*&quot;]},
      &quot;Action&quot;: [&quot;s3:GetObject&quot;],
      &quot;Resource&quot;: [&quot;arn:aws:s3:::arpansahu-one-bucket/static/*&quot;]
    }
  ]
}
</code></pre>
<p>
 This policy makes:
 <br/>
 -
 <code>
  static/*
 </code>
 ‚Üí
 <strong>
  Public read
 </strong>
 (anyone can access)
 <br/>
 -
 <code>
  media/*
 </code>
 ‚Üí
 <strong>
  Private
 </strong>
 (requires authentication)
 <br/>
 -
 <code>
  protected/*
 </code>
 ‚Üí
 <strong>
  Private
 </strong>
 (requires authentication + ownership check in Django)
 <br/>
 - Everything else ‚Üí
 <strong>
  Private
 </strong>
</p>
<p>
 <strong>
  Folder Structure Option 1: Simple
 </strong>
</p>
<pre><code>arpansahu-one-bucket/
‚îú‚îÄ‚îÄ static/              # PUBLIC (anonymous read via bucket policy)
‚îÇ   ‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îú‚îÄ‚îÄ media/               # PRIVATE (presigned URLs for authenticated users)
‚îÇ   ‚îú‚îÄ‚îÄ avatars/
‚îÇ   ‚îî‚îÄ‚îÄ uploads/
‚îî‚îÄ‚îÄ protected/           # PROTECTED (presigned URLs + ownership check)
    ‚îú‚îÄ‚îÄ invoices/
    ‚îî‚îÄ‚îÄ private-docs/
</code></pre>
<p>
 <strong>
  Folder Structure Option 2: Multi-Project with Portfolio Prefix
 </strong>
 ‚≠ê
 <strong>
  Recommended
 </strong>
</p>
<p>
 For hosting multiple Django projects in one bucket:
</p>
<pre><code>your-bucket-name/
‚îî‚îÄ‚îÄ portfolio/           # PUBLIC (anonymous read via bucket policy)
    ‚îú‚îÄ‚îÄ django_starter/
    ‚îÇ   ‚îî‚îÄ‚îÄ static/
    ‚îÇ       ‚îú‚îÄ‚îÄ css/
    ‚îÇ       ‚îú‚îÄ‚îÄ js/
    ‚îÇ       ‚îî‚îÄ‚îÄ admin/
    ‚îú‚îÄ‚îÄ borcelle_crm/
    ‚îÇ   ‚îî‚îÄ‚îÄ static/
    ‚îú‚îÄ‚îÄ chew_and_cheer/
    ‚îÇ   ‚îî‚îÄ‚îÄ static/
    ‚îî‚îÄ‚îÄ arpansahu_dot_me/
        ‚îî‚îÄ‚îÄ static/
</code></pre>
<p>
 <strong>
  Set public access for portfolio prefix using mc:
 </strong>
</p>
<pre><code class="language-bash"># Install MinIO client first (if not installed)
# See &quot;Install MinIO Client&quot; section below

# Set up alias (one-time)
mc alias set myminio http://localhost:9000 your_minio_root_user your_minio_root_password

# Set public read access for portfolio/* prefix
mc anonymous set public myminio/your-bucket-name/portfolio/

# Verify the policy
mc anonymous get myminio/your-bucket-name/portfolio/
# Should return: Access permission for `your-bucket-name/portfolio/` is `public`
</code></pre>
<p>
 <strong>
  Why use portfolio/ prefix?
 </strong>
 <br/>
 - ‚úÖ All projects share one bucket (cost-effective)
 <br/>
 - ‚úÖ Clear organization and separation
 <br/>
 - ‚úÖ Single bucket policy for all static files
 <br/>
 - ‚úÖ Easy to add new projects
 <br/>
 - ‚úÖ Consistent URL structure:
 <code>
  minioapi.arpansahu.space/your-bucket-name/portfolio/project-name/static/...
 </code>
</p>
<h3>
 4. Create Access Keys for Applications
</h3>
<ol>
 <li>
  Navigate to
  <strong>
   Access Keys
  </strong>
  ‚Üí
  <strong>
   Create access key
  </strong>
 </li>
 <li>
  Fill in details:
 </li>
 <li>
  <strong>
   Access Key:
  </strong>
  <code>
   django_user
  </code>
 </li>
 <li>
  <strong>
   Secret Key:
  </strong>
  <code>
   Gandu302@djangominio
  </code>
 </li>
 <li>
  <strong>
   Policy:
  </strong>
  <code>
   readwrite
  </code>
  (or custom policy)
 </li>
 <li>
  Click
  <strong>
   Create
  </strong>
 </li>
 <li>
  Save the credentials - they won't be shown again
 </li>
</ol>
<blockquote>
 <p>
  <strong>
   Security Note:
  </strong>
  Never use root credentials in applications. Always create separate access keys with minimal required permissions.
 </p>
</blockquote>
<hr/>
<hr/>
<h2>
 üêç Django Integration
</h2>
<h3>
 Install Required Packages
</h3>
<pre><code class="language-bash">pip install django-storages boto3
</code></pre>
<h3>
 Django Settings
</h3>
<h4>
 Option 1: Single Bucket (Simple)
</h4>
<pre><code class="language-python"># settings.py

# MinIO/S3 Configuration
AWS_S3_ENDPOINT_URL = &quot;https://minioapi.arpansahu.space&quot;
AWS_S3_VERIFY = True
AWS_ACCESS_KEY_ID = &quot;django_user&quot;
AWS_SECRET_ACCESS_KEY = &quot;Gandu302@djangominio&quot;
AWS_STORAGE_BUCKET_NAME = &quot;arpansahu-one-bucket&quot;  # Single bucket for everything
AWS_S3_ADDRESSING_STYLE = &quot;path&quot;
AWS_DEFAULT_ACL = None
AWS_S3_OBJECT_PARAMETERS = {
    &#x27;CacheControl&#x27;: &#x27;max-age=86400&#x27;,
}

# Storage Backends (Django 4.2+)
STORAGES = {
    &quot;default&quot;: {
        &quot;BACKEND&quot;: &quot;storages.backends.s3boto3.S3Boto3Storage&quot;,
    },
    &quot;staticfiles&quot;: {
        &quot;BACKEND&quot;: &quot;storages.backends.s3boto3.S3StaticStorage&quot;,
    },
}
</code></pre>
<blockquote>
 <p>
  <strong>
   Note:
  </strong>
  With single bucket, set bucket policy to
  <strong>
   Private
  </strong>
  . Django will handle access control via presigned URLs.
 </p>
</blockquote>
<h4>
 Option 2: Multiple Buckets (Recommended)
</h4>
<pre><code class="language-python"># settings.py

# MinIO/S3 Configuration
AWS_S3_ENDPOINT_URL = &quot;https://minioapi.arpansahu.space&quot;
AWS_S3_VERIFY = True
AWS_ACCESS_KEY_ID = &quot;django_user&quot;
AWS_SECRET_ACCESS_KEY = &quot;Gandu302@djangominio&quot;
AWS_S3_ADDRESSING_STYLE = &quot;path&quot;
AWS_DEFAULT_ACL = None

# Static Files Bucket (Public Read)
AWS_STATIC_BUCKET_NAME = &quot;arpansahu-static&quot;
AWS_S3_CUSTOM_DOMAIN = f&quot;{AWS_S3_ENDPOINT_URL.replace(&#x27;https://&#x27;, &#x27;&#x27;)}/{AWS_STATIC_BUCKET_NAME}&quot;

# Media Files Bucket (Private)
AWS_MEDIA_BUCKET_NAME = &quot;arpansahu-media&quot;

# Custom Storage Classes
from storages.backends.s3boto3 import S3Boto3Storage

class StaticStorage(S3Boto3Storage):
    bucket_name = AWS_STATIC_BUCKET_NAME
    default_acl = &#x27;public-read&#x27;  # Static files are publicly accessible
    querystring_auth = False  # No signed URLs needed

class MediaStorage(S3Boto3Storage):
    bucket_name = AWS_MEDIA_BUCKET_NAME
    default_acl = &#x27;private&#x27;  # Media files require authentication
    file_overwrite = False  # Don&#x27;t overwrite files with same name
    querystring_auth = True  # Use presigned URLs for temporary access
    querystring_expire = 3600  # URLs expire in 1 hour

# Storage Backends
STORAGES = {
    &quot;default&quot;: {
        &quot;BACKEND&quot;: &quot;path.to.MediaStorage&quot;,  # User uploads
    },
    &quot;staticfiles&quot;: {
        &quot;BACKEND&quot;: &quot;path.to.StaticStorage&quot;,  # CSS, JS, images
    },
}
</code></pre>
<p>
 <strong>
  Bucket Policies for Option 2:
 </strong>
 <br/>
 -
 <code>
  arpansahu-static
 </code>
 : Set to
 <strong>
  Download
 </strong>
 (public read-only)
 <br/>
 -
 <code>
  arpansahu-media
 </code>
 : Set to
 <strong>
  Private
 </strong>
 (Django controls access)
</p>
<h4>
 Option 3: Single Bucket with Path-Based Access (Recommended for Simplicity)
</h4>
<pre><code class="language-python"># settings.py

# MinIO/S3 Configuration
AWS_S3_ENDPOINT_URL = &quot;https://minioapi.arpansahu.space&quot;
AWS_S3_VERIFY = True
AWS_ACCESS_KEY_ID = &quot;django_user&quot;
AWS_SECRET_ACCESS_KEY = &quot;Gandu302@djangominio&quot;
AWS_STORAGE_BUCKET_NAME = &quot;arpansahu-one-bucket&quot;
AWS_S3_ADDRESSING_STYLE = &quot;path&quot;
AWS_DEFAULT_ACL = None

# Custom Storage Classes for Different Paths
from storages.backends.s3boto3 import S3Boto3Storage

class StaticStorage(S3Boto3Storage):
    location = &#x27;static&#x27;  # Files stored in /static/ prefix
    default_acl = &#x27;public-read&#x27;
    querystring_auth = False  # No signed URLs (public access via bucket policy)

class MediaStorage(S3Boto3Storage):
    location = &#x27;media&#x27;  # Files stored in /media/ prefix
    default_acl = &#x27;private&#x27;
    file_overwrite = False
    querystring_auth = True  # Presigned URLs for authenticated users
    querystring_expire = 3600  # 1 hour

class ProtectedStorage(S3Boto3Storage):
    location = &#x27;protected&#x27;  # Files stored in /protected/ prefix
    default_acl = &#x27;private&#x27;
    file_overwrite = False
    querystring_auth = True
    querystring_expire = 300  # 5 minutes (shorter for security)

# Storage Backends
STORAGES = {
    &quot;default&quot;: {
        &quot;BACKEND&quot;: &quot;path.to.MediaStorage&quot;,
    },
    &quot;staticfiles&quot;: {
        &quot;BACKEND&quot;: &quot;path.to.StaticStorage&quot;,
    },
}
</code></pre>
<p>
 <strong>
  Bucket Policy for Option 3:
 </strong>
 <br/>
 Set custom policy (see step 3 above) to make
 <code>
  static/*
 </code>
 public, rest private.
</p>
<p>
 <strong>
  Django Model Example with Protected Storage:
 </strong>
</p>
<pre><code class="language-python">class Invoice(models.Model):
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    pdf = models.FileField(
        upload_to=&#x27;invoices/&#x27;,
        storage=lambda: storages[&#x27;protected&#x27;]  # Protected path
    )

def download_invoice(request, invoice_id):
    invoice = Invoice.objects.get(id=invoice_id)
    if invoice.user != request.user:
        return HttpResponseForbidden()

    # Generate presigned URL only for owner
    storage = ProtectedStorage()
    url = storage.url(invoice.pdf.name)
    return redirect(url)
</code></pre>
<h3>
 Environment Variables (.env)
</h3>
<pre><code class="language-env"># Single Bucket Setup
AWS_S3_ENDPOINT_URL=&quot;https://minioapi.arpansahu.space&quot;
AWS_S3_VERIFY=True
AWS_ACCESS_KEY_ID=&quot;django_user&quot;
AWS_SECRET_ACCESS_KEY=&quot;Gandu302@djangominio&quot;
AWS_STORAGE_BUCKET_NAME=&quot;arpansahu-one-bucket&quot;
AWS_S3_ADDRESSING_STYLE=&quot;path&quot;

# Multiple Buckets Setup (add these)
AWS_STATIC_BUCKET_NAME=&quot;arpansahu-static&quot;
AWS_MEDIA_BUCKET_NAME=&quot;arpansahu-media&quot;
</code></pre>
<h3>
 Collect Static Files
</h3>
<pre><code class="language-bash">python manage.py collectstatic --noinput
</code></pre>
<h3>
 Usage in Models
</h3>
<pre><code class="language-python">from django.db import models

class Document(models.Model):
    title = models.CharField(max_length=200)
    # Uploads to media bucket (private)
    file = models.FileField(upload_to=&#x27;documents/&#x27;)
    created_at = models.DateTimeField(auto_now_add=True)

class UserProfile(models.Model):
    user = models.OneToOneField(User, on_delete=models.CASCADE)
    # Uploads to media bucket with presigned URL access
    avatar = models.ImageField(upload_to=&#x27;avatars/&#x27;)
</code></pre>
<h3>
 Accessing Private Files (Presigned URLs)
</h3>
<pre><code class="language-python">from django.core.files.storage import default_storage

# Generate temporary URL for private file
file_url = default_storage.url(&#x27;documents/private_file.pdf&#x27;)
# URL is valid for 1 hour (querystring_expire setting)
</code></pre>
<hr/>
<h2>
 üêç Python boto3 Examples
</h2>
<h3>
 Basic Operations
</h3>
<pre><code class="language-python">import boto3
from botocore.client import Config

# Initialize S3 client
s3 = boto3.client(
    &#x27;s3&#x27;,
    endpoint_url=&#x27;https://minioapi.arpansahu.space&#x27;,
    aws_access_key_id=&#x27;django_user&#x27;,
    aws_secret_access_key=&#x27;Gandu302@djangominio&#x27;,
    config=Config(signature_version=&#x27;s3v4&#x27;),
    verify=True
)

# Upload file
s3.upload_file(&#x27;local-file.txt&#x27;, &#x27;arpansahu-one-bucket&#x27;, &#x27;remote-file.txt&#x27;)

# Upload with metadata
s3.upload_file(
    &#x27;image.jpg&#x27;,
    &#x27;arpansahu-one-bucket&#x27;,
    &#x27;images/profile.jpg&#x27;,
    ExtraArgs={&#x27;ContentType&#x27;: &#x27;image/jpeg&#x27;, &#x27;ACL&#x27;: &#x27;public-read&#x27;}
)

# Download file
s3.download_file(&#x27;arpansahu-one-bucket&#x27;, &#x27;remote-file.txt&#x27;, &#x27;downloaded.txt&#x27;)

# List objects
response = s3.list_objects_v2(Bucket=&#x27;arpansahu-one-bucket&#x27;, Prefix=&#x27;documents/&#x27;)
for obj in response.get(&#x27;Contents&#x27;, []):
    print(f&quot;{obj[&#x27;Key&#x27;]} - {obj[&#x27;Size&#x27;]} bytes&quot;)

# Delete object
s3.delete_object(Bucket=&#x27;arpansahu-one-bucket&#x27;, Key=&#x27;remote-file.txt&#x27;)

# Generate presigned URL (temporary access)
url = s3.generate_presigned_url(
    &#x27;get_object&#x27;,
    Params={&#x27;Bucket&#x27;: &#x27;arpansahu-one-bucket&#x27;, &#x27;Key&#x27;: &#x27;private-file.pdf&#x27;},
    ExpiresIn=3600  # 1 hour
)
print(f&quot;Temporary URL: {url}&quot;)
</code></pre>
<h3>
 Upload Directory
</h3>
<pre><code class="language-python">import os

def upload_directory(local_dir, bucket, s3_prefix=&#x27;&#x27;):
    for root, dirs, files in os.walk(local_dir):
        for file in files:
            local_path = os.path.join(root, file)
            relative_path = os.path.relpath(local_path, local_dir)
            s3_path = os.path.join(s3_prefix, relative_path).replace(&#x27;\\&#x27;, &#x27;/&#x27;)

            print(f&quot;Uploading {local_path} to {s3_path}&quot;)
            s3.upload_file(local_path, bucket, s3_path)

# Usage
upload_directory(&#x27;/path/to/local/folder&#x27;, &#x27;arpansahu-one-bucket&#x27;, &#x27;backups/&#x27;)
</code></pre>
<hr/>
<hr/>
<h2>
 üõ†Ô∏è MinIO Client (mc)
</h2>
<p>
 MinIO Client provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff.
</p>
<h3>
 Installation
</h3>
<pre><code class="language-bash"># Linux/Mac
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/

# Mac (Homebrew)
brew install minio/stable/mc
</code></pre>
<h3>
 Configuration
</h3>
<pre><code class="language-bash"># Add MinIO server as alias
mc alias set myminio https://minioapi.arpansahu.space django_user Gandu302@djangominio

# Test connection
mc admin info myminio
</code></pre>
<h3>
 Common Commands
</h3>
<pre><code class="language-bash"># List buckets
mc ls myminio

# List objects in bucket
mc ls myminio/arpansahu-one-bucket

# Copy file to bucket
mc cp local-file.txt myminio/arpansahu-one-bucket/

# Copy entire directory
mc cp --recursive local-folder/ myminio/arpansahu-one-bucket/folder/

# Mirror directory (sync)
mc mirror local-folder/ myminio/arpansahu-one-bucket/folder/

# Download file
mc cp myminio/arpansahu-one-bucket/file.txt ./downloaded.txt

# Remove file
mc rm myminio/arpansahu-one-bucket/file.txt

# Remove directory recursively
mc rm --recursive --force myminio/arpansahu-one-bucket/folder/

# Get file stats
mc stat myminio/arpansahu-one-bucket/file.txt

# Watch for events
mc watch myminio/arpansahu-one-bucket
</code></pre>
<h3>
 Bucket Management
</h3>
<pre><code class="language-bash"># Create bucket
mc mb myminio/new-bucket

# Remove bucket
mc rb myminio/old-bucket

# Set bucket policy (public read)
mc anonymous set public myminio/arpansahu-one-bucket

# Set bucket policy (download only)
mc anonymous set download myminio/arpansahu-one-bucket

# Get bucket policy
mc anonymous get myminio/arpansahu-one-bucket
</code></pre>
<hr/>
<h2>
 üîß Management & Maintenance
</h2>
<h3>
 Docker Commands
</h3>
<pre><code class="language-bash"># View logs
docker logs -f minio

# Restart container
docker restart minio

# Stop container
docker stop minio

# Start container
docker start minio

# Remove container
docker rm -f minio
</code></pre>
<h3>
 Update MinIO
</h3>
<pre><code class="language-bash"># Pull latest image
docker pull quay.io/minio/minio:latest

# Stop and remove old container
docker stop minio &amp;&amp; docker rm minio

# Reinstall
cd &quot;AWS Deployment/Minio&quot;
./install.sh
</code></pre>
<h3>
 Backup Data
</h3>
<pre><code class="language-bash"># Backup all data
tar -czf minio-backup-$(date +%Y%m%d).tar.gz ~/minio/data

# Backup specific bucket (using mc)
mc mirror myminio/arpansahu-one-bucket ~/backups/bucket-backup/

# Restore from backup
mc mirror ~/backups/bucket-backup/ myminio/arpansahu-one-bucket/
</code></pre>
<h3>
 Check Disk Usage
</h3>
<pre><code class="language-bash"># Server disk space
df -h ~/minio/data

# Bucket sizes (via mc)
mc du myminio/arpansahu-one-bucket
</code></pre>
<hr/>
<h2>
 üêõ Troubleshooting
</h2>
<h3>
 WebSocket Connection Errors
</h3>
<p>
 <strong>
  Symptoms:
 </strong>
 Console shows repeated errors:
</p>
<pre><code>WebSocket connection to &#x27;wss://minio.arpansahu.space/ws/objectManager&#x27; failed
</code></pre>
<p>
 <strong>
  Cause:
 </strong>
 Missing WebSocket upgrade headers in nginx configuration.
</p>
<p>
 <strong>
  Fix:
 </strong>
</p>
<pre><code class="language-bash">cd &quot;AWS Deployment/Minio&quot;
sudo ./fix-websocket.sh
</code></pre>
<p>
 This script adds required headers:
 <br/>
 -
 <code>
  proxy_http_version 1.1
 </code>
 <br/>
 -
 <code>
  proxy_set_header Upgrade $http_upgrade
 </code>
 <br/>
 -
 <code>
  proxy_set_header Connection &quot;upgrade&quot;
 </code>
</p>
<p>
 After running, hard refresh browser (Ctrl+Shift+R or Cmd+Shift+R).
</p>
<p>
 <strong>
  Manual Verification:
 </strong>
</p>
<pre><code class="language-bash">grep -A 5 &quot;server_name minio.arpansahu.space&quot; /etc/nginx/sites-enabled/services | grep Upgrade
</code></pre>
<p>
 Should show:
 <code>
  proxy_set_header Upgrade $http_upgrade;
 </code>
</p>
<h3>
 Can't Access Console
</h3>
<pre><code class="language-bash"># Check if container is running
docker ps | grep minio

# Check logs
docker logs minio

# Restart container
docker restart minio

# Test nginx configuration
sudo nginx -t

# Reload nginx
sudo systemctl reload nginx

# Check DNS resolution
nslookup minio.arpansahu.space
</code></pre>
<h3>
 Upload Fails / File Too Large
</h3>
<pre><code class="language-bash"># Check nginx client_max_body_size
sudo grep -r &quot;client_max_body_size&quot; /etc/nginx/

# Should be 500M in MinIO configs
# If not, update and reload:
sudo vi /etc/nginx/sites-enabled/minio-console
sudo vi /etc/nginx/sites-enabled/minio-api
sudo systemctl reload nginx

# Check disk space
df -h ~/minio/data
</code></pre>
<h3>
 Connection Refused / Can't Connect to API
</h3>
<pre><code class="language-bash"># Verify ports are listening
sudo ss -lntp | grep -E &#x27;9000|9002&#x27;

# Test local access
curl http://localhost:9002  # Console
curl http://localhost:9000/minio/health/live  # API health

# Check firewall
sudo ufw status

# Test from Mac/external
curl -I https://minio.arpansahu.space
curl -I https://minioapi.arpansahu.space
</code></pre>
<h3>
 SSL/Certificate Issues
</h3>
<pre><code class="language-bash"># Verify certificates exist
ls -la /etc/letsencrypt/live/arpansahu.space/

# Test SSL
openssl s_client -connect minio.arpansahu.space:443 -servername minio.arpansahu.space

# Check nginx SSL configuration
sudo nginx -T | grep -A 10 &quot;minio.arpansahu.space&quot;
</code></pre>
<h3>
 Django Integration Issues
</h3>
<pre><code class="language-python"># Test boto3 connection
import boto3
s3 = boto3.client(
    &#x27;s3&#x27;,
    endpoint_url=&#x27;https://minioapi.arpansahu.space&#x27;,
    aws_access_key_id=&#x27;django_user&#x27;,
    aws_secret_access_key=&#x27;Gandu302@djangominio&#x27;
)
print(s3.list_buckets())
</code></pre>
<h3>
 Access Denied Errors
</h3>
<ol>
 <li>
  <strong>
   Verify access keys are correct
  </strong>
  in Django settings
 </li>
 <li>
  <strong>
   Check bucket policy
  </strong>
  in MinIO Console ‚Üí Buckets ‚Üí [bucket name] ‚Üí Access Policy
 </li>
 <li>
  <strong>
   Verify access key permissions
  </strong>
  in MinIO Console ‚Üí Access Keys ‚Üí [key] ‚Üí Policy
 </li>
 <li>
  <strong>
   Ensure bucket exists:
  </strong>
  <code>
   mc ls myminio
  </code>
 </li>
</ol>
<hr/>
<h2>
 üìö Additional Resources
</h2>
<ul>
 <li>
  <strong>
   MinIO Documentation:
  </strong>
  https://min.io/docs/minio/linux/index.html
 </li>
 <li>
  <strong>
   Django Storages:
  </strong>
  https://django-storages.readthedocs.io/en/latest/backends/amazon-S3.html
 </li>
 <li>
  <strong>
   boto3 Documentation:
  </strong>
  https://boto3.amazonaws.com/v1/documentation/api/latest/index.html
 </li>
 <li>
  <strong>
   MinIO Client Guide:
  </strong>
  https://min.io/docs/minio/linux/reference/minio-mc.html
 </li>
</ul>
<hr/>
<h2>
 üîí Security Best Practices
</h2>
<h3>
 Bucket Policy Guidelines
</h3>
<p>
 <strong>
  ‚úÖ DO:
 </strong>
 <br/>
 - Use
 <strong>
  Private
 </strong>
 policy for user uploads, sensitive data, backups
 <br/>
 - Use
 <strong>
  Download
 </strong>
 (public read) policy ONLY for static assets (CSS, JS, images)
 <br/>
 - Create separate buckets for different access levels
 <br/>
 - Use presigned URLs for temporary access to private files
 <br/>
 - Enable bucket versioning for important data
</p>
<p>
 <strong>
  ‚ùå DON'T:
 </strong>
 <br/>
 - Never use
 <strong>
  Public
 </strong>
 (full read/write) policy - major security risk
 <br/>
 - Don't store sensitive data in public buckets
 <br/>
 - Don't share root credentials with applications
 <br/>
 - Don't set static and media files in same bucket with public policy
</p>
<h3>
 Bucket Policy by Use Case
</h3>
<table>
 <thead>
  <tr>
   <th>
    Content Type
   </th>
   <th>
    Bucket Policy
   </th>
   <th>
    Why
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <strong>
     Static Files
    </strong>
    (CSS, JS, fonts, images)
   </td>
   <td>
    Download (public read)
   </td>
   <td>
    Need to be loaded by browsers without authentication
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Media Uploads
    </strong>
    (user avatars, documents)
   </td>
   <td>
    Private
   </td>
   <td>
    Access controlled by Django, use presigned URLs
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Database Backups
    </strong>
   </td>
   <td>
    Private
   </td>
   <td>
    Sensitive data, admin-only access
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Public Assets
    </strong>
    (blog images, public downloads)
   </td>
   <td>
    Download (public read)
   </td>
   <td>
    Intentionally public content
   </td>
  </tr>
  <tr>
   <td>
    <strong>
     Form Uploads
    </strong>
    (before processing)
   </td>
   <td>
    Private
   </td>
   <td>
    Temporary storage, should be access-controlled
   </td>
  </tr>
 </tbody>
</table>
<h3>
 Access Key Permissions
</h3>
<p>
 Create access keys with minimal required permissions:
</p>
<p>
 <strong>
  For Django Application:
 </strong>
</p>
<pre><code class="language-json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Action&quot;: [
        &quot;s3:GetObject&quot;,
        &quot;s3:PutObject&quot;,
        &quot;s3:DeleteObject&quot;,
        &quot;s3:ListBucket&quot;
      ],
      &quot;Resource&quot;: [
        &quot;arn:aws:s3:::arpansahu-media/*&quot;,
        &quot;arn:aws:s3:::arpansahu-static/*&quot;,
        &quot;arn:aws:s3:::arpansahu-media&quot;,
        &quot;arn:aws:s3:::arpansahu-static&quot;
      ]
    }
  ]
}
</code></pre>
<p>
 <strong>
  For Read-Only Access:
 </strong>
</p>
<pre><code class="language-json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Action&quot;: [
        &quot;s3:GetObject&quot;,
        &quot;s3:ListBucket&quot;
      ],
      &quot;Resource&quot;: [
        &quot;arn:aws:s3:::arpansahu-media/*&quot;,
        &quot;arn:aws:s3:::arpansahu-media&quot;
      ]
    }
  ]
}
</code></pre>
<h3>
 General Security
</h3>
<ol>
 <li>
  <strong>
   Never expose MinIO ports (9000, 9002) directly
  </strong>
  - always use nginx reverse proxy
 </li>
 <li>
  <strong>
   Use separate access keys for each application
  </strong>
  - never share root credentials
 </li>
 <li>
  <strong>
   Enable bucket versioning
  </strong>
  for important data
 </li>
 <li>
  <strong>
   Set minimal required permissions
  </strong>
  on access keys
 </li>
 <li>
  <strong>
   Regularly rotate access keys
  </strong>
 </li>
 <li>
  <strong>
   Monitor access logs
  </strong>
  via MinIO Console
 </li>
 <li>
  <strong>
   Use HTTPS only
  </strong>
  - never HTTP for production
 </li>
 <li>
  <strong>
   Keep MinIO updated
  </strong>
  to latest stable version
 </li>
 <li>
  <strong>
   Review bucket policies regularly
  </strong>
  - ensure they match current requirements
 </li>
 <li>
  <strong>
   Use presigned URLs for private content
  </strong>
  - temporary access with expiration
 </li>
</ol>
<hr/>
<hr/>
<h2>
 üåê Complete Django Integration with All Services
</h2>
<h3>
 Full Production Configuration Example
</h3>
<p>
 This example shows a complete Django setup with
 <strong>
  MinIO + Redis (TLS) + PostgreSQL + Celery
 </strong>
 , all using domain names and secure SSL/TLS connections.
</p>
<h4>
 Environment Variables (.env)
</h4>
<pre><code class="language-env"># Django
DEBUG=False
SECRET_KEY=&quot;your-secret-key&quot;
ALLOWED_HOSTS=django-starter.arpansahu.space

# PostgreSQL (TLS stream proxy on port 9552)
DATABASE_URL=postgresql://postgres:your_postgres_password@postgres.arpansahu.space:9552/your_database_name

# Redis (TLS stream proxy on port 9551)
REDIS_CLOUD_URL=rediss://:your_redis_password@redis.arpansahu.space:9551

# MinIO S3 (API endpoint with HTTPS)
AWS_S3_ENDPOINT_URL=https://minioapi.arpansahu.space
AWS_S3_VERIFY=True
AWS_ACCESS_KEY_ID=your_minio_access_key
AWS_SECRET_ACCESS_KEY=your_minio_secret_key
AWS_STORAGE_BUCKET_NAME=your-bucket-name
AWS_S3_ADDRESSING_STYLE=path
</code></pre>
<h4>
 Django Settings (settings.py)
</h4>
<pre><code class="language-python">import os
import ssl
from pathlib import Path

# Load environment variables
DEBUG = os.getenv(&#x27;DEBUG&#x27;, &#x27;False&#x27;) == &#x27;True&#x27;
SECRET_KEY = os.getenv(&#x27;SECRET_KEY&#x27;)
ALLOWED_HOSTS = os.getenv(&#x27;ALLOWED_HOSTS&#x27;, &#x27;&#x27;).split(&#x27;,&#x27;)

# Database Configuration
import dj_database_url
DATABASES = {
    &#x27;default&#x27;: dj_database_url.config(
        default=os.getenv(&#x27;DATABASE_URL&#x27;),
        conn_max_age=600,
        conn_health_checks=True,
    )
}

# Redis Configuration
REDIS_CLOUD_URL = os.getenv(&#x27;REDIS_CLOUD_URL&#x27;)

# Cache with Redis SSL
CACHES = {
    &#x27;default&#x27;: {
        &#x27;BACKEND&#x27;: &#x27;django_redis.cache.RedisCache&#x27;,
        &#x27;LOCATION&#x27;: REDIS_CLOUD_URL,
        &#x27;OPTIONS&#x27;: {
            &#x27;CLIENT_CLASS&#x27;: &#x27;django_redis.client.DefaultClient&#x27;,
            &#x27;CONNECTION_POOL_KWARGS&#x27;: {
                &#x27;ssl_cert_reqs&#x27;: ssl.CERT_REQUIRED  # Verify Let&#x27;s Encrypt cert
            }
        }
    }
}

# Celery Configuration with Redis SSL
CELERY_BROKER_URL = REDIS_CLOUD_URL
CELERY_RESULT_BACKEND = REDIS_CLOUD_URL
CELERY_ACCEPT_CONTENT = [&#x27;json&#x27;]
CELERY_TASK_SERIALIZER = &#x27;json&#x27;
CELERY_RESULT_SERIALIZER = &#x27;json&#x27;
CELERY_TIMEZONE = &#x27;UTC&#x27;

# Celery SSL Configuration (Let&#x27;s Encrypt certificates are trusted)
CELERY_REDIS_BACKEND_USE_SSL = {
    &#x27;ssl_cert_reqs&#x27;: ssl.CERT_REQUIRED
}
CELERY_BROKER_USE_SSL = {
    &#x27;ssl_cert_reqs&#x27;: ssl.CERT_REQUIRED
}

# MinIO/S3 Configuration for Multi-Project Setup
AWS_S3_ENDPOINT_URL = os.getenv(&#x27;AWS_S3_ENDPOINT_URL&#x27;)
AWS_S3_VERIFY = os.getenv(&#x27;AWS_S3_VERIFY&#x27;, &#x27;True&#x27;) == &#x27;True&#x27;
AWS_ACCESS_KEY_ID = os.getenv(&#x27;AWS_ACCESS_KEY_ID&#x27;)
AWS_SECRET_ACCESS_KEY = os.getenv(&#x27;AWS_SECRET_ACCESS_KEY&#x27;)
AWS_STORAGE_BUCKET_NAME = os.getenv(&#x27;AWS_STORAGE_BUCKET_NAME&#x27;)
AWS_S3_ADDRESSING_STYLE = &#x27;path&#x27;
AWS_DEFAULT_ACL = None

# Custom domain for static files (portfolio prefix for multi-project)
PROJECT_NAME = &#x27;django_starter&#x27;  # Change per project
AWS_LOCATION = f&#x27;portfolio/{PROJECT_NAME}&#x27;  # Project-specific prefix
AWS_S3_CUSTOM_DOMAIN = f&#x27;{AWS_S3_ENDPOINT_URL.replace(&quot;https://&quot;, &quot;&quot;)}/{AWS_STORAGE_BUCKET_NAME}&#x27;

# Static files configuration
STATIC_URL = f&#x27;https://{AWS_S3_CUSTOM_DOMAIN}/{AWS_LOCATION}/static/&#x27;
STATIC_ROOT = BASE_DIR / &#x27;staticfiles&#x27;

# Storage backends (Django 4.2+)
STORAGES = {
    &quot;default&quot;: {
        &quot;BACKEND&quot;: &quot;storages.backends.s3boto3.S3Boto3Storage&quot;,
    },
    &quot;staticfiles&quot;: {
        &quot;BACKEND&quot;: &quot;storages.backends.s3boto3.S3StaticStorage&quot;,
    },
}

# Additional S3 settings
AWS_S3_OBJECT_PARAMETERS = {
    &#x27;CacheControl&#x27;: &#x27;max-age=86400&#x27;,  # Cache for 1 day
}
AWS_QUERYSTRING_AUTH = False  # No signed URLs for static files
</code></pre>
<h4>
 Celery Configuration (celery.py)
</h4>
<pre><code class="language-python">import os
from celery import Celery

os.environ.setdefault(&#x27;DJANGO_SETTINGS_MODULE&#x27;, &#x27;django_starter.settings&#x27;)

app = Celery(&#x27;django_starter&#x27;)
app.config_from_object(&#x27;django.conf:settings&#x27;, namespace=&#x27;CELERY&#x27;)
app.autodiscover_tasks()

@app.task(bind=True)
def debug_task(self):
    print(f&#x27;Request: {self.request!r}&#x27;)
</code></pre>
<h4>
 Requirements
</h4>
<pre><code class="language-txt">Django&gt;=4.2
psycopg2-binary
dj-database-url
django-redis
redis
celery
django-storages
boto3
</code></pre>
<h4>
 Deployment Commands
</h4>
<pre><code class="language-bash"># Collect static files to MinIO
python manage.py collectstatic --noinput

# Run migrations
python manage.py migrate

# Start Django (production)
gunicorn django_starter.wsgi:application --bind 0.0.0.0:8016

# Start Celery worker
celery -A django_starter worker --loglevel=info

# Start Celery beat (if needed)
celery -A django_starter beat --loglevel=info
</code></pre>
<h4>
 Infrastructure Requirements
</h4>
<p>
 All these services must be configured on your server:
</p>
<ol>
 <li>
  <strong>
   PostgreSQL
  </strong>
  with nginx TLS stream proxy on port 9552
 </li>
 <li>
  <strong>
   Redis
  </strong>
  with nginx TLS stream proxy on port 9551
 </li>
 <li>
  <strong>
   MinIO API
  </strong>
  with nginx HTTPS proxy at minioapi.arpansahu.space
 </li>
 <li>
  <strong>
   Let's Encrypt SSL certificates
  </strong>
  (automatically trusted by Python)
 </li>
</ol>
<p>
 See individual service documentation:
 <br/>
 -
 <a href="../03-postgres/README.md">
  PostgreSQL Setup
 </a>
 <br/>
 -
 <a href="../05-redis/README.md">
  Redis Setup
 </a>
 <br/>
 -
 <a href="../08-minio/README.md">
  MinIO Setup
 </a>
</p>
<h4>
 Verification
</h4>
<pre><code class="language-bash"># Test Redis connection
redis-cli -h redis.arpansahu.space -p 9551 -a your_redis_password --tls ping
# Should return: PONG

# Test MinIO access
curl -I https://minioapi.arpansahu.space/your-bucket-name/portfolio/your_project/static/admin/css/base.css
# Should return: HTTP/2 200

# Test static file serving
curl https://django-starter.arpansahu.space
# CSS/JS should load from minioapi.arpansahu.space
</code></pre>
<h4>
 Expected Celery Logs
</h4>
<pre><code>[2026-02-03 14:42:59,941: INFO/MainProcess] Connected to rediss://:**@redis.arpansahu.space:9551//
[2026-02-03 14:42:59,953: INFO/MainProcess] celery@django_starter ready.
</code></pre>
<h4>
 Common Issues
</h4>
<table>
 <thead>
  <tr>
   <th>
    Issue
   </th>
   <th>
    Cause
   </th>
   <th>
    Solution
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    400 Bad Request from boto3
   </td>
   <td>
    Using Console URL instead of API
   </td>
   <td>
    Use
    <code>
     minioapi.arpansahu.space
    </code>
    , not
    <code>
     minio.arpansahu.space
    </code>
   </td>
  </tr>
  <tr>
   <td>
    CSS not loading
   </td>
   <td>
    Files not uploaded to MinIO
   </td>
   <td>
    Run
    <code>
     collectstatic
    </code>
    , check MinIO bucket
   </td>
  </tr>
  <tr>
   <td>
    Redis SSL connection failed
   </td>
   <td>
    Certificate verification issue
   </td>
   <td>
    Use
    <code>
     ssl.CERT_REQUIRED
    </code>
    (Let's Encrypt is trusted)
   </td>
  </tr>
  <tr>
   <td>
    Celery can't connect to Redis
   </td>
   <td>
    Wrong URL or missing TLS proxy
   </td>
   <td>
    Use
    <code>
     rediss://
    </code>
    scheme, ensure nginx stream proxy on 9551
   </td>
  </tr>
  <tr>
   <td>
    collectstatic slow/fails
   </td>
   <td>
    Network issues or wrong credentials
   </td>
   <td>
    Check AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
   </td>
  </tr>
 </tbody>
</table>
<hr/>
<h2>
 ‚úÖ Verification
</h2>
<p>
 After installation, verify everything works:
</p>
<pre><code class="language-bash"># 1. Check container status
docker ps | grep minio

# 2. Check local access
curl http://localhost:9002
curl http://localhost:9000/minio/health/live

# 3. Check HTTPS access
curl -I https://minio.arpansahu.space
curl -I https://minioapi.arpansahu.space

# 4. Login to console
# Visit: https://minio.arpansahu.space
# Login with: arpansahu / Gandu302@minio

# 5. Test with mc client
mc alias set test https://minioapi.arpansahu.space django_user Gandu302@djangominio
mc ls test
</code></pre>
<p>
 All checks should pass ‚úÖ
</p>
<hr/>
<h2>
 üìÅ Files Reference
</h2>
<p>
 All deployment files are in:
 <code>
  AWS Deployment/Minio/
 </code>
</p>
<table>
 <thead>
  <tr>
   <th>
    File
   </th>
   <th>
    Purpose
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    <code>
     .env.example
    </code>
   </td>
   <td>
    Template for environment variables
   </td>
  </tr>
  <tr>
   <td>
    <code>
     .env
    </code>
   </td>
   <td>
    Actual credentials (not in git)
   </td>
  </tr>
  <tr>
   <td>
    <code>
     install.sh
    </code>
   </td>
   <td>
    Main installation script
   </td>
  </tr>
  <tr>
   <td>
    <code>
     add-nginx-config.sh
    </code>
   </td>
   <td>
    Adds nginx reverse proxy config
   </td>
  </tr>
  <tr>
   <td>
    <code>
     fix-websocket.sh
    </code>
   </td>
   <td>
    Fixes WebSocket connection issues
   </td>
  </tr>
  <tr>
   <td>
    <code>
     nginx-console.conf
    </code>
   </td>
   <td>
    Standalone Console nginx config
   </td>
  </tr>
  <tr>
   <td>
    <code>
     nginx-api.conf
    </code>
   </td>
   <td>
    Standalone API nginx config
   </td>
  </tr>
  <tr>
   <td>
    <code>
     apply_minio_policy.sh
    </code>
   </td>
   <td>
    Automated bucket policy application script
   </td>
  </tr>
  <tr>
   <td>
    <code>
     apply_policy.py
    </code>
   </td>
   <td>
    Python script for bucket policy management
   </td>
  </tr>
  <tr>
   <td>
    <code>
     minio_bucket_policy.json.example
    </code>
   </td>
   <td>
    Template for bucket policy
   </td>
  </tr>
  <tr>
   <td>
    <code>
     minio_bucket_policy.json
    </code>
   </td>
   <td>
    Actual bucket policy (not in git)
   </td>
  </tr>
  <tr>
   <td>
    <code>
     README.md
    </code>
   </td>
   <td>
    This documentation
   </td>
  </tr>
 </tbody>
</table>
<p>
 <strong>
  On Server:
 </strong>
 <br/>
 - Data:
 <code>
  ~/minio/data/
 </code>
 <br/>
 - Nginx config:
 <code>
  /etc/nginx/sites-available/services
 </code>
 (merged config)
 <br/>
 - Logs:
 <code>
  docker logs minio
 </code>
</p>
<hr/>
<h2>
 Jenkins (CI/CD Automation Server)
</h2>
<p>
 Jenkins is an open-source automation server that enables developers to build, test, and deploy applications through continuous integration and continuous delivery (CI/CD). This guide provides a complete, production-ready setup with Java 21, Jenkins LTS, Nginx reverse proxy, and comprehensive credential management.
</p>
<h3>
 Prerequisites
</h3>
<p>
 Before installing Jenkins, ensure you have:
</p>
<ol>
 <li>
  Ubuntu Server 22.04 LTS
 </li>
 <li>
  Nginx with SSL certificates configured
 </li>
 <li>
  Domain name (example: jenkins.arpansahu.space)
 </li>
 <li>
  Wildcard SSL certificate already issued (via acme.sh)
 </li>
 <li>
  Minimum 2GB RAM, 20GB disk space
 </li>
 <li>
  Root or sudo access
 </li>
 <li>
  Docker installed (for containerized builds)
 </li>
</ol>
<h3>
 Architecture Overview
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (Port 443) - TLS Termination
        ‚îÇ
        ‚îî‚îÄ jenkins.arpansahu.space
             ‚îÇ
             ‚îî‚îÄ Jenkins (localhost:8080)
                  ‚îÇ
                  ‚îú‚îÄ Jenkins Controller (Web UI + API)
                  ‚îú‚îÄ Build Agents (local/remote)
                  ‚îú‚îÄ Workspace (/var/lib/jenkins)
                  ‚îî‚îÄ Credentials Store
</code></pre>
<p>
 Key Principles:
 <br/>
 - Jenkins runs on localhost only (port 8080)
 <br/>
 - Nginx handles all TLS termination
 <br/>
 - Credentials stored in Jenkins encrypted store
 <br/>
 - Pipelines defined as code (Jenkinsfile)
 <br/>
 - Docker-based builds for isolation
</p>
<h3>
 Why Jenkins
</h3>
<p>
 <strong>
  Advantages:
 </strong>
 <br/>
 - Open-source and free
 <br/>
 - Extensive plugin ecosystem (1800+)
 <br/>
 - Pipeline as Code (Jenkinsfile)
 <br/>
 - Distributed builds
 <br/>
 - Docker integration
 <br/>
 - GitHub/GitLab integration
 <br/>
 - Email notifications
 <br/>
 - Role-based access control
</p>
<p>
 <strong>
  Use Cases:
 </strong>
 <br/>
 - Automated builds on commit
 <br/>
 - Automated testing
 <br/>
 - Docker image building
 <br/>
 - Deployment automation
 <br/>
 - Scheduled jobs
 <br/>
 - Integration with Harbor registry
 <br/>
 - Multi-branch pipelines
</p>
<h3>
 Part 1: Install Java 21
</h3>
<p>
 Jenkins requires Java to run. We'll install OpenJDK 21 (latest LTS).
</p>
<p>
 <strong>
  ‚ö†Ô∏è Important:
 </strong>
 Java 17 support ends March 31, 2026. Use Java 21 for continued support.
</p>
<h4>
 Check Current Java Version
</h4>
<pre><code class="language-bash">java -version
</code></pre>
<p>
 If you see Java 17 or older, follow the upgrade steps below.
</p>
<h4>
 Upgrade from Java 17 to Java 21 (If Needed)
</h4>
<p>
 If Jenkins is already installed on Java 17:
</p>
<ol>
 <li>
  Install Java 21
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
    sudo apt install -y openjdk-21-jdk
</code></pre>
<ol>
 <li>
  Check Jenkins service status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  Update Jenkins to use Java 21
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop jenkins
    sudo update-alternatives --config java
</code></pre>
<pre><code>Select Java 21 from the list (e.g., `/usr/lib/jvm/java-21-openjdk-amd64/bin/java`)
</code></pre>
<ol>
 <li>
  Verify Java version
 </li>
</ol>
<pre><code class="language-bash">    java -version
</code></pre>
<pre><code>Should show: `openjdk version &quot;21.0.x&quot;`
</code></pre>
<ol>
 <li>
  Update JAVA_HOME for Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/default/jenkins
</code></pre>
<pre><code>Add or update:
</code></pre>
<pre><code class="language-bash">    JAVA_HOME=&quot;/usr/lib/jvm/java-21-openjdk-amd64&quot;
    JENKINS_JAVA_CMD=&quot;$JAVA_HOME/bin/java&quot;
</code></pre>
<ol>
 <li>
  Restart Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  <p>
   Verify in Jenkins UI
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System Information ‚Üí Look for
   <code>
    java.version
   </code>
   (should be 21.x)
  </p>
 </li>
</ol>
<h4>
 Fresh Installation of Java 21
</h4>
<p>
 For new installations:
</p>
<ol>
 <li>
  Update system packages
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
</code></pre>
<ol>
 <li>
  Install OpenJDK 21
 </li>
</ol>
<pre><code class="language-bash">    sudo apt install -y openjdk-21-jdk
</code></pre>
<ol>
 <li>
  Verify Java installation
 </li>
</ol>
<pre><code class="language-bash">    java -version
</code></pre>
<pre><code>Expected output:
</code></pre>
<pre><code>    openjdk version &quot;21.0.x&quot; 2024-xx-xx
    OpenJDK Runtime Environment (build 21.0.x+x)
    OpenJDK 64-Bit Server VM (build 21.0.x+x, mixed mode, sharing)
</code></pre>
<ol>
 <li>
  Set JAVA_HOME (optional but recommended)
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/environment
</code></pre>
<pre><code>Add:
</code></pre>
<pre><code class="language-bash">    JAVA_HOME=&quot;/usr/lib/jvm/java-21-openjdk-amd64&quot;
</code></pre>
<pre><code>Apply changes:
</code></pre>
<pre><code class="language-bash">    source /etc/environment
    echo $JAVA_HOME
</code></pre>
<h3>
 Part 2: Install Jenkins LTS
</h3>
<p>
 Jenkins Long-Term Support (LTS) releases are recommended for production environments. Current LTS:
 <strong>
  2.528.3
 </strong>
</p>
<ol>
 <li>
  Add Jenkins repository key (both legacy and modern format for compatibility)
 </li>
</ol>
<pre><code class="language-bash">    # Modern keyring format (recommended)
    curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo gpg --dearmor -o /usr/share/keyrings/jenkins-archive-keyring.gpg

    # Also add legacy key for repository compatibility
    gpg --keyserver keyserver.ubuntu.com --recv-keys 7198F4B714ABFC68
    gpg --export 7198F4B714ABFC68 &gt; /tmp/jenkins-key.gpg
    sudo gpg --dearmor &lt; /tmp/jenkins-key.gpg &gt; /usr/share/keyrings/jenkins-old-keyring.gpg
</code></pre>
<ol>
 <li>
  Add Jenkins repository
 </li>
</ol>
<pre><code class="language-bash">    echo &quot;deb [signed-by=/usr/share/keyrings/jenkins-old-keyring.gpg] https://pkg.jenkins.io/debian-stable binary/&quot; | sudo tee /etc/apt/sources.list.d/jenkins.list &gt; /dev/null
</code></pre>
<ol>
 <li>
  Update package list
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
</code></pre>
<ol>
 <li>
  Install Jenkins (latest LTS)
 </li>
</ol>
<pre><code class="language-bash">    # Install latest LTS version
    sudo apt install -y jenkins

    # Or install specific LTS version
    # sudo apt install -y jenkins=2.528.3
</code></pre>
<ol>
 <li>
  Check installed version
 </li>
</ol>
<pre><code class="language-bash">    jenkins --version
</code></pre>
<pre><code>Expected: `2.528.3` or newer LTS
</code></pre>
<ol>
 <li>
  Enable Jenkins service
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl enable jenkins
</code></pre>
<ol>
 <li>
  Start Jenkins service
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Verify Jenkins is running
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status jenkins
</code></pre>
<pre><code>Expected: Active (running)
</code></pre>
<ol>
 <li>
  Check Jenkins is listening on port 8080
 </li>
</ol>
<pre><code class="language-bash">    sudo ss -tulnp | grep 8080
</code></pre>
<pre><code>Expected: Jenkins listening on 127.0.0.1:8080
</code></pre>
<h3>
 Part 2.1: Upgrade Jenkins to Latest LTS
</h3>
<p>
 To upgrade an existing Jenkins installation:
</p>
<ol>
 <li>
  Check current version
 </li>
</ol>
<pre><code class="language-bash">    jenkins --version
    # Or via API:
    curl -s -I https://jenkins.arpansahu.space/api/json | grep X-Jenkins
</code></pre>
<ol>
 <li>
  Check available versions
 </li>
</ol>
<pre><code class="language-bash">    apt-cache policy jenkins | head -30
</code></pre>
<pre><code>Note: Look for versions 2.xxx.x (LTS releases), not 2.5xx+ (weekly releases)
</code></pre>
<ol>
 <li>
  Backup Jenkins before upgrade
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -czf /tmp/jenkins-backup-$(date +%Y%m%d-%H%M%S).tar.gz /var/lib/jenkins/
</code></pre>
<ol>
 <li>
  Stop Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop jenkins
</code></pre>
<ol>
 <li>
  Upgrade to latest LTS
 </li>
</ol>
<pre><code class="language-bash">    sudo apt update
    sudo apt install --only-upgrade jenkins -y

    # Or install specific LTS version:
    # sudo apt install jenkins=2.528.3 -y
</code></pre>
<ol>
 <li>
  Start Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Verify upgrade
 </li>
</ol>
<pre><code class="language-bash">    jenkins --version
    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  <p>
   Check Jenkins UI
  </p>
  <p>
   https://jenkins.arpansahu.space ‚Üí Manage Jenkins ‚Üí About Jenkins
  </p>
 </li>
</ol>
<h3>
 Part 3: Configure Nginx Reverse Proxy
</h3>
<ol>
 <li>
  Edit Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/nginx/sites-available/services
</code></pre>
<ol>
 <li>
  Add Jenkins server block
 </li>
</ol>
<pre><code class="language-nginx">    # Jenkins CI/CD - HTTP ‚Üí HTTPS
    server {
        listen 80;
        listen [::]:80;
        server_name jenkins.arpansahu.space;
        return 301 https://$host$request_uri;
    }

    # Jenkins CI/CD - HTTPS
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name jenkins.arpansahu.space;

        ssl_certificate     /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;

        # Jenkins-specific timeouts
        proxy_read_timeout 300;
        proxy_connect_timeout 300;
        proxy_send_timeout 300;

        location / {
            proxy_pass http://127.0.0.1:8080;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;

            # Required for Jenkins CLI and agent connections
            proxy_http_version 1.1;
            proxy_request_buffering off;
        }
    }
</code></pre>
<ol>
 <li>
  Test Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nginx -t
</code></pre>
<ol>
 <li>
  Reload Nginx
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl reload nginx
</code></pre>
<h3>
 Part 4: Initial Jenkins Setup
</h3>
<ol>
 <li>
  Get initial admin password
 </li>
</ol>
<pre><code class="language-bash">    sudo cat /var/lib/jenkins/secrets/initialAdminPassword
</code></pre>
<pre><code>Copy this password (example: a1b2c3d4e5f6...)
</code></pre>
<ol>
 <li>
  <p>
   Access Jenkins Web UI
  </p>
  <p>
   Go to: https://jenkins.arpansahu.space
  </p>
 </li>
 <li>
  <p>
   Enter initial admin password
  </p>
  <p>
   Paste the password from step 1.
  </p>
 </li>
 <li>
  <p>
   Install suggested plugins
  </p>
  <ul>
   <li>
    Click: Install suggested plugins
   </li>
   <li>
    Wait for plugin installation (5-10 minutes)
   </li>
  </ul>
 </li>
 <li>
  <p>
   Create admin user
  </p>
  <p>
   Configure:
   <br/>
   - Username:
   <code>
    admin
   </code>
   <br/>
   - Password: (your strong password)
   <br/>
   - Full name:
   <code>
    Admin User
   </code>
   <br/>
   - Email: your-email@example.com
  </p>
  <p>
   Click: Save and Continue
  </p>
 </li>
 <li>
  <p>
   Configure Jenkins URL
  </p>
  <p>
   Jenkins URL:
   <code>
    https://jenkins.arpansahu.space
   </code>
  </p>
  <p>
   Click: Save and Finish
  </p>
 </li>
 <li>
  <p>
   Start using Jenkins
  </p>
  <p>
   Click: Start using Jenkins
  </p>
 </li>
</ol>
<h3>
 Part 5: Configure Jenkins Credentials
</h3>
<p>
 Jenkins stores credentials securely for use in pipelines. We'll configure 4 essential credentials.
</p>
<h4>
 5.1: GitHub Authentication Credentials
</h4>
<ol>
 <li>
  <p>
   Navigate to credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure GitHub credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    :
    <code>
     arpansahu
    </code>
    (your GitHub username)
   </li>
   <li>
    <strong>
     Password
    </strong>
    :
    <code>
     ghp_xxxxxxxxxxxx
    </code>
    (GitHub Personal Access Token)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     github-auth
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     Github Auth
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   Note: Generate GitHub PAT at https://github.com/settings/tokens with scopes: repo, admin:repo_hook
  </p>
 </li>
</ol>
<h4>
 5.2: Harbor Registry Credentials
</h4>
<ol>
 <li>
  <p>
   Add Harbor credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure Harbor credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    :
    <code>
     admin
    </code>
    (or robot account:
    <code>
     robot$ci-bot
    </code>
    )
   </li>
   <li>
    <strong>
     Password
    </strong>
    : (Harbor password or robot token)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     harbor-credentials
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     harbor-credentials
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
 </li>
</ol>
<h4>
 5.3: Jenkins Admin API Credentials
</h4>
<ol>
 <li>
  <p>
   Add Jenkins admin credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure Jenkins API credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    :
    <code>
     admin
    </code>
    (Jenkins admin username)
   </li>
   <li>
    <strong>
     Password
    </strong>
    : (Jenkins admin password)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     jenkins-admin-credentials
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     Jenkins admin credentials for API authentication and pipeline usage
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   Use case: Pipeline triggers, REST API calls, remote job execution
  </p>
 </li>
</ol>
<h4>
 5.4: Sentry Authentication Token
</h4>
<ol>
 <li>
  <p>
   Add Sentry CLI token
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure Sentry credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Secret text
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Secret
    </strong>
    : (Sentry auth token from https://sentry.io/settings/account/api/auth-tokens/)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     sentry-auth-token
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     Sentry CLI Authentication Token
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   Use case: Sentry release tracking, source map uploads, error monitoring integration
  </p>
 </li>
</ol>
<h4>
 5.5: GitHub Authentication Credentials
</h4>
<ol>
 <li>
  <p>
   Add GitHub credentials
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Credentials ‚Üí System ‚Üí Global credentials ‚Üí Add Credentials
  </p>
 </li>
 <li>
  <p>
   Configure GitHub credentials
  </p>
  <ul>
   <li>
    <strong>
     Kind
    </strong>
    : Username with password
   </li>
   <li>
    <strong>
     Scope
    </strong>
    : Global
   </li>
   <li>
    <strong>
     Username
    </strong>
    : (GitHub username)
   </li>
   <li>
    <strong>
     Password
    </strong>
    : (GitHub Personal Access Token with repo permissions)
   </li>
   <li>
    <strong>
     ID
    </strong>
    :
    <code>
     github_auth
    </code>
   </li>
   <li>
    <strong>
     Description
    </strong>
    :
    <code>
     GitHub authentication for branch merging and repository operations
    </code>
   </li>
  </ul>
  <p>
   Click: Create
  </p>
  <p>
   <strong>
    How to generate GitHub PAT:
   </strong>
   <br/>
   1. Go to GitHub ‚Üí Settings ‚Üí Developer settings ‚Üí Personal access tokens ‚Üí Tokens (classic)
   <br/>
   2. Generate new token with permissions:
   <code>
    repo
   </code>
   (Full control of private repositories)
   <br/>
   3. Copy token immediately (shown only once)
  </p>
  <p>
   Use case: Automated branch merging, repository operations, deployment workflows
  </p>
 </li>
</ol>
<h3>
 Part 6: Configure Global Jenkins Variables
</h3>
<p>
 Global variables are available to all Jenkins pipelines.
</p>
<ol>
 <li>
  <p>
   Navigate to system configuration
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System
  </p>
 </li>
 <li>
  <p>
   Scroll to Global properties
  </p>
  <p>
   Check: Environment variables
  </p>
 </li>
 <li>
  <p>
   Add global variables
  </p>
  <p>
   Click: Add (for each variable)
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Name
     </th>
     <th>
      Value
     </th>
     <th>
      Description
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      MAIL_JET_API_KEY
     </td>
     <td>
      (your Mailjet API key)
     </td>
     <td>
      Email notification service
     </td>
    </tr>
    <tr>
     <td>
      MAIL_JET_API_SECRET
     </td>
     <td>
      (your Mailjet secret)
     </td>
     <td>
      Email notification service
     </td>
    </tr>
    <tr>
     <td>
      MAIL_JET_EMAIL_ADDRESS
     </td>
     <td>
      noreply@arpansahu.space
     </td>
     <td>
      Sender email address
     </td>
    </tr>
    <tr>
     <td>
      MY_EMAIL_ADDRESS
     </td>
     <td>
      your-email@example.com
     </td>
     <td>
      Notification recipient
     </td>
    </tr>
   </tbody>
  </table>
 </li>
 <li>
  <p>
   Save configuration
  </p>
  <p>
   Scroll down and click: Save
  </p>
 </li>
</ol>
<h3>
 Part 7: Configure Jenkins for Docker Builds
</h3>
<p>
 Jenkins needs Docker access to build containerized applications.
</p>
<ol>
 <li>
  Add Jenkins user to Docker group
 </li>
</ol>
<pre><code class="language-bash">    sudo usermod -aG docker jenkins
</code></pre>
<ol>
 <li>
  Restart Jenkins to apply group changes
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl restart jenkins
</code></pre>
<ol>
 <li>
  Verify Jenkins can access Docker
 </li>
</ol>
<pre><code class="language-bash">    sudo -u jenkins docker ps
</code></pre>
<pre><code>Expected: Docker container list (even if empty)
</code></pre>
<h3>
 Part 8: Configure Jenkins Sudo Access (Optional)
</h3>
<p>
 Required if pipelines need to copy files from protected directories.
</p>
<ol>
 <li>
  Edit sudoers file
 </li>
</ol>
<pre><code class="language-bash">    sudo visudo
</code></pre>
<ol>
 <li>
  <p>
   Add Jenkins sudo permissions
  </p>
  <p>
   Add at end of file:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Allow Jenkins to run specific commands without password
    jenkins ALL=(ALL) NOPASSWD: /bin/cp, /bin/mkdir, /bin/chown
</code></pre>
<pre><code>Or for full sudo access (less secure):
</code></pre>
<pre><code class="language-bash">    jenkins ALL=(ALL) NOPASSWD: ALL
</code></pre>
<ol>
 <li>
  <p>
   Save and exit
  </p>
  <p>
   In nano:
   <code>
    Ctrl + O
   </code>
   ,
   <code>
    Enter
   </code>
   ,
   <code>
    Ctrl + X
   </code>
   <br/>
   In vi:
   <code>
    Esc
   </code>
   ,
   <code>
    :wq
   </code>
   ,
   <code>
    Enter
   </code>
  </p>
 </li>
 <li>
  <p>
   Verify sudo access
  </p>
 </li>
</ol>
<pre><code class="language-bash">    sudo -u jenkins sudo -l
</code></pre>
<h3>
 Part 9: Create Project Nginx Configuration
</h3>
<p>
 Each project needs its own Nginx configuration for deployment.
</p>
<ol>
 <li>
  Create project Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/nginx/sites-available/my-django-app
</code></pre>
<ol>
 <li>
  Add project server block (Docker deployment)
 </li>
</ol>
<pre><code class="language-nginx">    # Django App - HTTP ‚Üí HTTPS
    server {
        listen 80;
        listen [::]:80;
        server_name myapp.arpansahu.space;
        return 301 https://$host$request_uri;
    }

    # Django App - HTTPS
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name myapp.arpansahu.space;

        ssl_certificate     /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;

        location / {
            proxy_pass http://127.0.0.1:8000;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;

            # WebSocket support
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection &quot;upgrade&quot;;
        }
    }
</code></pre>
<ol>
 <li>
  <p>
   For Kubernetes deployment (alternative)
  </p>
  <p>
   Replace
   <code>
    proxy_pass
   </code>
   line:
  </p>
 </li>
</ol>
<pre><code class="language-nginx">    proxy_pass http://&lt;CLUSTER_IP&gt;:30080;
</code></pre>
<ol>
 <li>
  Enable site configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo ln -s /etc/nginx/sites-available/my-django-app /etc/nginx/sites-enabled/
</code></pre>
<ol>
 <li>
  Test Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nginx -t
</code></pre>
<ol>
 <li>
  Reload Nginx
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl reload nginx
</code></pre>
<h3>
 Part 10: Create Jenkinsfile for Build Pipeline
</h3>
<p>
 Create
 <code>
  Jenkinsfile-build
 </code>
 in your project repository root.
</p>
<p>
 Example Jenkinsfile-build:
</p>
<pre><code class="language-groovy">pipeline {
    agent { label &#x27;local&#x27; }

    environment {
        HARBOR_URL = &#x27;harbor.arpansahu.space&#x27;
        HARBOR_PROJECT = &#x27;library&#x27;
        IMAGE_NAME = &#x27;my-django-app&#x27;
        IMAGE_TAG = &quot;${env.BUILD_NUMBER}&quot;
    }

    stages {
        stage(&#x27;Checkout&#x27;) {
            steps {
                checkout scm
            }
        }

        stage(&#x27;Build Docker Image&#x27;) {
            steps {
                script {
                    docker.build(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:${IMAGE_TAG}&quot;)
                }
            }
        }

        stage(&#x27;Push to Harbor&#x27;) {
            steps {
                script {
                    docker.withRegistry(&quot;https://${HARBOR_URL}&quot;, &#x27;harbor-credentials&#x27;) {
                        docker.image(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:${IMAGE_TAG}&quot;).push()
                        docker.image(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:${IMAGE_TAG}&quot;).push(&#x27;latest&#x27;)
                    }
                }
            }
        }

        stage(&#x27;Trigger Deploy&#x27;) {
            steps {
                build job: &#x27;my-django-app-deploy&#x27;, wait: false
            }
        }
    }

    post {
        success {
            emailext(
                subject: &quot;Build Success: ${env.JOB_NAME} #${env.BUILD_NUMBER}&quot;,
                body: &quot;Build completed successfully.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
        failure {
            emailext(
                subject: &quot;Build Failed: ${env.JOB_NAME} #${env.BUILD_NUMBER}&quot;,
                body: &quot;Build failed. Check Jenkins console output.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
    }
}
</code></pre>
<h3>
 Part 11: Create Jenkinsfile for Deploy Pipeline
</h3>
<p>
 Create
 <code>
  Jenkinsfile-deploy
 </code>
 in your project repository root.
</p>
<p>
 Example Jenkinsfile-deploy:
</p>
<pre><code class="language-groovy">pipeline {
    agent { label &#x27;local&#x27; }

    environment {
        HARBOR_URL = &#x27;harbor.arpansahu.space&#x27;
        HARBOR_PROJECT = &#x27;library&#x27;
        IMAGE_NAME = &#x27;my-django-app&#x27;
        CONTAINER_NAME = &#x27;my-django-app&#x27;
        CONTAINER_PORT = &#x27;8000&#x27;
    }

    stages {
        stage(&#x27;Stop Old Container&#x27;) {
            steps {
                script {
                    sh &quot;&quot;&quot;
                        docker stop ${CONTAINER_NAME} || true
                        docker rm ${CONTAINER_NAME} || true
                    &quot;&quot;&quot;
                }
            }
        }

        stage(&#x27;Pull Latest Image&#x27;) {
            steps {
                script {
                    docker.withRegistry(&quot;https://${HARBOR_URL}&quot;, &#x27;harbor-credentials&#x27;) {
                        docker.image(&quot;${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:latest&quot;).pull()
                    }
                }
            }
        }

        stage(&#x27;Deploy Container&#x27;) {
            steps {
                script {
                    sh &quot;&quot;&quot;
                        docker run -d \
                          --name ${CONTAINER_NAME} \
                          --restart unless-stopped \
                          -p ${CONTAINER_PORT}:8000 \
                          --env-file /var/lib/jenkins/.env/${IMAGE_NAME} \
                          ${HARBOR_URL}/${HARBOR_PROJECT}/${IMAGE_NAME}:latest
                    &quot;&quot;&quot;
                }
            }
        }

        stage(&#x27;Health Check&#x27;) {
            steps {
                script {
                    sleep(time: 10, unit: &#x27;SECONDS&#x27;)
                    sh &quot;curl -f http://localhost:${CONTAINER_PORT}/health || exit 1&quot;
                }
            }
        }
    }

    post {
        success {
            emailext(
                subject: &quot;Deploy Success: ${env.JOB_NAME}&quot;,
                body: &quot;Deployment completed successfully.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
        failure {
            emailext(
                subject: &quot;Deploy Failed: ${env.JOB_NAME}&quot;,
                body: &quot;Deployment failed. Check Jenkins console output.&quot;,
                to: &quot;${env.MY_EMAIL_ADDRESS}&quot;
            )
        }
    }
}
</code></pre>
<h3>
 Part 12: Create Jenkins Pipeline Projects
</h3>
<h4>
 12.1: Create Build Pipeline
</h4>
<ol>
 <li>
  <p>
   Create new pipeline
  </p>
  <p>
   Dashboard ‚Üí New Item
  </p>
 </li>
 <li>
  <p>
   Configure pipeline
  </p>
  <ul>
   <li>
    <strong>
     Name
    </strong>
    :
    <code>
     my-django-app-build
    </code>
   </li>
   <li>
    <strong>
     Type
    </strong>
    : Pipeline
   </li>
   <li>
    Click: OK
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure pipeline settings
  </p>
  <ul>
   <li>
    <strong>
     Description
    </strong>
    : Build and push Docker image to Harbor
   </li>
   <li>
    <strong>
     GitHub project
    </strong>
    : (check and add your repo URL)
   </li>
   <li>
    <strong>
     Build Triggers
    </strong>
    : GitHub hook trigger for GITScm polling
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure Pipeline definition
  </p>
  <ul>
   <li>
    <strong>
     Definition
    </strong>
    : Pipeline script from SCM
   </li>
   <li>
    <strong>
     SCM
    </strong>
    : Git
   </li>
   <li>
    <strong>
     Repository URL
    </strong>
    :
    <code>
     https://github.com/arpansahu/my-django-app.git
    </code>
   </li>
   <li>
    <strong>
     Credentials
    </strong>
    :
    <code>
     github-auth
    </code>
   </li>
   <li>
    <strong>
     Branch
    </strong>
    :
    <code>
     */build
    </code>
   </li>
   <li>
    <strong>
     Script Path
    </strong>
    :
    <code>
     Jenkinsfile-build
    </code>
   </li>
  </ul>
 </li>
 <li>
  <p>
   Save pipeline
  </p>
  <p>
   Click: Save
  </p>
 </li>
</ol>
<h4>
 12.2: Create Deploy Pipeline
</h4>
<ol>
 <li>
  <p>
   Create new pipeline
  </p>
  <p>
   Dashboard ‚Üí New Item
  </p>
 </li>
 <li>
  <p>
   Configure pipeline
  </p>
  <ul>
   <li>
    <strong>
     Name
    </strong>
    :
    <code>
     my-django-app-deploy
    </code>
   </li>
   <li>
    <strong>
     Type
    </strong>
    : Pipeline
   </li>
   <li>
    Click: OK
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure pipeline settings
  </p>
  <ul>
   <li>
    <strong>
     Description
    </strong>
    : Deploy Docker container from Harbor
   </li>
   <li>
    <strong>
     Build Triggers
    </strong>
    : None (triggered by build pipeline)
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure Pipeline definition
  </p>
  <ul>
   <li>
    <strong>
     Definition
    </strong>
    : Pipeline script from SCM
   </li>
   <li>
    <strong>
     SCM
    </strong>
    : Git
   </li>
   <li>
    <strong>
     Repository URL
    </strong>
    :
    <code>
     https://github.com/arpansahu/my-django-app.git
    </code>
   </li>
   <li>
    <strong>
     Credentials
    </strong>
    :
    <code>
     github-auth
    </code>
   </li>
   <li>
    <strong>
     Branch
    </strong>
    :
    <code>
     */main
    </code>
   </li>
   <li>
    <strong>
     Script Path
    </strong>
    :
    <code>
     Jenkinsfile-deploy
    </code>
   </li>
  </ul>
 </li>
 <li>
  <p>
   Save pipeline
  </p>
  <p>
   Click: Save
  </p>
 </li>
</ol>
<h3>
 Part 13: Configure Environment Files
</h3>
<p>
 Store sensitive environment variables outside the repository.
</p>
<ol>
 <li>
  Create environment file directory
 </li>
</ol>
<pre><code class="language-bash">    sudo mkdir -p /var/lib/jenkins/.env
    sudo chown jenkins:jenkins /var/lib/jenkins/.env
</code></pre>
<ol>
 <li>
  Create project environment file
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /var/lib/jenkins/.env/my-django-app
</code></pre>
<ol>
 <li>
  Add environment variables
 </li>
</ol>
<pre><code class="language-bash">    # Django settings
    SECRET_KEY=your-secret-key-here
    DEBUG=False
    ALLOWED_HOSTS=myapp.arpansahu.space

    # Database
    DATABASE_URL=postgresql://user:pass@db:5432/myapp

    # Redis
    REDIS_URL=redis://redis:6379/0

    # Email
    EMAIL_BACKEND=django.core.mail.backends.smtp.EmailBackend
    EMAIL_HOST=smtp.mailjet.com
    EMAIL_PORT=587
    EMAIL_USE_TLS=True
    EMAIL_HOST_USER=your-mailjet-api-key
    EMAIL_HOST_PASSWORD=your-mailjet-secret

    # Sentry
    SENTRY_DSN=https://xxx@sentry.io/xxx
</code></pre>
<ol>
 <li>
  Set proper permissions
 </li>
</ol>
<pre><code class="language-bash">    sudo chown jenkins:jenkins /var/lib/jenkins/.env/my-django-app
    sudo chmod 600 /var/lib/jenkins/.env/my-django-app
</code></pre>
<h3>
 Part 14: Configure Email Notifications
</h3>
<ol>
 <li>
  <p>
   Install Email Extension Plugin
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Plugins ‚Üí Available plugins
  </p>
  <p>
   Search:
   <code>
    Email Extension Plugin
   </code>
  </p>
  <p>
   Click: Install
  </p>
 </li>
 <li>
  <p>
   Configure SMTP settings
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System ‚Üí Extended E-mail Notification
  </p>
  <p>
   Configure:
   <br/>
   -
   <strong>
    SMTP server
   </strong>
   :
   <code>
    in-v3.mailjet.com
   </code>
   <br/>
   -
   <strong>
    SMTP port
   </strong>
   :
   <code>
    587
   </code>
   <br/>
   -
   <strong>
    Use SMTP Authentication
   </strong>
   : ‚úì Checked
   <br/>
   -
   <strong>
    User Name
   </strong>
   :
   <code>
    ${MAIL_JET_API_KEY}
   </code>
   <br/>
   -
   <strong>
    Password
   </strong>
   :
   <code>
    ${MAIL_JET_API_SECRET}
   </code>
   <br/>
   -
   <strong>
    Use TLS
   </strong>
   : ‚úì Checked
   <br/>
   -
   <strong>
    Default user e-mail suffix
   </strong>
   :
   <code>
    @arpansahu.space
   </code>
  </p>
 </li>
 <li>
  <p>
   Test email configuration
  </p>
  <p>
   Click: Test configuration by sending test e-mail
  </p>
  <p>
   Enter:
   <code>
    ${MY_EMAIL_ADDRESS}
   </code>
  </p>
  <p>
   Expected: Email received
  </p>
 </li>
 <li>
  <p>
   Save configuration
  </p>
  <p>
   Click: Save
  </p>
 </li>
</ol>
<h3>
 Managing Jenkins Service
</h3>
<ol>
 <li>
  Check Jenkins status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status jenkins
</code></pre>
<ol>
 <li>
  Stop Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop jenkins
</code></pre>
<ol>
 <li>
  Start Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Restart Jenkins
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl restart jenkins
</code></pre>
<ol>
 <li>
  View Jenkins logs
 </li>
</ol>
<pre><code class="language-bash">    sudo journalctl -u jenkins -f
</code></pre>
<ol>
 <li>
  View Jenkins application logs
 </li>
</ol>
<pre><code class="language-bash">    sudo tail -f /var/log/jenkins/jenkins.log
</code></pre>
<h3>
 Backup and Restore
</h3>
<ol>
 <li>
  Backup Jenkins home directory
 </li>
</ol>
<pre><code class="language-bash">    # Stop Jenkins
    sudo systemctl stop jenkins

    # Backup Jenkins home
    sudo tar -czf jenkins-backup-$(date +%Y%m%d).tar.gz /var/lib/jenkins

    # Start Jenkins
    sudo systemctl start jenkins
</code></pre>
<ol>
 <li>
  Backup only critical data
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -czf jenkins-config-backup-$(date +%Y%m%d).tar.gz \
      /var/lib/jenkins/config.xml \
      /var/lib/jenkins/jobs/ \
      /var/lib/jenkins/users/ \
      /var/lib/jenkins/credentials.xml \
      /var/lib/jenkins/secrets/
</code></pre>
<ol>
 <li>
  Restore Jenkins backup
 </li>
</ol>
<pre><code class="language-bash">    # Stop Jenkins
    sudo systemctl stop jenkins

    # Restore backup
    sudo tar -xzf jenkins-backup-YYYYMMDD.tar.gz -C /

    # Set ownership
    sudo chown -R jenkins:jenkins /var/lib/jenkins

    # Start Jenkins
    sudo systemctl start jenkins
</code></pre>
<h3>
 Common Issues and Fixes
</h3>
<ol>
 <li>
  <p>
   Jenkins not starting
  </p>
  <p>
   Cause: Java not found or port conflict
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check Java installation
    java -version

    # Check if port 8080 is in use
    sudo ss -tulnp | grep 8080

    # Check Jenkins logs
    sudo journalctl -u jenkins -n 50
</code></pre>
<ol>
 <li>
  <p>
   Cannot push to Harbor from Jenkins
  </p>
  <p>
   Cause: Docker credentials or network issue
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Test Docker login as Jenkins user
    sudo -u jenkins docker login harbor.arpansahu.space

    # Check Jenkins can reach Harbor
    sudo -u jenkins curl -I https://harbor.arpansahu.space
</code></pre>
<ol>
 <li>
  <p>
   Pipeline fails with permission denied
  </p>
  <p>
   Cause: Jenkins doesn't have Docker access
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Add Jenkins to Docker group
    sudo usermod -aG docker jenkins

    # Restart Jenkins
    sudo systemctl restart jenkins

    # Verify
    sudo -u jenkins docker ps
</code></pre>
<ol>
 <li>
  <p>
   Email notifications not working
  </p>
  <p>
   Cause: SMTP configuration incorrect
  </p>
  <p>
   Fix:
  </p>
  <ul>
   <li>
    Verify Mailjet API credentials in global variables
   </li>
   <li>
    Check SMTP settings in Email Extension configuration
   </li>
   <li>
    Send test email from Jenkins
   </li>
   <li>
    Check Mailjet dashboard for send logs
   </li>
  </ul>
 </li>
 <li>
  <p>
   GitHub webhook not triggering builds
  </p>
  <p>
   Cause: Webhook not configured or firewall blocking
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Verify Jenkins is accessible from internet
    curl -I https://jenkins.arpansahu.space

    # Configure GitHub webhook
    # Repository ‚Üí Settings ‚Üí Webhooks ‚Üí Add webhook
    # Payload URL: https://jenkins.arpansahu.space/github-webhook/
    # Content type: application/json
    # Events: Just the push event
</code></pre>
<h3>
 Security Best Practices
</h3>
<ol>
 <li>
  <p>
   Use HTTPS only
  </p>
  <ul>
   <li>
    Never access Jenkins over HTTP
   </li>
   <li>
    Always use Nginx reverse proxy with TLS
   </li>
  </ul>
 </li>
 <li>
  <p>
   Strong authentication
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Enable security realm
    Dashboard ‚Üí Manage Jenkins ‚Üí Security ‚Üí Security Realm
    Select: Jenkins&#x27; own user database
</code></pre>
<ol>
 <li>
  <p>
   Enable CSRF protection
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Security ‚Üí CSRF Protection
   <br/>
   Check: Enable CSRF Protection
  </p>
 </li>
 <li>
  <p>
   Limit build agent connections
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí Security ‚Üí Agents
   <br/>
   Set: Fixed port (50000) or disable
  </p>
 </li>
 <li>
  <p>
   Use credentials store
  </p>
  <ul>
   <li>
    Never hardcode credentials in Jenkinsfile
   </li>
   <li>
    Always use Jenkins credentials store
   </li>
   <li>
    Rotate credentials regularly
   </li>
  </ul>
 </li>
 <li>
  <p>
   Regular updates
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check for Jenkins updates
    Dashboard ‚Üí Manage Jenkins ‚Üí System Information

    # Update Jenkins
    sudo apt update
    sudo apt upgrade jenkins
</code></pre>
<ol>
 <li>
  Backup regularly
 </li>
</ol>
<pre><code class="language-bash">    # Automate with cron
    sudo crontab -e
</code></pre>
<pre><code>Add:
</code></pre>
<pre><code class="language-bash">    0 2 * * * /usr/local/bin/backup-jenkins.sh
</code></pre>
<h3>
 Performance Optimization
</h3>
<ol>
 <li>
  Increase Java heap size
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/default/jenkins
</code></pre>
<pre><code>Add/modify:
</code></pre>
<pre><code class="language-bash">    JAVA_ARGS=&quot;-Xmx2048m -Xms1024m&quot;
</code></pre>
<pre><code>Restart Jenkins:
</code></pre>
<pre><code class="language-bash">    sudo systemctl restart jenkins
</code></pre>
<ol>
 <li>
  <p>
   Clean old builds
  </p>
  <p>
   Configure in project:
   <br/>
   - Discard old builds
   <br/>
   - Keep max 10 builds
   <br/>
   - Keep builds for 7 days
  </p>
 </li>
 <li>
  <p>
   Use build agents
  </p>
  <p>
   Distribute builds across multiple machines instead of building everything on controller.
  </p>
 </li>
</ol>
<h3>
 Monitoring Jenkins
</h3>
<ol>
 <li>
  <p>
   Check Jenkins system info
  </p>
  <p>
   Dashboard ‚Üí Manage Jenkins ‚Üí System Information
  </p>
 </li>
 <li>
  <p>
   Monitor disk usage
  </p>
 </li>
</ol>
<pre><code class="language-bash">    du -sh /var/lib/jenkins/*
</code></pre>
<ol>
 <li>
  <p>
   Monitor build queue
  </p>
  <p>
   Dashboard ‚Üí Build Queue (left sidebar)
  </p>
 </li>
 <li>
  <p>
   View build history
  </p>
  <p>
   Dashboard ‚Üí Build History (left sidebar)
  </p>
 </li>
</ol>
<h3>
 Final Verification Checklist
</h3>
<p>
 Run these commands to verify Jenkins is working:
</p>
<pre><code class="language-bash"># Check Jenkins service
sudo systemctl status jenkins

# Check Java version
java -version

# Check port binding
sudo ss -tulnp | grep 8080

# Check Nginx config
sudo nginx -t

# Test HTTPS access
curl -I https://jenkins.arpansahu.space

# Verify Docker access
sudo -u jenkins docker ps
</code></pre>
<p>
 Then test in browser:
 <br/>
 - Access: https://jenkins.arpansahu.space
 <br/>
 - Login with admin credentials
 <br/>
 - Verify all 4 credentials exist
 <br/>
 - Create test pipeline
 <br/>
 - Run manual build
 <br/>
 - Check email notification received
</p>
<h3>
 What This Setup Provides
</h3>
<p>
 After following this guide, you will have:
</p>
<ol>
 <li>
  Jenkins LTS with Java 21
 </li>
 <li>
  HTTPS access via Nginx reverse proxy
 </li>
 <li>
  4 configured credentials (GitHub, Harbor, Jenkins API, Sentry)
 </li>
 <li>
  Global environment variables for emails
 </li>
 <li>
  Docker integration for builds
 </li>
 <li>
  Email notifications via Mailjet
 </li>
 <li>
  Build and deploy pipeline examples
 </li>
 <li>
  Production-ready configuration
 </li>
 <li>
  Automatic startup with systemd
 </li>
 <li>
  Comprehensive monitoring and logging
 </li>
</ol>
<h3>
 Example Configuration Summary
</h3>
<table>
 <thead>
  <tr>
   <th>
    Component
   </th>
   <th>
    Value
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    Jenkins URL
   </td>
   <td>
    https://jenkins.arpansahu.space
   </td>
  </tr>
  <tr>
   <td>
    Jenkins Port
   </td>
   <td>
    8080 (localhost only)
   </td>
  </tr>
  <tr>
   <td>
    Jenkins Home
   </td>
   <td>
    /var/lib/jenkins
   </td>
  </tr>
  <tr>
   <td>
    Java Version
   </td>
   <td>
    OpenJDK 21
   </td>
  </tr>
  <tr>
   <td>
    Admin User
   </td>
   <td>
    admin
   </td>
  </tr>
  <tr>
   <td>
    Nginx Config
   </td>
   <td>
    /etc/nginx/sites-available/services
   </td>
  </tr>
 </tbody>
</table>
<h3>
 Architecture Summary
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (TLS Termination)
        ‚îÇ [Wildcard Certificate: *.arpansahu.space]
        ‚îÇ
        ‚îî‚îÄ jenkins.arpansahu.space (Port 443 ‚Üí 8080)
             ‚îÇ
             ‚îî‚îÄ Jenkins Controller
                  ‚îÇ
                  ‚îú‚îÄ Credentials Store
                  ‚îÇ   ‚îú‚îÄ github-auth
                  ‚îÇ   ‚îú‚îÄ harbor-credentials
                  ‚îÇ   ‚îú‚îÄ jenkins-admin-credentials
                  ‚îÇ   ‚îî‚îÄ sentry-auth-token
                  ‚îÇ
                  ‚îú‚îÄ Build Pipelines
                  ‚îÇ   ‚îú‚îÄ Jenkinsfile-build (Docker build + push)
                  ‚îÇ   ‚îî‚îÄ Jenkinsfile-deploy (Docker deploy)
                  ‚îÇ
                  ‚îî‚îÄ Integration
                      ‚îú‚îÄ GitHub (webhooks)
                      ‚îú‚îÄ Harbor (registry)
                      ‚îú‚îÄ Docker (builds)
                      ‚îú‚îÄ Mailjet (notifications)
                      ‚îî‚îÄ Sentry (error tracking)
</code></pre>
<h3>
 Key Rules to Remember
</h3>
<ol>
 <li>
  Jenkins port 8080 never exposed externally
 </li>
 <li>
  Always use credentials store, never hardcode
 </li>
 <li>
  Use Jenkinsfile for pipeline as code
 </li>
 <li>
  Separate build and deploy pipelines
 </li>
 <li>
  Store .env files outside repository
 </li>
 <li>
  Enable email notifications for failures
 </li>
 <li>
  Regular backups of /var/lib/jenkins
 </li>
 <li>
  Keep Jenkins and plugins updated
 </li>
 <li>
  Use Harbor for private registry
 </li>
 <li>
  Monitor build queue and disk usage
 </li>
</ol>
<h3>
 Next Steps
</h3>
<p>
 After setting up Jenkins:
</p>
<ol>
 <li>
  Configure GitHub webhooks for automatic builds
 </li>
 <li>
  Create pipelines for each project
 </li>
 <li>
  Set up build agents for distributed builds
 </li>
 <li>
  Configure Slack/Teams notifications
 </li>
 <li>
  Implement automated testing in pipelines
 </li>
 <li>
  Set up deployment approvals
 </li>
 <li>
  Configure Jenkins metrics monitoring
 </li>
</ol>
<p>
 My Jenkins instance: https://jenkins.arpansahu.space
</p>
<p>
 For Harbor integration, see harbor.md documentation.
</p>
<h2>
 Harbor (Self-Hosted Private Docker Registry)
</h2>
<p>
 Harbor is an open-source container image registry that secures images with role-based access control, scans images for vulnerabilities, and signs images as trusted. It extends Docker Distribution by adding enterprise features like security, identity management, and image replication. This guide provides a complete, production-ready setup with Nginx reverse proxy.
</p>
<h3>
 Prerequisites
</h3>
<p>
 Before installing Harbor, ensure you have:
</p>
<ol>
 <li>
  Ubuntu Server 22.04 LTS
 </li>
 <li>
  Docker Engine installed (see docker_installation.md)
 </li>
 <li>
  Nginx with SSL certificates configured
 </li>
 <li>
  Domain name (example: harbor.arpansahu.space)
 </li>
 <li>
  Wildcard SSL certificate already issued (via acme.sh)
 </li>
 <li>
  Minimum 4GB RAM, 40GB disk space
 </li>
 <li>
  Root or sudo access
 </li>
</ol>
<h3>
 Architecture Overview
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (Port 443) - TLS Termination
        ‚îÇ
        ‚îî‚îÄ harbor.arpansahu.space
             ‚îÇ
             ‚îî‚îÄ Harbor Internal Nginx (localhost:8080)
                  ‚îÇ
                  ‚îú‚îÄ Harbor Core
                  ‚îú‚îÄ Harbor Registry
                  ‚îú‚îÄ Harbor Portal (Web UI)
                  ‚îú‚îÄ Trivy (Vulnerability Scanner)
                  ‚îú‚îÄ Notary (Image Signing)
                  ‚îî‚îÄ ChartMuseum (Helm Charts)
</code></pre>
<p>
 Key Principles:
 <br/>
 - Harbor runs on localhost only
 <br/>
 - System Nginx handles all external TLS
 <br/>
 - Harbor has its own internal Nginx
 <br/>
 - All data persisted in Docker volumes
 <br/>
 - Automatic restart via systemd
</p>
<h3>
 Why Harbor
</h3>
<p>
 <strong>
  Advantages:
 </strong>
 <br/>
 - Role-based access control (RBAC)
 <br/>
 - Vulnerability scanning with Trivy
 <br/>
 - Image signing and trust (Notary)
 <br/>
 - Helm chart repository
 <br/>
 - Image replication
 <br/>
 - Garbage collection
 <br/>
 - Web UI for management
 <br/>
 - Docker Hub proxy cache
</p>
<p>
 <strong>
  Use Cases:
 </strong>
 <br/>
 - Private Docker registry for organization
 <br/>
 - Secure image storage
 <br/>
 - Vulnerability assessment
 <br/>
 - Compliance and auditing
 <br/>
 - Multi-project isolation
 <br/>
 - Image lifecycle management
</p>
<h3>
 Part 1: Download and Extract Harbor
</h3>
<ol>
 <li>
  Download latest Harbor release
 </li>
</ol>
<pre><code class="language-bash">    cd /opt
    sudo wget https://github.com/goharbor/harbor/releases/download/v2.11.0/harbor-offline-installer-v2.11.0.tgz
</code></pre>
<pre><code>Check for latest version at: https://github.com/goharbor/harbor/releases
</code></pre>
<ol>
 <li>
  Extract Harbor installer
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -xzvf harbor-offline-installer-v2.11.0.tgz
    cd harbor
</code></pre>
<ol>
 <li>
  Verify extracted files
 </li>
</ol>
<pre><code class="language-bash">    ls -la
</code></pre>
<pre><code>Expected files:
- harbor.yml.tmpl
- install.sh
- prepare
- common.sh
- harbor.*.tar.gz (images)
</code></pre>
<h3>
 Part 2: Configure Harbor
</h3>
<ol>
 <li>
  Copy template configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo cp harbor.yml.tmpl harbor.yml
</code></pre>
<ol>
 <li>
  Edit Harbor configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano harbor.yml
</code></pre>
<ol>
 <li>
  <p>
   Configure essential settings
  </p>
  <p>
   Find and modify these lines:
  </p>
 </li>
</ol>
<pre><code class="language-yaml">    # Hostname for Harbor
    hostname: harbor.arpansahu.space

    # HTTP settings (used for internal communication)
    http:
      port: 8080

    # HTTPS settings (disabled - Nginx handles this)
    # Comment out or remove the https section completely
    # https:
    #   port: 443
    #   certificate: /path/to/cert
    #   private_key: /path/to/key

    # Harbor admin password
    harbor_admin_password: YourStrongPasswordHere

    # Database settings (PostgreSQL)
    database:
      password: ChangeDatabasePassword
      max_idle_conns: 100
      max_open_conns: 900

    # Data volume location
    data_volume: /data

    # Trivy (vulnerability scanner)
    trivy:
      ignore_unfixed: false
      skip_update: false
      offline_scan: false
      insecure: false

    # Job service
    jobservice:
      max_job_workers: 10

    # Notification webhook job
    notification:
      webhook_job_max_retry: 3

    # Log settings
    log:
      level: info
      local:
        rotate_count: 50
        rotate_size: 200M
        location: /var/log/harbor
</code></pre>
<pre><code>Important changes:
- Set `hostname` to your domain
- Set `http.port` to 8080 (internal)
- Comment out entire `https` section
- Change `harbor_admin_password`
- Change `database.password`
- Keep `data_volume: /data` for persistence
</code></pre>
<ol>
 <li>
  <p>
   Save and exit
  </p>
  <p>
   In nano:
   <code>
    Ctrl + O
   </code>
   ,
   <code>
    Enter
   </code>
   ,
   <code>
    Ctrl + X
   </code>
  </p>
 </li>
</ol>
<h3>
 Part 3: Install Harbor
</h3>
<ol>
 <li>
  Run Harbor installer with all components
 </li>
</ol>
<pre><code class="language-bash">    sudo ./install.sh --with-notary --with-trivy --with-chartmuseum
</code></pre>
<pre><code>This will:
- Load Harbor Docker images
- Generate docker-compose.yml
- Create necessary directories
- Start all Harbor services

Installation takes 5-10 minutes depending on system.
</code></pre>
<ol>
 <li>
  Verify installation
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose ps
</code></pre>
<pre><code>Expected services (all should be &quot;Up&quot;):
- harbor-core
- harbor-db (PostgreSQL)
- harbor-jobservice
- harbor-log
- harbor-portal (Web UI)
- nginx (Harbor&#x27;s internal)
- redis
- registry
- registryctl
- trivy-adapter
- notary-server
- notary-signer
- chartmuseum
</code></pre>
<ol>
 <li>
  Check Harbor logs
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose logs -f
</code></pre>
<pre><code>Press `Ctrl + C` to exit logs.
</code></pre>
<h3>
 Part 4: Configure System Nginx
</h3>
<ol>
 <li>
  Edit Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/nginx/sites-available/services
</code></pre>
<ol>
 <li>
  Add Harbor server block
 </li>
</ol>
<pre><code class="language-nginx">    # Harbor Registry - HTTP ‚Üí HTTPS
    server {
        listen 80;
        listen [::]:80;
        server_name harbor.arpansahu.space;
        return 301 https://$host$request_uri;
    }

    # Harbor Registry - HTTPS
    server {
        listen 443 ssl http2;
        listen [::]:443 ssl http2;
        server_name harbor.arpansahu.space;

        ssl_certificate     /etc/nginx/ssl/arpansahu.space/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/arpansahu.space/privkey.pem;

        ssl_protocols TLSv1.2 TLSv1.3;

        location / {
            # Allow large image uploads (2GB recommended, 0 for unlimited)
            # Note: Set to at least 2G for typical Docker images
            client_max_body_size 2G;

            proxy_pass http://127.0.0.1:8080;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto https;

            # WebSocket support
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection &quot;upgrade&quot;;

            # Timeouts for large image pushes
            proxy_connect_timeout 300;
            proxy_send_timeout 300;
            proxy_read_timeout 300;
        }
    }
</code></pre>
<ol>
 <li>
  Test Nginx configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo nginx -t
</code></pre>
<ol>
 <li>
  Reload Nginx
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl reload nginx
</code></pre>
<h3>
 Part 5: Configure Auto-Start with Systemd
</h3>
<p>
 Harbor needs to start automatically after reboot. Docker Compose alone doesn't provide this.
</p>
<ol>
 <li>
  Create systemd service file
 </li>
</ol>
<pre><code class="language-bash">    sudo nano /etc/systemd/system/harbor.service
</code></pre>
<ol>
 <li>
  Add service configuration
 </li>
</ol>
<pre><code class="language-bash">    [Unit]
    Description=Harbor Container Registry
    After=docker.service
    Requires=docker.service

    [Service]
    Type=oneshot
    RemainAfterExit=yes
    WorkingDirectory=/opt/harbor
    ExecStart=/usr/bin/docker compose up -d
    ExecStop=/usr/bin/docker compose down
    Restart=on-failure
    RestartSec=10

    [Install]
    WantedBy=multi-user.target
</code></pre>
<ol>
 <li>
  Reload systemd daemon
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl daemon-reload
</code></pre>
<ol>
 <li>
  Enable Harbor service
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl enable harbor
</code></pre>
<ol>
 <li>
  Verify service status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status harbor
</code></pre>
<pre><code>Expected: Loaded and active
</code></pre>
<h3>
 Part 6: Configure Firewall and Port Forwarding
</h3>
<ol>
 <li>
  Configure UFW firewall
 </li>
</ol>
<pre><code class="language-bash">    # Allow HTTP/HTTPS (if not already allowed)
    sudo ufw allow 80/tcp
    sudo ufw allow 443/tcp

    # Block direct access to Harbor port
    sudo ufw deny 8080/tcp

    # Reload firewall
    sudo ufw reload
</code></pre>
<ol>
 <li>
  <p>
   Configure router port forwarding
  </p>
  <p>
   Access router admin: https://airtel.arpansahu.space (or http://192.168.1.1:81)
  </p>
  <p>
   Add port forwarding rules:
  </p>
  <table>
   <thead>
    <tr>
     <th>
      Service
     </th>
     <th>
      External Port
     </th>
     <th>
      Internal IP
     </th>
     <th>
      Internal Port
     </th>
     <th>
      Protocol
     </th>
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>
      Harbor HTTP
     </td>
     <td>
      80
     </td>
     <td>
      192.168.1.200
     </td>
     <td>
      80
     </td>
     <td>
      TCP
     </td>
    </tr>
    <tr>
     <td>
      Harbor HTTPS
     </td>
     <td>
      443
     </td>
     <td>
      192.168.1.200
     </td>
     <td>
      443
     </td>
     <td>
      TCP
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   Note: Do NOT forward port 8080 (Harbor internal port).
  </p>
 </li>
</ol>
<h3>
 Part 7: Test Harbor Installation
</h3>
<ol>
 <li>
  Check all containers are running
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose ps
</code></pre>
<pre><code>All should show &quot;Up&quot; status.
</code></pre>
<ol>
 <li>
  Test local access
 </li>
</ol>
<pre><code class="language-bash">    curl -I http://127.0.0.1:8080
</code></pre>
<pre><code>Expected: HTTP 200 or 301
</code></pre>
<ol>
 <li>
  Test external HTTPS access
 </li>
</ol>
<pre><code class="language-bash">    curl -I https://harbor.arpansahu.space
</code></pre>
<pre><code>Expected: HTTP 200
</code></pre>
<ol>
 <li>
  <p>
   Access Harbor Web UI
  </p>
  <p>
   Go to: https://harbor.arpansahu.space
  </p>
 </li>
 <li>
  <p>
   Login with admin credentials
  </p>
  <ul>
   <li>
    Username:
    <code>
     admin
    </code>
   </li>
   <li>
    Password: (from harbor.yml harbor_admin_password)
   </li>
  </ul>
 </li>
</ol>
<h3>
 Part 8: Initial Harbor Configuration
</h3>
<ol>
 <li>
  <p>
   Change admin password
  </p>
  <ul>
   <li>
    Click admin (top right) ‚Üí Change Password
   </li>
   <li>
    Set strong password
   </li>
   <li>
    Save
   </li>
  </ul>
 </li>
 <li>
  <p>
   Create project
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí New Project
   </li>
   <li>
    Project Name:
    <code>
     library
    </code>
    (default) or custom name
   </li>
   <li>
    Access Level: Private (recommended)
   </li>
   <li>
    Click: OK
   </li>
  </ul>
 </li>
 <li>
  <p>
   Create robot account for CI/CD
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Robot Accounts
   </li>
   <li>
    Click: New Robot Account
   </li>
   <li>
    Name:
    <code>
     ci-bot
    </code>
   </li>
   <li>
    Expiration: Never (or set expiry)
   </li>
   <li>
    Permissions: Push Artifact, Pull Artifact
   </li>
   <li>
    Click: Add
   </li>
   <li>
    Save token securely (shown only once)
   </li>
  </ul>
 </li>
</ol>
<h3>
 Part 9: Using Harbor as Docker Registry
</h3>
<h4>
 Login to Harbor
</h4>
<ol>
 <li>
  Login from Docker client
 </li>
</ol>
<pre><code class="language-bash">    docker login harbor.arpansahu.space
</code></pre>
<pre><code>Enter:
- Username: `admin` (or your username)
- Password: (your Harbor password)

Expected: Login Succeeded
</code></pre>
<ol>
 <li>
  Login with robot account (for CI/CD)
 </li>
</ol>
<pre><code class="language-bash">    docker login harbor.arpansahu.space -u robot$ci-bot -p YOUR_ROBOT_TOKEN
</code></pre>
<h4>
 Push Images to Harbor
</h4>
<ol>
 <li>
  Tag existing image
 </li>
</ol>
<pre><code class="language-bash">    docker tag nginx:latest harbor.arpansahu.space/library/nginx:latest
</code></pre>
<pre><code>Format: `harbor.domain.com/project/image:tag`
</code></pre>
<ol>
 <li>
  Push image to Harbor
 </li>
</ol>
<pre><code class="language-bash">    docker push harbor.arpansahu.space/library/nginx:latest
</code></pre>
<ol>
 <li>
  <p>
   Verify in Harbor UI
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Repositories
   </li>
   <li>
    You should see: nginx repository
   </li>
  </ul>
 </li>
</ol>
<h4>
 Pull Images from Harbor
</h4>
<ol>
 <li>
  Pull image from Harbor
 </li>
</ol>
<pre><code class="language-bash">    docker pull harbor.arpansahu.space/library/nginx:latest
</code></pre>
<ol>
 <li>
  Use in docker-compose.yml
 </li>
</ol>
<pre><code class="language-yaml">    services:
      web:
        image: harbor.arpansahu.space/library/nginx:latest
</code></pre>
<h3>
 Part 10: Configure Image Retention Policy
</h3>
<p>
 Retention policies automatically delete old images to save space.
</p>
<ol>
 <li>
  <p>
   Navigate to project
  </p>
  <ul>
   <li>
    Projects ‚Üí library ‚Üí Policy
   </li>
  </ul>
 </li>
 <li>
  <p>
   Add retention rule
  </p>
  <p>
   Click: Add Rule
  </p>
  <p>
   Configure:
   <br/>
   -
   <strong>
    Repositories
   </strong>
   : matching
   <code>
    **
   </code>
   (all repositories)
   <br/>
   -
   <strong>
    By artifact count
   </strong>
   : Retain the most recently pulled
   <code>
    3
   </code>
   artifacts
   <br/>
   -
   <strong>
    Tags
   </strong>
   : matching
   <code>
    **
   </code>
   (all tags)
   <br/>
   -
   <strong>
    Untagged artifacts
   </strong>
   : ‚úì Checked (delete untagged)
  </p>
  <p>
   This keeps last 3 pulled images and deletes others.
  </p>
  <p>
   <img alt="Add Retention Rule" class="d-block w-100" src="https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/harbor/retention_rule_add.png"/>
  </p>
 </li>
 <li>
  <p>
   Schedule retention policy
  </p>
  <p>
   Click: Add Retention Rule ‚Üí Schedule
  </p>
  <p>
   Configure schedule:
   <br/>
   -
   <strong>
    Type
   </strong>
   : Daily / Weekly / Monthly
   <br/>
   -
   <strong>
    Time
   </strong>
   : 02:00 AM (off-peak)
   <br/>
   -
   <strong>
    Cron
   </strong>
   :
   <code>
    0 2 * * *
   </code>
   (2 AM daily)
  </p>
  <p>
   Click: Save
  </p>
  <p>
   <img alt="Retention Rule Schedule" class="d-block w-100" src="https://raw.githubusercontent.com/arpansahu/common_readme/main/AWS%20Deployment/harbor/retention_rule_schedule.png"/>
  </p>
 </li>
 <li>
  <p>
   Test retention policy
  </p>
  <p>
   Click: Dry Run
  </p>
  <p>
   This shows what would be deleted without actually deleting.
  </p>
 </li>
</ol>
<h3>
 Part 11: Enable Vulnerability Scanning
</h3>
<p>
 Harbor uses Trivy to scan images for vulnerabilities.
</p>
<ol>
 <li>
  <p>
   Configure automatic scanning
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Configuration
   </li>
   <li>
    Enable: Automatically scan images on push
   </li>
   <li>
    Click: Save
   </li>
  </ul>
 </li>
 <li>
  <p>
   Manual scan existing image
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Repositories ‚Üí nginx
   </li>
   <li>
    Select tag: latest
   </li>
   <li>
    Click: Scan
   </li>
  </ul>
 </li>
 <li>
  <p>
   View scan results
  </p>
  <ul>
   <li>
    Click on tag
   </li>
   <li>
    View: Vulnerabilities tab
   </li>
   <li>
    See: Critical, High, Medium, Low vulnerabilities
   </li>
  </ul>
 </li>
 <li>
  <p>
   Set CVE allowlist (optional)
  </p>
  <ul>
   <li>
    Go to: Projects ‚Üí library ‚Üí Configuration
   </li>
   <li>
    Add CVE IDs to allow despite vulnerabilities
   </li>
   <li>
    Use for false positives or accepted risks
   </li>
  </ul>
 </li>
</ol>
<h3>
 Managing Harbor Service
</h3>
<ol>
 <li>
  Check Harbor status
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl status harbor
</code></pre>
<ol>
 <li>
  Stop Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop harbor
</code></pre>
<pre><code>or
</code></pre>
<pre><code class="language-bash">    cd /opt/harbor
    sudo docker compose down
</code></pre>
<ol>
 <li>
  Start Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start harbor
</code></pre>
<pre><code>or
</code></pre>
<pre><code class="language-bash">    cd /opt/harbor
    sudo docker compose up -d
</code></pre>
<ol>
 <li>
  Restart Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl restart harbor
</code></pre>
<ol>
 <li>
  View Harbor logs
 </li>
</ol>
<pre><code class="language-bash">    cd /opt/harbor
    sudo docker compose logs -f
</code></pre>
<ol>
 <li>
  View specific service logs
 </li>
</ol>
<pre><code class="language-bash">    sudo docker compose logs -f harbor-core
</code></pre>
<h3>
 Backup and Restore
</h3>
<ol>
 <li>
  Backup Harbor data
 </li>
</ol>
<pre><code class="language-bash">    # Stop Harbor
    sudo systemctl stop harbor

    # Backup data directory
    sudo tar -czf harbor-data-backup-$(date +%Y%m%d).tar.gz /data

    # Backup configuration
    sudo cp /opt/harbor/harbor.yml /backup/harbor-config-$(date +%Y%m%d).yml

    # Backup database
    sudo docker exec harbor-db pg_dumpall -U postgres &gt; harbor-db-backup-$(date +%Y%m%d).sql

    # Start Harbor
    sudo systemctl start harbor
</code></pre>
<ol>
 <li>
  Restore Harbor data
 </li>
</ol>
<pre><code class="language-bash">    # Stop Harbor
    sudo systemctl stop harbor

    # Restore data directory
    sudo tar -xzf harbor-data-backup-YYYYMMDD.tar.gz -C /

    # Restore configuration
    sudo cp /backup/harbor-config-YYYYMMDD.yml /opt/harbor/harbor.yml

    # Restore database
    sudo docker exec -i harbor-db psql -U postgres &lt; harbor-db-backup-YYYYMMDD.sql

    # Start Harbor
    sudo systemctl start harbor
</code></pre>
<h3>
 Common Issues and Fixes
</h3>
<ol>
 <li>
  <p>
   Harbor containers not starting
  </p>
  <p>
   Cause: Port conflict or insufficient resources
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check if port 8080 is in use
    sudo ss -tulnp | grep 8080

    # Check Docker logs
    cd /opt/harbor
    sudo docker compose logs

    # Check system resources
    free -h
    df -h
</code></pre>
<ol>
 <li>
  <p>
   Cannot login to Harbor
  </p>
  <p>
   Cause: Wrong credentials or database issue
  </p>
  <p>
   Fix:
  </p>
  <ul>
   <li>
    Verify admin password in harbor.yml
   </li>
   <li>
    Reset admin password:
   </li>
  </ul>
 </li>
</ol>
<pre><code class="language-bash">      cd /opt/harbor
      sudo docker compose exec harbor-core harbor-core password-reset
</code></pre>
<ol>
 <li>
  <p>
   Image push fails
  </p>
  <p>
   Cause: Storage full or permission issues
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check disk space
    df -h /data

    # Check Harbor logs
    sudo docker compose logs -f registry

    # Check data directory permissions
    sudo ls -la /data
</code></pre>
<ol>
 <li>
  <p>
   SSL certificate errors
  </p>
  <p>
   Cause: Nginx certificate misconfigured
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Verify certificate
    openssl x509 -in /etc/nginx/ssl/arpansahu.space/fullchain.pem -noout -dates

    # Check Nginx configuration
    sudo nginx -t

    # Reload Nginx
    sudo systemctl reload nginx
</code></pre>
<ol>
 <li>
  <p>
   Vulnerability scanning not working
  </p>
  <p>
   Cause: Trivy adapter not running or internet connectivity
  </p>
  <p>
   Fix:
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Check Trivy adapter
    sudo docker compose ps trivy-adapter

    # Check Trivy logs
    sudo docker compose logs trivy-adapter

    # Update Trivy database manually
    sudo docker compose exec trivy-adapter /home/scanner/trivy --download-db-only
</code></pre>
<h3>
 Security Best Practices
</h3>
<ol>
 <li>
  <p>
   Use strong passwords
  </p>
  <ul>
   <li>
    Admin password: minimum 16 characters
   </li>
   <li>
    Database password: minimum 16 characters
   </li>
   <li>
    Robot account tokens: treat as secrets
   </li>
  </ul>
 </li>
 <li>
  <p>
   Enable HTTPS only
  </p>
  <ul>
   <li>
    Never use HTTP for Harbor
   </li>
   <li>
    Always proxy through Nginx with TLS
   </li>
  </ul>
 </li>
 <li>
  <p>
   Implement RBAC
  </p>
  <ul>
   <li>
    Create projects with limited access
   </li>
   <li>
    Use robot accounts for automation
   </li>
   <li>
    Assign minimal required permissions
   </li>
  </ul>
 </li>
 <li>
  <p>
   Enable vulnerability scanning
  </p>
  <ul>
   <li>
    Automatically scan on push
   </li>
   <li>
    Set CVE severity thresholds
   </li>
   <li>
    Block deployment of vulnerable images
   </li>
  </ul>
 </li>
 <li>
  <p>
   Configure image retention
  </p>
  <ul>
   <li>
    Automatically delete old images
   </li>
   <li>
    Keep only necessary image versions
   </li>
   <li>
    Schedule during off-peak hours
   </li>
  </ul>
 </li>
 <li>
  <p>
   Regular backups
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Automate with cron
    sudo crontab -e
</code></pre>
<pre><code>Add:
</code></pre>
<pre><code class="language-bash">    0 2 * * * /usr/local/bin/backup-harbor.sh
</code></pre>
<ol>
 <li>
  Monitor logs
 </li>
</ol>
<pre><code class="language-bash">    # Regular log review
    sudo docker compose logs --since 24h | grep ERROR
</code></pre>
<h3>
 Performance Optimization
</h3>
<ol>
 <li>
  <p>
   Configure garbage collection
  </p>
  <ul>
   <li>
    Go to: Administration ‚Üí Garbage Collection
   </li>
   <li>
    Schedule: Weekly at 2 AM
   </li>
   <li>
    This removes unreferenced image layers
   </li>
  </ul>
 </li>
 <li>
  <p>
   Optimize database
  </p>
 </li>
</ol>
<pre><code class="language-bash">    # Run vacuum on PostgreSQL
    sudo docker compose exec harbor-db vacuumdb -U postgres -d registry
</code></pre>
<ol>
 <li>
  <p>
   Configure resource limits
  </p>
  <p>
   Edit docker-compose.yml (auto-generated):
  </p>
 </li>
</ol>
<pre><code class="language-yaml">    services:
      registry:
        deploy:
          resources:
            limits:
              memory: 2G
            reservations:
              memory: 512M
</code></pre>
<ol>
 <li>
  <p>
   Enable Redis cache
  </p>
  <p>
   Harbor uses Redis by default for caching.
   <br/>
   Increase Redis memory if needed.
  </p>
 </li>
</ol>
<h3>
 Monitoring Harbor
</h3>
<ol>
 <li>
  Check Harbor health
 </li>
</ol>
<pre><code class="language-bash">    curl -k https://harbor.arpansahu.space/api/v2.0/health
</code></pre>
<ol>
 <li>
  Monitor Docker resources
 </li>
</ol>
<pre><code class="language-bash">    sudo docker stats
</code></pre>
<ol>
 <li>
  Check disk usage
 </li>
</ol>
<pre><code class="language-bash">    du -sh /data/*
</code></pre>
<ol>
 <li>
  View system logs
 </li>
</ol>
<pre><code class="language-bash">    sudo journalctl -u harbor -f
</code></pre>
<h3>
 Updating Harbor
</h3>
<ol>
 <li>
  <p>
   Backup current installation
  </p>
  <p>
   Follow backup procedure above.
  </p>
 </li>
 <li>
  <p>
   Download new Harbor version
  </p>
 </li>
</ol>
<pre><code class="language-bash">    cd /opt
    sudo wget https://github.com/goharbor/harbor/releases/download/vX.Y.Z/harbor-offline-installer-vX.Y.Z.tgz
</code></pre>
<ol>
 <li>
  Stop current Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl stop harbor
</code></pre>
<ol>
 <li>
  Extract new version
 </li>
</ol>
<pre><code class="language-bash">    sudo tar -xzvf harbor-offline-installer-vX.Y.Z.tgz
    sudo mv harbor harbor-old
    sudo mv harbor-new harbor
</code></pre>
<ol>
 <li>
  Copy configuration
 </li>
</ol>
<pre><code class="language-bash">    sudo cp harbor-old/harbor.yml harbor/harbor.yml
</code></pre>
<ol>
 <li>
  Run migration
 </li>
</ol>
<pre><code class="language-bash">    cd /opt/harbor
    sudo ./install.sh --with-notary --with-trivy --with-chartmuseum
</code></pre>
<ol>
 <li>
  Start Harbor
 </li>
</ol>
<pre><code class="language-bash">    sudo systemctl start harbor
</code></pre>
<h3>
 Final Verification Checklist
</h3>
<p>
 Run these commands to verify Harbor is working:
</p>
<pre><code class="language-bash"># Check all containers
sudo docker compose ps

# Check systemd service
sudo systemctl status harbor

# Check local access
curl -I http://127.0.0.1:8080

# Check HTTPS access
curl -I https://harbor.arpansahu.space

# Check Nginx config
sudo nginx -t

# Check firewall
sudo ufw status | grep -E &#x27;(80|443)&#x27;

# Test Docker login
docker login harbor.arpansahu.space
</code></pre>
<p>
 Then test in browser:
 <br/>
 - Access: https://harbor.arpansahu.space
 <br/>
 - Login with admin credentials
 <br/>
 - Create test project
 <br/>
 - Push test image
 <br/>
 - Scan image for vulnerabilities
 <br/>
 - Verify retention policy configured
</p>
<h3>
 What This Setup Provides
</h3>
<p>
 After following this guide, you will have:
</p>
<ol>
 <li>
  Self-hosted private Docker registry
 </li>
 <li>
  HTTPS access via Nginx reverse proxy
 </li>
 <li>
  Automatic startup with systemd
 </li>
 <li>
  Vulnerability scanning with Trivy
 </li>
 <li>
  Image signing with Notary
 </li>
 <li>
  Helm chart repository
 </li>
 <li>
  Automatic image retention
 </li>
 <li>
  Web UI for management
 </li>
 <li>
  Robot accounts for CI/CD
 </li>
 <li>
  Production-ready configuration
 </li>
</ol>
<h3>
 Example Configuration Summary
</h3>
<table>
 <thead>
  <tr>
   <th>
    Component
   </th>
   <th>
    Value
   </th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <td>
    Harbor URL
   </td>
   <td>
    https://harbor.arpansahu.space
   </td>
  </tr>
  <tr>
   <td>
    Internal Port
   </td>
   <td>
    8080 (localhost only)
   </td>
  </tr>
  <tr>
   <td>
    Admin User
   </td>
   <td>
    admin
   </td>
  </tr>
  <tr>
   <td>
    Default Project
   </td>
   <td>
    library
   </td>
  </tr>
  <tr>
   <td>
    Data Directory
   </td>
   <td>
    /data
   </td>
  </tr>
  <tr>
   <td>
    Config File
   </td>
   <td>
    /opt/harbor/harbor.yml
   </td>
  </tr>
  <tr>
   <td>
    Service File
   </td>
   <td>
    /etc/systemd/system/harbor.service
   </td>
  </tr>
 </tbody>
</table>
<h3>
 Architecture Summary
</h3>
<pre><code>Internet (HTTPS)
   ‚îÇ
   ‚îî‚îÄ Nginx (TLS Termination)
        ‚îÇ [Wildcard Certificate: *.arpansahu.space]
        ‚îÇ
        ‚îî‚îÄ harbor.arpansahu.space (Port 443 ‚Üí 8080)
             ‚îÇ
             ‚îî‚îÄ Harbor Stack (Docker Compose)
                  ‚îú‚îÄ Harbor Core (API + Logic)
                  ‚îú‚îÄ Harbor Portal (Web UI)
                  ‚îú‚îÄ Registry (Image Storage)
                  ‚îú‚îÄ PostgreSQL (Metadata)
                  ‚îú‚îÄ Redis (Cache)
                  ‚îú‚îÄ Trivy (Vulnerability Scanner)
                  ‚îú‚îÄ Notary (Image Signing)
                  ‚îî‚îÄ ChartMuseum (Helm Charts)
</code></pre>
<h3>
 Key Rules to Remember
</h3>
<ol>
 <li>
  Harbor internal port (8080) never exposed externally
 </li>
 <li>
  System Nginx handles all TLS termination
 </li>
 <li>
  Use systemd for automatic startup
 </li>
 <li>
  Robot accounts for CI/CD pipelines
 </li>
 <li>
  Configure retention to manage storage
 </li>
 <li>
  Enable vulnerability scanning on push
 </li>
 <li>
  Regular backups of /data directory
 </li>
 <li>
  Monitor disk usage in /data
 </li>
 <li>
  Use RBAC for multi-tenant access
 </li>
 <li>
  Keep Harbor updated
 </li>
</ol>
<h3>
 Troubleshooting
</h3>
<h4>
 1. 413 Request Entity Too Large Error
</h4>
<p>
 <strong>
  Symptom:
 </strong>
 Docker push fails with
 <code>
  413 Request Entity Too Large
 </code>
 when pushing large images.
</p>
<p>
 <strong>
  Cause:
 </strong>
 Nginx
 <code>
  client_max_body_size
 </code>
 limit is too small (default is 1MB).
</p>
<p>
 <strong>
  Solution:
 </strong>
</p>
<ol>
 <li>
  Edit system nginx configuration:
 </li>
</ol>
<pre><code class="language-bash">   sudo nano /etc/nginx/sites-available/services
</code></pre>
<ol>
 <li>
  Find the Harbor location block and add/update:
 </li>
</ol>
<pre><code class="language-nginx">   location / {
       client_max_body_size 2G;  # Adjust as needed
       proxy_pass http://127.0.0.1:8080;
       # ... rest of config
   }
</code></pre>
<ol>
 <li>
  Test and reload nginx:
 </li>
</ol>
<pre><code class="language-bash">   sudo nginx -t
   sudo systemctl reload nginx
</code></pre>
<p>
 <strong>
  Note:
 </strong>
 Harbor's internal nginx is already set to
 <code>
  client_max_body_size 0;
 </code>
 (unlimited) in its
 <code>
  /etc/nginx/nginx.conf
 </code>
 , so you only need to fix the external/system nginx configuration at
 <code>
  /etc/nginx/sites-available/services
 </code>
 .
</p>
<p>
 <strong>
  Verify Harbor's internal nginx (optional):
 </strong>
</p>
<pre><code class="language-bash">docker exec nginx cat /etc/nginx/nginx.conf | grep client_max_body_size
# Should show: client_max_body_size 0;
</code></pre>
<h4>
 2. Cannot Connect to Harbor
</h4>
<p>
 <strong>
  Check these:
 </strong>
</p>
<pre><code class="language-bash"># 1. Is Harbor running?
sudo systemctl status harbor
docker ps | grep harbor

# 2. Is nginx running?
sudo systemctl status nginx

# 3. Check logs
sudo journalctl -u harbor -n 50
docker logs nginx
</code></pre>
<h4>
 3. Login Issues
</h4>
<pre><code class="language-bash"># Reset admin password
cd /opt/harbor
sudo docker-compose stop
sudo ./prepare
sudo docker-compose up -d
</code></pre>
<h4>
 4. Disk Space Full
</h4>
<pre><code class="language-bash"># Check disk usage
df -h /data

# Run garbage collection
docker exec harbor-core harbor-gc

# Or via UI: Administration ‚Üí Garbage Collection ‚Üí Run Now
</code></pre>
<h4>
 5. Slow Image Pushes
</h4>
<p>
 Check nginx configuration for these settings:
</p>
<pre><code class="language-nginx">proxy_buffering off;
proxy_request_buffering off;
proxy_connect_timeout 300;
proxy_send_timeout 300;
proxy_read_timeout 300;
</code></pre>
<h3>
 Next Steps
</h3>
<p>
 After setting up Harbor:
</p>
<ol>
 <li>
  Create projects for different teams
 </li>
 <li>
  Configure robot accounts for CI/CD
 </li>
 <li>
  Set up vulnerability scan policies
 </li>
 <li>
  Configure image retention rules
 </li>
 <li>
  Enable garbage collection
 </li>
 <li>
  Set up replication (if multi-site)
 </li>
 <li>
  Integrate with CI/CD pipelines
 </li>
</ol>
<p>
 My Harbor instance: https://harbor.arpansahu.space
</p>
<p>
 For CI/CD integration, see Jenkins documentation.
</p>
<h1>
 Website Uptime Monitor
</h1>
<p>
 This project monitors the uptime of specified websites and sends an email alert if any website is down or returns a non-2xx status code. The project uses a shell script to set up a virtual environment, install dependencies, run the monitoring script, and then clean up the virtual environment.
</p>
<h2>
 Prerequisites
</h2>
<ul>
 <li>
  Python 3
 </li>
 <li>
  Pip (Python package installer)
 </li>
 <li>
  Mailjet account for email alerts
 </li>
 <li>
  Cron for scheduling the script
 </li>
</ul>
<h2>
 Setup
</h2>
<h3>
 1. Clone the Repository
</h3>
<pre><code class="language-sh">git clone https://github.com/yourusername/website-uptime-monitor.git
cd website-uptime-monitor
</code></pre>
<h3>
 2. Create a
 <code>
  .env
 </code>
 File
</h3>
<p>
 Create a
 <code>
  .env
 </code>
 file in the root directory and add the following content:
</p>
<pre><code class="language-env">MAILJET_API_KEY=your_mailjet_api_key
MAILJET_SECRET_KEY=your_mailjet_secret_key
SENDER_EMAIL=your_sender_email@example.com
RECEIVER_EMAIL=your_receiver_email@example.com
</code></pre>
<h2>
 Running the Script
</h2>
<p>
 To run the script manually, give permissions and execute:
</p>
<pre><code class="language-sh">chmod +x ./setup_and_run.sh
./setup_and_run.sh
</code></pre>
<pre><code class="language-sh">chmod +x ./docker_cleanup_mail.sh
./docker_cleanup_mail.sh
</code></pre>
<h2>
 Setting Up a Cron Job
</h2>
<p>
 To run the script automatically at regular intervals, set up a cron job:
</p>
<ol>
 <li>
  Edit the crontab:
 </li>
</ol>
<pre><code class="language-sh">crontab -e
</code></pre>
<ol>
 <li>
  Add the following line to run the script every 5 hours:
 </li>
</ol>
<pre><code class="language-sh">0 */5 * * * /bin/bash /root/arpansahu-one-scripts/setup_and_run.sh &gt;&gt; /root/logs/website_up_time.log 2&gt;&amp;1
0 0 * * * export MAILJET_API_KEY=&quot;MAILJET_API_KEY&quot; &amp;&amp; export MAILJET_SECRET_KEY=&quot;MAILJET_SECRET_KEY&quot; &amp;&amp; export SENDER_EMAIL=&quot;SENDER_EMAIL&quot; &amp;&amp; export RECEIVER_EMAIL=&quot;RECEIVER_EMAIL&quot; &amp;&amp; /usr/bin/docker system prune -af --volumes &gt; /root/logs/docker_prune.log 2&gt;&amp;1 &amp;&amp; /root/arpansahu-one-scripts/docker_cleanup_mail.sh
</code></pre>
<h1>
 Integrating Jenkins
</h1>
<ul>
 <li>
  Now Create a file named Jenkinsfile at the root of Git Repo and add following lines to file
 </li>
</ul>
<pre><code class="language-bash">pipeline {
    agent { label &#x27;local&#x27; }
    environment {
        ENV_PROJECT_NAME = &quot;arpansahu_one_scripts&quot;
    }
    stages {
        stage(&#x27;Initialize&#x27;) {
            steps {
                script {
                    echo &quot;Current workspace path is: ${env.WORKSPACE}&quot;
                }
            }
        }
        stage(&#x27;Checkout&#x27;) {
            steps {
                checkout scm
            }
        }
    }
    post {
        success {
            script {
                // Retrieve the latest commit message
                def commitMessage = sh(script: &quot;git log -1 --pretty=%B&quot;, returnStdout: true).trim()
                if (currentBuild.description == &#x27;DEPLOYMENT_EXECUTED&#x27;) {
                    sh &quot;&quot;&quot;curl -s \
                    -X POST \
                    --user $MAIL_JET_API_KEY:$MAIL_JET_API_SECRET \
                    https://api.mailjet.com/v3.1/send \
                    -H &quot;Content-Type:application/json&quot; \
                    -d &#x27;{
                        &quot;Messages&quot;:[
                                {
                                        &quot;From&quot;: {
                                                &quot;Email&quot;: &quot;$MAIL_JET_EMAIL_ADDRESS&quot;,
                                                &quot;Name&quot;: &quot;ArpanSahuOne Jenkins Notification&quot;
                                        },
                                        &quot;To&quot;: [
                                                {
                                                        &quot;Email&quot;: &quot;$MY_EMAIL_ADDRESS&quot;,
                                                        &quot;Name&quot;: &quot;Development Team&quot;
                                                }
                                        ],
                                        &quot;Subject&quot;: &quot;Jenkins Build Pipeline your project ${currentBuild.fullDisplayName} Ran Successfully&quot;,
                                        &quot;TextPart&quot;: &quot;Hola Development Team, your project ${currentBuild.fullDisplayName} is now deployed&quot;,
                                        &quot;HTMLPart&quot;: &quot;&lt;h3&gt;Hola Development Team, your project ${currentBuild.fullDisplayName} is now deployed &lt;/h3&gt; &lt;br&gt; &lt;p&gt; Build Url: ${env.BUILD_URL}  &lt;/p&gt;&quot;
                                }
                        ]
                    }&#x27;&quot;&quot;&quot;
                }
                // Trigger the common_readme job for all repositories&quot;
                build job: &#x27;common_readme&#x27;, parameters: [string(name: &#x27;environment&#x27;, value: &#x27;prod&#x27;)], wait: false

            }
        }
        failure {
            sh &quot;&quot;&quot;curl -s \
            -X POST \
            --user $MAIL_JET_API_KEY:$MAIL_JET_API_SECRET \
            https://api.mailjet.com/v3.1/send \
            -H &quot;Content-Type:application/json&quot; \
            -d &#x27;{
                &quot;Messages&quot;:[
                        {
                                &quot;From&quot;: {
                                        &quot;Email&quot;: &quot;$MAIL_JET_EMAIL_ADDRESS&quot;,
                                        &quot;Name&quot;: &quot;ArpanSahuOne Jenkins Notification&quot;
                                },
                                &quot;To&quot;: [
                                        {
                                                &quot;Email&quot;: &quot;$MY_EMAIL_ADDRESS&quot;,
                                                &quot;Name&quot;: &quot;Developer Team&quot;
                                        }
                                ],
                            &quot;Subject&quot;: &quot;Jenkins Build Pipeline your project ${currentBuild.fullDisplayName} Ran Failed&quot;,
                            &quot;TextPart&quot;: &quot;Hola Development Team, your project ${currentBuild.fullDisplayName} deployment failed&quot;,
                            &quot;HTMLPart&quot;: &quot;&lt;h3&gt;Hola Development Team, your project ${currentBuild.fullDisplayName} is not deployed, Build Failed &lt;/h3&gt; &lt;br&gt; &lt;p&gt; Build Url: ${env.BUILD_URL}  &lt;/p&gt;&quot;
                        }
                ]
            }&#x27;&quot;&quot;&quot;
        }
    }
}
</code></pre>
<p>
 Note: agent {label 'local'} is used to specify which node will execute the jenkins job deployment. So local linux server is labelled with 'local' are the project with this label will be executed in local machine node.
</p>
<ul>
 <li>
  Configure a Jenkins project from jenkins ui located at https://jenkins.arpansahu.me
 </li>
</ul>
<p>
 Make sure to use Pipeline project and name it whatever you want I have named it as per great_chat
</p>
<p>
 <img alt="Jenkins Pipeline Configuration" src="https://github.com/arpansahu/arpansahu-one-scripts/raw/main/Jenkinsfile.png"/>
</p>
<p>
 In this above picture you can see credentials right? you can add your github credentials and harbor credentials use harbor-credentials as id for harbor credentials.
 <br/>
 from Manage Jenkins on home Page --> Manage Credentials
</p>
<p>
 and add your GitHub credentials from there
</p>
<ul>
 <li>
  Add a .env file to you project using following command (This step is no more required stage('Dependencies'))
 </li>
</ul>
<pre><code class="language-bash">    sudo vi  /var/lib/jenkins/workspace/arpansahu_one_script/.env
</code></pre>
<pre><code>Your workspace name may be different.

Add all the env variables as required and mentioned in the Readme File.
</code></pre>
<ul>
 <li>
  <p>
   Add Global Jenkins Variables from Dashboard --> Manage --> Jenkins
   <br/>
   Configure System
  </p>
 </li>
 <li>
  <p>
   MAIL_JET_API_KEY
  </p>
 </li>
 <li>
  MAIL_JET_API_SECRET
 </li>
 <li>
  MAIL_JET_EMAIL_ADDRESS
 </li>
 <li>
  MY_EMAIL_ADDRESS
 </li>
</ul>
<p>
 Now you are good to go.
</p>
<h2>
 License
</h2>
<p>
 This project is licensed under the MIT License. See the
 <a href="LICENSE">
  LICENSE
 </a>
 file for details.
</p>
<h2>
 Documentation
</h2>
<p>
 <a href="https://www.python.org/">
  <img alt="Python" src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.djangoproject.com/">
  <img alt="Django" src="https://img.shields.io/badge/Django-092E20?style=for-the-badge&logo=django&logoColor=white"/>
 </a>
 <br/>
 <a href="https://developer.mozilla.org/en-US/docs/Glossary/HTML5">
  <img alt="HTML5" src="https://img.shields.io/badge/html5-%23E34F26.svg?style=for-the-badge&logo=html5&logoColor=white"/>
 </a>
 <br/>
 <a href="https://developer.mozilla.org/en-US/docs/Web/CSS">
  <img alt="CSS3" src="https://img.shields.io/badge/css3-%231572B6.svg?style=for-the-badge&logo=css3&logoColor=white"/>
 </a>
 <br/>
 <a href="https://getbootstrap.com/">
  <img alt="Bootstrap" src="https://img.shields.io/badge/Bootstrap-563D7C?style=for-the-badge&logo=bootstrap&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.javascript.com/">
  <img alt="Javascript" src="https://img.shields.io/badge/JavaScript-323330?style=for-the-badge&logo=javascript&logoColor=F7DF1E"/>
 </a>
 <br/>
 <a href="https://redis.io/docs/">
  <img alt="Redis" src="https://img.shields.io/badge/redis-%23DD0031.svg?style=for-the-badge&logo=redis&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.postgresql.org/docs/">
  <img alt="Postgres" src="https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.github.com/">
  <img alt="Github" src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.docker.com/">
  <img alt="Docker" src="https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white"/>
 </a>
 <br/>
 <a href="https://goharbor.io/">
  <img alt="Harbor" src="https://img.shields.io/badge/HARBOR-TEXT?style=for-the-badge&logo=harbor&logoColor=white&color=blue"/>
 </a>
 <br/>
 <a href="https://kubernetes.io/">
  <img alt="Kubernetes" src="https://img.shields.io/badge/kubernetes-326ce5.svg?&style=for-the-badge&logo=kubernetes&logoColor=white"/>
 </a>
 <br/>
 <a href="https://www.jenkins.io/">
  <img alt="Jenkins" src="https://img.shields.io/badge/Jenkins-D24939?style=for-the-badge&logo=Jenkins&logoColor=white"/>
 </a>
 <br/>
 <a href="https://nginx.org/en/">
  <img alt="Nginx" src="https://img.shields.io/badge/Nginx-009639?style=for-the-badge&logo=nginx&logoColor=white"/>
 </a>
 <br/>
 <a href="https://min.io/">
  <img alt="MINIIO" src="https://img.shields.io/badge/MINIO-TEXT?style=for-the-badge&logo=minio&logoColor=white&color=%23C72E49"/>
 </a>
 <br/>
 <a href="https://ubuntu.com/">
  <img alt="Ubuntu" src="https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white"/>
 </a>
 <br/>
 <a href="https://mailjet.com/">
  <img alt="Mail Jet" src="https://img.shields.io/badge/MAILJET-9933CC?style=for-the-badge&logo=minutemailer&logoColor=white"/>
 </a>
 <br/>
 <a href="https://graphql.org/">
  <img alt="GraphQL" src="https://img.shields.io/badge/-GraphQL-E10098?style=for-the-badge&logo=graphql&logoColor=white"/>
 </a>
 <br/>
 <a href="https://rancher.com/">
  <img alt="Rancher" src="https://img.shields.io/badge/Rancher-0075A8?style=for-the-badge&logo=rancher&logoColor=white"/>
 </a>
</p>
<h2>
 Environment Variables
</h2>
<p>
 To run this project, you will need to add the following environment variables to your .env file
</p>
<p>
 SECRET_KEY=
</p>
<p>
 DEBUG=
</p>
<p>
 ALLOWED_HOSTS=
</p>
<p>
 MAIL_JET_API_KEY=
</p>
<p>
 MAIL_JET_API_SECRET=
</p>
<p>
 MAIL_JET_EMAIL_ADDRESS=
</p>
<p>
 AWS_ACCESS_KEY_ID=
</p>
<p>
 AWS_SECRET_ACCESS_KEY=
</p>
<p>
 AWS_STORAGE_BUCKET_NAME=
</p>
<p>
 BUCKET_TYPE=
</p>
<p>
 DATABASE_URL=
</p>
<p>
 REDIS_CLOUD_URL=
</p>
<h1>
 SENTRY
</h1>
<p>
 SENTRY_ENVIRONMENT=
</p>
<p>
 SENTRY_DSH_URL=
</p>
<h1>
 deploy_kube.sh requirements
</h1>
<p>
 HARBOR_USERNAME=
</p>
<p>
 HARBOR_PASSWORD=
</p>
